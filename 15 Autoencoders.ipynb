{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 8\n",
    "===\n",
    "Let's create an autoencoder network that pretrains on MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "%autosave 60\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib.layers import batch_norm, dropout\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import tensorflow as tf\n",
    "\n",
    "def he_normal_initialisation(n_inputs, n_outputs):\n",
    "    stddev = np.power(2 / (n_inputs + n_outputs), 1 / np.sqrt(2))\n",
    "    # truncated normal distributions limit the size of the weights, speeding up the training time.\n",
    "    return tf.truncated_normal((n_inputs, n_outputs), stddev=stddev)\n",
    "\n",
    "def he_uniform_initialisation(n_inputs, n_outputs):\n",
    "    r = np.power(6 / (n_inputs + n_outputs), 1 / np.sqrt(2))\n",
    "    # truncated normal distributions limit the size of the weights, speeding up the training time.\n",
    "    return tf.random_uniform((n_inputs, n_outputs), -r, r)\n",
    "\n",
    "def create_next_batch_fn(data, sequence_lengths, targets, batch_size):\n",
    "    assert len(data) == len(sequence_lengths) and len(data) == len(targets)\n",
    "    current_batch = 0\n",
    "    def next_batch():\n",
    "        nonlocal current_batch\n",
    "        i = current_batch\n",
    "        #print(current_batch)\n",
    "        current_batch = (current_batch + batch_size) % len(data)\n",
    "        return data[i:i+batch_size], sequence_lengths[i:i+batch_size], targets[i:i+batch_size]\n",
    "    return next_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "loss: 2.27078\n",
      "loss: 0.254759\n",
      "loss: 0.141714\n",
      "loss: 0.101709\n",
      "loss: 0.0780657\n",
      "loss: 0.0700765\n",
      "loss: 0.0645068\n",
      "loss: 0.0657069\n",
      "loss: 0.0627948\n",
      "loss: 0.0614734\n",
      "loss: 0.0583138\n",
      "loss: 0.0585591\n",
      "loss: 0.0606396\n",
      "loss: 0.0556942\n",
      "loss: 0.0523049\n",
      "loss: 0.0486281\n",
      "loss: 0.0459388\n",
      "loss: 0.0445281\n",
      "loss: 0.043414\n",
      "loss: 0.0444157\n",
      "loss: 0.0406482\n",
      "loss: 0.0429298\n",
      "loss: 0.045086\n",
      "loss: 0.0454946\n",
      "loss: 0.0391934\n",
      "loss: 0.0399485\n",
      "loss: 0.0360391\n",
      "loss: 0.0341994\n",
      "loss: 0.0398608\n",
      "loss: 0.0451679\n",
      "loss: 0.0359333\n",
      "loss: 0.0366532\n",
      "loss: 0.0327975\n",
      "loss: 0.0331991\n",
      "loss: 0.0534569\n",
      "loss: 0.038663\n",
      "loss: 0.0338426\n",
      "epoch 1\n",
      "loss: 0.0330448\n",
      "loss: 0.0314743\n",
      "loss: 0.031414\n",
      "loss: 0.0317418\n",
      "loss: 0.0295013\n",
      "loss: 0.0354196\n",
      "loss: 0.0314794\n",
      "loss: 0.0321343\n",
      "loss: 0.0301898\n",
      "loss: 0.0315988\n",
      "loss: 0.0306294\n",
      "loss: 0.0280288\n",
      "loss: 0.0308449\n",
      "loss: 0.0283249\n",
      "loss: 0.0281437\n",
      "loss: 0.0291511\n",
      "loss: 0.0378604\n",
      "loss: 0.0307838\n",
      "loss: 0.0286704\n",
      "loss: 0.0270061\n",
      "loss: 0.0257591\n",
      "loss: 0.0278083\n",
      "loss: 0.0406164\n",
      "loss: 0.0286104\n",
      "loss: 0.0260851\n",
      "loss: 0.0281577\n",
      "loss: 0.0244658\n",
      "loss: 0.0240143\n",
      "loss: 0.0275407\n",
      "loss: 0.0339346\n",
      "loss: 0.025839\n",
      "loss: 0.0252203\n",
      "loss: 0.0259585\n",
      "loss: 0.0234969\n",
      "loss: 0.0237163\n",
      "loss: 0.0266187\n",
      "loss: 0.0262446\n",
      "epoch 2\n",
      "loss: 0.0246969\n",
      "loss: 0.0235134\n",
      "loss: 0.0300652\n",
      "loss: 0.0243105\n",
      "loss: 0.0231697\n",
      "loss: 0.0225438\n",
      "loss: 0.0251659\n",
      "loss: 0.0294945\n",
      "loss: 0.0240409\n",
      "loss: 0.0233496\n",
      "loss: 0.0196994\n",
      "loss: 0.0236485\n",
      "loss: 0.0246886\n",
      "loss: 0.023963\n",
      "loss: 0.0213355\n",
      "loss: 0.02077\n",
      "loss: 0.022508\n",
      "loss: 0.0209679\n",
      "loss: 0.0203923\n",
      "loss: 0.023649\n",
      "loss: 0.0236636\n",
      "loss: 0.027912\n",
      "loss: 0.0245935\n",
      "loss: 0.0236713\n",
      "loss: 0.0185645\n",
      "loss: 0.0193879\n",
      "loss: 0.0186019\n",
      "loss: 0.0232467\n",
      "loss: 0.02971\n",
      "loss: 0.0234261\n",
      "loss: 0.0197728\n",
      "loss: 0.0213933\n",
      "loss: 0.0232277\n",
      "loss: 0.0211189\n",
      "loss: 0.0192217\n",
      "loss: 0.0191085\n",
      "loss: 0.0181811\n",
      "epoch 3\n",
      "loss: 0.0175776\n",
      "loss: 0.0194698\n",
      "loss: 0.018162\n",
      "loss: 0.0205557\n",
      "loss: 0.0195453\n",
      "loss: 0.0197401\n",
      "loss: 0.0190948\n",
      "loss: 0.0280992\n",
      "loss: 0.0284913\n",
      "loss: 0.0287597\n",
      "loss: 0.0256168\n",
      "loss: 0.0188141\n",
      "loss: 0.0202368\n",
      "loss: 0.0157231\n",
      "loss: 0.0164696\n",
      "loss: 0.0186706\n",
      "loss: 0.0220734\n",
      "loss: 0.020123\n",
      "loss: 0.0171931\n",
      "loss: 0.0229486\n",
      "loss: 0.0180793\n",
      "loss: 0.0181969\n",
      "loss: 0.021359\n",
      "loss: 0.0198274\n",
      "loss: 0.0157341\n",
      "loss: 0.0164204\n",
      "loss: 0.0170393\n",
      "loss: 0.0165444\n",
      "loss: 0.0151572\n",
      "loss: 0.0149291\n",
      "loss: 0.016798\n",
      "loss: 0.0205813\n",
      "loss: 0.017712\n",
      "loss: 0.0158771\n",
      "loss: 0.0181389\n",
      "loss: 0.0167054\n",
      "loss: 0.0190026\n",
      "epoch 4\n",
      "loss: 0.0188404\n",
      "loss: 0.0179476\n",
      "loss: 0.0171596\n",
      "loss: 0.0147567\n",
      "loss: 0.0179938\n",
      "loss: 0.0251245\n",
      "loss: 0.0162464\n",
      "loss: 0.0152466\n",
      "loss: 0.0208697\n",
      "loss: 0.0149969\n",
      "loss: 0.0142512\n",
      "loss: 0.0169499\n",
      "loss: 0.0153119\n",
      "loss: 0.0153365\n",
      "loss: 0.014849\n",
      "loss: 0.0187303\n",
      "loss: 0.0189694\n",
      "loss: 0.019752\n",
      "loss: 0.0167608\n",
      "loss: 0.0154998\n",
      "loss: 0.0131942\n",
      "loss: 0.0135243\n",
      "loss: 0.0143413\n",
      "loss: 0.0133943\n",
      "loss: 0.0131782\n",
      "loss: 0.0146912\n",
      "loss: 0.0148078\n",
      "loss: 0.0155875\n",
      "loss: 0.0135891\n",
      "loss: 0.0142686\n",
      "loss: 0.0135829\n",
      "loss: 0.0127991\n",
      "loss: 0.0153643\n",
      "loss: 0.0155743\n",
      "loss: 0.019971\n",
      "loss: 0.0211655\n",
      "loss: 0.015507\n",
      "epoch 5\n",
      "loss: 0.0203617\n",
      "loss: 0.0199937\n",
      "loss: 0.0252105\n",
      "loss: 0.0253268\n",
      "loss: 0.0197124\n",
      "loss: 0.0154774\n",
      "loss: 0.0122849\n",
      "loss: 0.0118179\n",
      "loss: 0.0132695\n",
      "loss: 0.0153637\n",
      "loss: 0.0123196\n",
      "loss: 0.011981\n",
      "loss: 0.0119371\n",
      "loss: 0.0107928\n",
      "loss: 0.0130492\n",
      "loss: 0.012446\n",
      "loss: 0.0121379\n",
      "loss: 0.0118675\n",
      "loss: 0.0132857\n",
      "loss: 0.0121228\n",
      "loss: 0.0118431\n",
      "loss: 0.0114468\n",
      "loss: 0.0108065\n",
      "loss: 0.0144242\n",
      "loss: 0.0122571\n",
      "loss: 0.010847\n",
      "loss: 0.0113981\n",
      "loss: 0.0136567\n",
      "loss: 0.0126933\n",
      "loss: 0.0125195\n",
      "loss: 0.0118033\n",
      "loss: 0.0118655\n",
      "loss: 0.0107103\n",
      "loss: 0.0131195\n",
      "loss: 0.0108728\n",
      "loss: 0.0124263\n",
      "loss: 0.0112881\n",
      "epoch 6\n",
      "loss: 0.0113728\n",
      "loss: 0.0132186\n",
      "loss: 0.012656\n",
      "loss: 0.0127131\n",
      "loss: 0.0120829\n",
      "loss: 0.0115001\n",
      "loss: 0.0121006\n",
      "loss: 0.0102933\n",
      "loss: 0.0111933\n",
      "loss: 0.0112812\n",
      "loss: 0.012973\n",
      "loss: 0.0129063\n",
      "loss: 0.0138336\n",
      "loss: 0.0110815\n",
      "loss: 0.0101132\n",
      "loss: 0.0114028\n",
      "loss: 0.0103589\n",
      "loss: 0.0122788\n",
      "loss: 0.0118862\n",
      "loss: 0.0137129\n",
      "loss: 0.0115452\n",
      "loss: 0.016336\n",
      "loss: 0.0119682\n",
      "loss: 0.0111916\n",
      "loss: 0.0101514\n",
      "loss: 0.0111593\n",
      "loss: 0.0110658\n",
      "loss: 0.0115354\n",
      "loss: 0.0102453\n",
      "loss: 0.00958442\n",
      "loss: 0.00937573\n",
      "loss: 0.0121834\n",
      "loss: 0.0108558\n",
      "loss: 0.0099695\n",
      "loss: 0.0112821\n",
      "loss: 0.0104118\n",
      "loss: 0.0137767\n",
      "epoch 7\n",
      "loss: 0.0117027\n",
      "loss: 0.0111917\n",
      "loss: 0.0100651\n",
      "loss: 0.0119087\n",
      "loss: 0.0103803\n",
      "loss: 0.0103604\n",
      "loss: 0.0102015\n",
      "loss: 0.0126598\n",
      "loss: 0.0116741\n",
      "loss: 0.00975474\n",
      "loss: 0.0116517\n",
      "loss: 0.0112913\n",
      "loss: 0.0101732\n",
      "loss: 0.00969362\n",
      "loss: 0.00949372\n",
      "loss: 0.0111959\n",
      "loss: 0.00964731\n",
      "loss: 0.00936586\n",
      "loss: 0.00890736\n",
      "loss: 0.0114387\n",
      "loss: 0.0107395\n",
      "loss: 0.00937311\n",
      "loss: 0.00870076\n",
      "loss: 0.0115439\n",
      "loss: 0.00978117\n",
      "loss: 0.00929171\n",
      "loss: 0.00940147\n",
      "loss: 0.0080428\n",
      "loss: 0.0103123\n",
      "loss: 0.00923915\n",
      "loss: 0.00873748\n",
      "loss: 0.0100065\n",
      "loss: 0.0088365\n",
      "loss: 0.00976072\n",
      "loss: 0.00875141\n",
      "loss: 0.00990922\n",
      "loss: 0.0111188\n",
      "epoch 8\n",
      "loss: 0.00944267\n",
      "loss: 0.00915612\n",
      "loss: 0.00993246\n",
      "loss: 0.00948051\n",
      "loss: 0.00798007\n",
      "loss: 0.00976291\n",
      "loss: 0.00876746\n",
      "loss: 0.00990673\n",
      "loss: 0.00888798\n",
      "loss: 0.0117568\n",
      "loss: 0.0108455\n",
      "loss: 0.0110223\n",
      "loss: 1.10164\n",
      "loss: 88.0109\n",
      "loss: 31.7124\n",
      "loss: 30.744\n",
      "loss: 4.98128\n",
      "loss: 2.70199\n",
      "loss: 1.08787\n",
      "loss: 0.574992\n",
      "loss: 0.320893\n",
      "loss: 0.21691\n",
      "loss: 0.235946\n",
      "loss: 0.19373\n",
      "loss: 0.168649\n",
      "loss: 0.156371\n",
      "loss: 0.17685\n",
      "loss: 0.130393\n",
      "loss: 0.116722\n",
      "loss: 0.11959\n",
      "loss: 0.196734\n",
      "loss: 0.125605\n",
      "loss: 0.112528\n",
      "loss: 0.10735\n",
      "loss: 0.124463\n",
      "loss: 0.111374\n",
      "loss: 0.102939\n",
      "epoch 9\n",
      "loss: 0.098412\n",
      "loss: 0.0928831\n",
      "loss: 0.0948542\n",
      "loss: 0.0915311\n",
      "loss: 0.0956355\n",
      "loss: 0.101808\n",
      "loss: 0.0881048\n",
      "loss: 0.0848132\n",
      "loss: 0.0877739\n",
      "loss: 0.0844899\n",
      "loss: 0.0838053\n",
      "loss: 0.0828231\n",
      "loss: 0.0789539\n",
      "loss: 0.0790398\n",
      "loss: 0.0758867\n",
      "loss: 0.0795858\n",
      "loss: 0.0806282\n",
      "loss: 0.0739845\n",
      "loss: 0.0743417\n",
      "loss: 0.0768881\n",
      "loss: 0.0738261\n",
      "loss: 0.0739256\n",
      "loss: 0.0804054\n",
      "loss: 0.074586\n",
      "loss: 0.0726624\n",
      "loss: 0.0713413\n",
      "loss: 0.0728427\n",
      "loss: 0.0779859\n",
      "loss: 0.0694586\n",
      "loss: 0.0759109\n",
      "loss: 0.0713063\n",
      "loss: 0.0708952\n",
      "loss: 0.0715488\n",
      "loss: 0.0678704\n",
      "loss: 0.0668074\n",
      "loss: 0.0968056\n",
      "loss: 0.0668678\n",
      "epoch 10\n",
      "loss: 0.0713423\n",
      "loss: 0.070655\n",
      "loss: 0.0695282\n",
      "loss: 0.0678305\n",
      "loss: 0.070903\n",
      "loss: 0.0683668\n",
      "loss: 0.0686294\n",
      "loss: 0.0712065\n",
      "loss: 0.069137\n",
      "loss: 0.068232\n",
      "loss: 0.0637731\n",
      "loss: 0.0707775\n",
      "loss: 0.0666284\n",
      "loss: 0.0697431\n",
      "loss: 0.0715141\n",
      "loss: 0.0686426\n",
      "loss: 0.0703945\n",
      "loss: 0.0669654\n",
      "loss: 0.0706806\n",
      "loss: 0.0682579\n",
      "loss: 0.0645278\n",
      "loss: 0.0663187\n",
      "loss: 0.0669965\n",
      "loss: 0.0691556\n",
      "loss: 0.0681787\n",
      "loss: 0.0669325\n",
      "loss: 0.0671349\n",
      "loss: 0.0684043\n",
      "loss: 0.0679631\n",
      "loss: 0.0651555\n",
      "loss: 0.0696481\n",
      "loss: 0.0667614\n",
      "loss: 0.0659839\n",
      "loss: 0.0688322\n",
      "loss: 0.0652124\n",
      "loss: 0.0655774\n",
      "loss: 0.0650904\n",
      "epoch 11\n",
      "loss: 0.0667303\n",
      "Stopping early during epoch 11 with best loss: 0.00944267\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/mnist_autoencoder_model_early_stopping.ckpt\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "input_spatial_size = 28\n",
    "input_channels = 1\n",
    "batch_size = 150\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_input_neurons = input_spatial_size ** 2\n",
    "n_hidden_neurons_layer1 = 300\n",
    "n_hidden_neurons_layer2 = 150\n",
    "n_hidden_neurons_layer3 = n_hidden_neurons_layer1\n",
    "n_output_neurons = n_input_neurons\n",
    "l2_reg = 0.0001\n",
    "\n",
    "initializer = lambda a: he_uniform_initialisation(a[0], a[1])#tf.contrib.layers.variance_scaling_initializer()\n",
    "activation = tf.nn.elu\n",
    "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_input_neurons), name=\"input\") \n",
    "    \"\"\"\n",
    "    weights1 = initializer([n_input_neurons, n_hidden_neurons_layer1])\n",
    "    biases1 = tf.Variable(tf.zeros(n_hidden_neurons_layer1))\n",
    "    \n",
    "    weights2 = initializer([n_hidden_neurons_layer1, n_hidden_neurons_layer2])\n",
    "    biases2 = tf.Variable(tf.zeros(n_hidden_neurons_layer2))\n",
    "    \n",
    "    weights3 = initializer([n_hidden_neurons_layer2, n_hidden_neurons_layer3])\n",
    "    biases3 = tf.Variable(tf.zeros(n_hidden_neurons_layer3))\n",
    "    \n",
    "    weights4 = initializer([n_hidden_neurons_layer3, n_output_neurons])\n",
    "    biases4 = tf.Variable(tf.zeros(n_output_neurons))\n",
    "    \n",
    "    hidden1 = activation(tf.matmul(X, weights1) + biases1)\n",
    "    hidden2 = activation(tf.matmul(hidden1, weights2) + biases2)\n",
    "    hidden3 = activation(tf.matmul(hidden2, weights3) + biases3)\n",
    "    outputs = tf.matmul(hidden3, weights4) + biases4\n",
    "    \"\"\"\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    l2_regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "    from functools import partial\n",
    "    my_dense_layer = partial(tf.layers.dense,\n",
    "                             activation=tf.nn.elu,\n",
    "                             kernel_initializer=he_init,\n",
    "                             kernel_regularizer=l2_regularizer)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden_neurons_layer1)\n",
    "    hidden2 = my_dense_layer(hidden1, n_hidden_neurons_layer2)\n",
    "    hidden3 = my_dense_layer(hidden2, n_hidden_neurons_layer3)\n",
    "    outputs = my_dense_layer(hidden3, n_output_neurons, activation=None)\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        reconstruction_loss = tf.reduce_mean(tf.square(outputs - X), name=\"reconstruction_loss\")\n",
    "        regularisation_loss = regularizer(weights1) + regularizer(weights2) \\\n",
    "            + regularizer(weights3) + regularizer(weights4)\n",
    "        loss = reconstruction_loss# + regularisation_loss\n",
    "\n",
    "    with tf.name_scope(\"training\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "interim_checkpoint_path = \"./checkpoints/mnist_autoencoder_model.ckpt\"\n",
    "early_stopping_checkpoint_path = \"./checkpoints/mnist_autoencoder_model_early_stopping.ckpt\"\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "log_dir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "summary_op = tf.summary.merge([loss_summary])\n",
    "file_writer = tf.summary.FileWriter(log_dir, tf.get_default_graph())\n",
    "\n",
    "epochs = 20\n",
    "n_batches = int(np.ceil(len(mnist.train.images) // batch_size))\n",
    "\n",
    "early_stopping_check_frequency = n_batches // 4\n",
    "early_stopping_check_limit = n_batches * 3\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "session = sess\n",
    "sess.run(init)\n",
    "#saver.restore(sess, interim_checkpoint_path)\n",
    "\n",
    "best_loss = 1000000000.0\n",
    "best_loss_step = 0\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch\", epoch)\n",
    "    for batch_index in range(n_batches):\n",
    "        step = epoch * n_batches + batch_index\n",
    "        # TODO: replace this with code that gets a batch from X and y.\n",
    "        X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "        if batch_index % 10 == 0:\n",
    "            summary_str = summary_op.eval(session=sess, feed_dict={X: X_batch})\n",
    "            file_writer.add_summary(summary_str, step)\n",
    "        t = sess.run([training_op], feed_dict={X: X_batch})\n",
    "        l = sess.run(reconstruction_loss, feed_dict={X: X_batch})\n",
    "        if batch_index % 10 == 0: print(\"loss:\", l)\n",
    "        # Early stopping check\n",
    "        if batch_index % early_stopping_check_frequency == 0:\n",
    "            if l < best_loss:\n",
    "                saver.save(sess, early_stopping_checkpoint_path)\n",
    "                best_loss = l\n",
    "                best_loss_step = step\n",
    "            elif step >= (best_loss_step + early_stopping_check_limit):\n",
    "                print(\"Stopping early during epoch\", epoch, \"with best loss:\", best_loss)\n",
    "                break\n",
    "    else:\n",
    "        continue\n",
    "    break\n",
    "    save_path = saver.save(sess, interim_checkpoint_path)\n",
    "saver.restore(sess, early_stopping_checkpoint_path)\n",
    "save_path = saver.save(sess, \"./checkpoints/mnist_autoencoder_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niR9CiR9CiR9CiR9CiR9C/Q+tQlnV6P1waQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7da0615a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBUIQfCEX4gVCEHwhF+IFQhB8I9Qdc/5v4ytp+HAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e595be160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEr8EEr8EEr8EEr8EEr8EOoftmzn3LwQWuQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7da9ae5240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADVhJREFUeJzt3dtvVnUWxvHFQYFSeqAttjYUBNpEKCFCCFHvMN544T+q\nfwIJVxoCGAI2mggSSsuptZQWWo7VuZmLyST7ed7pntnqPN/P7cpu39OTfbF+a+0df/zxRwHIs/PP\nfgEA/hyEHwhF+IFQhB8IRfiBUIQfCEX4gVCEHwhF+IFQu7v8Z3Nzc/I44Zs3b+T16jTi1taWvHZw\ncFDWX79+Leu///77tmpVVTt27JD14eFhWd/c3Nx2fc+ePfJa99revn0r6y9evJB19d7afm6uvrGx\n0VjbvVv/9Hft2iXr7vp9+/bJuvrO3OfiXtvs7Kz+YP6JOz8QivADoQg/EIrwA6EIPxCK8AOhCD8Q\nqtM+/7t372Td9W1HRkYaa6qnW1X16tUrWR8YGJD1Z8+eNdbc6+7r65P11dVVWXd9XfX/3bXufIM7\ne3Ho0CFZV+cA3BkEx/XS1Xt3G6zee+89WW9zxqBKZ+H999+X17rvrFfc+YFQhB8IRfiBUIQfCEX4\ngVCEHwhF+IFQnfb5XV/WzTE/f/68seZ6o//LeX7XM3a9csddr3rO7nxD2363Ov9QpV+b64W778z9\nXlZWVhpr7oyB27HQpo9fVbVzZ/N9V9Wq/HfSK+78QCjCD4Qi/EAowg+EIvxAKMIPhOq01edGVw8e\nPCjrajzUtaxcK2/v3r2yrtptri3kWnXr6+uy7t6bqrdpE1b5ceT+/n5ZV9x38vLly23/7bb/u+2Y\ntWs9q8/drUt331mvuPMDoQg/EIrwA6EIPxCK8AOhCD8QivADoTrt87uesBuDVCPBbrzTjXC60dQD\nBw401paWluS1bkTTcT1ltXbc9ekd13N2o63qUdZuXbr73260VY0Eu/MP7hHcblTa/dbVGQb3vt2o\nc6+48wOhCD8QivADoQg/EIrwA6EIPxCK8AOhOu3zu168m6lfW1trrLk+/tbWlqy7+W41M++uda/N\nzX67Pv/y8nJjzb3vhYUFWd/c3JT1U6dOybp6hLfbU+D2HBw7dkzW1ec6Ojoqr1Vrv6v0GvmqqqGh\nIVlX5wTcint3xqBX3PmBUIQfCEX4gVCEHwhF+IFQhB8IRfiBUJ32+V1f1/VO1TmBtvPZbpeA6hlP\nTEzIa91MvdvD7nrxv/zyS2Ptm2++kde6PQZteulVVSdOnGisuXMf6oxAVdXjx49lXX3nbi+/69O7\nsxvut6x2EbjPxZ376BV3fiAU4QdCEX4gFOEHQhF+IBThB0J12upzLQq1HrtKj5e61oobF3b/27V2\nFDeiqR49XuVbpGp9dtvxUDUuXFV19epVWZ+ZmWmsTU1NyWvdSK/7PamWmRoP7+V/O+5zV6PWbgy7\nzW/xX3HnB0IRfiAU4QdCEX4gFOEHQhF+IBThB0L9pUZ6Xe9V9TfdY4vdmKR6ZHKVfm3uDIF7RLfr\ntbu//+WXXzbWJicn5bVu5PfOnTuyfvfuXVmfn59vrLmRXfcI7g8//FDW1dkNdz7B/R5cH9+tc1ej\n0O4R3W58vVfc+YFQhB8IRfiBUIQfCEX4gVCEHwhF+IFQnfb5XX9y//79sq764W41t+vzu3l+teLa\nrdZ289duLl3NxFfp1d+uD+/WhrvPdXp6WtbPnj3bWOvv75fXun63+72o78ydf3CP6HZnUtr8Ht1v\n0Z0b6RV3fiAU4QdCEX4gFOEHQhF+IBThB0IRfiBUp31+19d1vXi1D8CdIXC70N38tuo5u7l097cP\nHjwo6+7x4aqf/eOPP8prl5aWZH1gYEDWx8bGZF09T+HJkyfy2ocPH8r6+Pi4rCttdzC4Mwjusezq\nO3V/2/0eesWdHwhF+IFQhB8IRfiBUIQfCEX4gVCEHwjVaZ9f9aOrfG9V7Tp3fVv1DPsqP3Ov9rS7\nPr7by//dd9/JujujoPrhbtfAgwcPZN299hcvXsj6Dz/80Fj74IMP5LWufvPmTVlX50Lc3z59+rSs\nu2cGuHl+9Vt3Oxbc8y96xZ0fCEX4gVCEHwhF+IFQhB8IRfiBUJ22+twjl1Urr0q3vNwqZbcO2b02\nNdqqxlarqr7//ntZ//bbb2X90aNHsj4xMdFYc+1T96hp11Zy731oaGjbf3t5eVnWf/vtN1lfX19v\nrM3OzsprDx8+LOujo6Oy7t6bGl93OXD1XnHnB0IRfiAU4QdCEX4gFOEHQhF+IBThB0J12ud3q7nd\n6KrqWbt+9evXr2V9eHhY1lVP2fV03VisG3Wem5uTddUPd2vBjx49Kuvu8eEXLlyQ9S+++KKx5s4g\nqD59VdXly5dl/dq1a421GzduyGvduRC3rl2dvajSI+Tut+pGyHvFnR8IRfiBUIQfCEX4gVCEHwhF\n+IFQhB8I1Wmf33F9X/VoYrdC2vVd3RkE93hx5eTJk7L+1Vdfybpb5aw+t6mpKXntp59+Kuvnzp2T\n9Y8++kjW1TmBtvsdVldXZf3SpUuNtfn5eXnt4OCgrLvzEY56tLk7F+LOtPSKOz8QivADoQg/EIrw\nA6EIPxCK8AOhCD8QqtM+f5uZ+So9Y+1moNv2TtXu/MnJSXnt+Pi4rH/99dey/vnnn8u6em/u0ePu\nUdOu7s4gqLn5I0eOyGvdLgK3R0E9hls91rzK9/nfvn0r6ysrK7Kuzj+4nLjH0feKOz8QivADoQg/\nEIrwA6EIPxCK8AOhCD8QqtM+v+sJq75slZ7Zd/3svr4+WXfnBI4fP95Yc3vU3a4At7f/xIkTsq72\n26sdCFVVb968kfUrV67IutsXoGbyXa/dfS7uc1fX796tf/quj+/2O7hzAupzcc9KcK+tV9z5gVCE\nHwhF+IFQhB8IRfiBUIQfCPWXavW51o5qj7g10G7Ns3vksmsNKeoR2lVVa2tr2/7bVXqk17WF7t+/\nL+turNa1SFXdPYJ7cXFR1m/duiXr6vc2PT0tr3Xr1oeGhmTdtZ7d701x4+m94s4PhCL8QCjCD4Qi\n/EAowg+EIvxAKMIPhOq0z+/GR90q5jajjG60dWlpSdbV+m3Xd3Wjym499v79+2VdnUFwZwxcfXNz\nU9bn5uZkXY3turMX7rU9ePBA1j/++OPG2vnz5+W1Z86ckXU3Iu5+q+r8gztTwupuAK0QfiAU4QdC\nEX4gFOEHQhF+IBThB0J12ud3K4ldL17N7Lteu1vzrNaCV+lHdI+MjMhr1R6CqqrR0VFZd2cQnj59\n2lj76aef5LXXr1+X9YWFBVl/8uSJrKt++NjYmLzWPdr8k08+kfXPPvussaZWsVf5x67Pz8/LupvX\nV4+b39jYkNe631OvuPMDoQg/EIrwA6EIPxCK8AOhCD8QivADoTrt87vZcPfY4+fPnzfW3O57t5/e\n7Z9XzxRwc+nuEd3ufTvqjMLPP/8sr3Wvze1YmJ2dlXV1huHChQvy2omJCVl3M/Wql+7et/uturMZ\nbc+0KO476RV3fiAU4QdCEX4gFOEHQhF+IBThB0J12upzK4dVK89x660d19q5fft2Y821Xty4sHs0\nuXu0+dTUVGPt6NGj8lq3ovrw4cOy7tZMq9fmWpw7d+p7kxqzrtKj1r/++qu81r2vwcFBWXdr6lUr\n0P1v92jzXnHnB0IRfiAU4QdCEX4gFOEHQhF+IBThB0J12ud3/W7X39yzZ09jzfXa245gXrx4sbHm\nerrufbt+99DQkKyrR1G7a91YrFsj7UZj1aOq3Upy99rdd3bv3r1t/+19+/bJuvtO3WtTY+BbW1vy\nWlZ3A2iF8AOhCD8QivADoQg/EIrwA6EIPxCq0z6/esR2le4JV+l1xwMDA/Jat5rb9X1XVlYaa24m\n3vXS2zzOuUqfM3Az8Y8fP5Z19whut4tAnc1wewrcGQL3GG3VD3f7G1yfvm2vXf2W26yw/09w5wdC\nEX4gFOEHQhF+IBThB0IRfiAU4QdCddrnd7121w9Xc85uvlr1m6t831Zd7/YQuOcVLC4uyrqaS6/S\ns+duj4E7BzA8PCzrMzMzsq7em5vnd78H99rV9e47cY9dd7149xwJ9ffd47vHxsZkvVfc+YFQhB8I\nRfiBUIQfCEX4gVCEHwhF+IFQnfb53W59t69ccbsCXF/WnRNwPWfl5cuXsu52xLu5dfXe3a4A1892\n39mtW7dk/dWrV401t6fA9eLdTL46m+GeR+B+T45631V6l4Hbc7C+vr6t1/TvuPMDoQg/EIrwA6EI\nPxCK8AOhCD8QqtNWn2vdOGrs1rXTlpeXZd2t7lZ/3/1vt4LaPeJ7YmJC1tVoq1o5XuXHrN3YrPvc\n1HtzbUTXLhscHJR1tVbcreZ23HfmqM/Vtfrcd9Lza/iv/BUAfzuEHwhF+IFQhB8IRfiBUIQfCEX4\ngVCd9vnb9i9VP91d68ZH3ePB1Xpu1zN25xvcKLMbXXX9cMWtNHefmxsvVe/N9fndCms3ltvm/INb\nj+1+L457b4o7m9Er7vxAKMIPhCL8QCjCD4Qi/EAowg+EIvxAqB2u1wrg/xN3fiAU4QdCEX4gFOEH\nQhF+IBThB0IRfiAU4QdCEX4gFOEHQhF+IBThB0IRfiAU4QdCEX4gFOEHQhF+IBThB0IRfiAU4QdC\nEX4gFOEHQhF+INQ/AMCTbBNvtwtWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7da565e860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABgpJREFUeJzt3T1rFHschuHdo2IVCxUklVErwXdjqQRFsFAbW4lgZSli\naWMl4icISERLBSEQhEAIdlYWvlQ2EiwVG4mihWtzTjm/ydnNbmKe62ofJztgbqb4Z5Jur9frAHn+\nWe8bANaH+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CHU1hF/nh8nhOHrruYfefJDKPFDKPFDKPFDKPFD\nKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFDKPFD\nKPFDKPFDKPFDKPFDKPFDKPFDqFH/ie5IKysr5T4/P1/ur1+/Lvdnz541bsvLy+W1bXq9+q+q79mz\np9ynp6cbt4MHD/Z9bafT6WzZsqXcqXnyQyjxQyjxQyjxQyjxQyjxQyjxQ6hu2znuGhvph43KnTt3\nyn1hYaHc287xu91uuY+NjTVu+/btK68dto8fPzZu3759K6998+ZNuR86dKivewpQf8P8y5MfQokf\nQokfQokfQokfQokfQokfQnmffw18/fq13Hfv3l3ubT8H0GbXrl2N24kTJwb62oN6/vx543b9+vXy\n2suXL5f70tJSuU9MTJR7Ok9+CCV+CCV+CCV+CCV+CCV+COWVXtbN8ePHy/3t27flfv/+/XK/ffv2\n/76nTcIrvUAz8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo7/MzVB8+\nfGjcTp8+XV77+fPncv/9+3df9xTA+/xAM/FDKPFDKPFDKPFDKPFDKPFDKH+im4H8+PGj3B88eNC4\nffnypbz24sWLfd0Tq+PJD6HED6HED6HED6HED6HED6HED6Gc8zOQ6n39TqfTmZ2d7ftrX7hwoe9r\naefJD6HED6HED6HED6HED6HED6Ec9TGQJ0+e9H3tgQMHyv3q1at9f23aefJDKPFDKPFDKPFDKPFD\nKPFDKPFDKOf8lF68eFHuMzMzfX/ttp8R2LFjR99fm3ae/BBK/BBK/BBK/BBK/BBK/BBK/BDKOX+4\nlZWVcp+fny/379+/l/uxY8cat7b3+RkuT34IJX4IJX4IJX4IJX4IJX4IJX4I1e31eqP8vJF+GO3O\nnj1b7i9fviz3ycnJcp+bm2vcxsfHy2vpW3c1/8iTH0KJH0KJH0KJH0KJH0KJH0KJH0J5n3+Te/jw\nYbm/evWq3Ldv317u9+7dK3dn+RuXJz+EEj+EEj+EEj+EEj+EEj+EctS3CVTHeTdv3iyv/fXrV7k/\nevSo3M+dO1fubFye/BBK/BBK/BBK/BBK/BBK/BBK/BDKr+7+Czx+/Ljcb9y40bi1nePPzs6W+7Vr\n18qdDcmv7gaaiR9CiR9CiR9CiR9CiR9CiR9COeffAN69e1fuR48eLffq12vPzMyU105PT5c7fyXn\n/EAz8UMo8UMo8UMo8UMo8UMo8UMo5/wj8P79+3I/cuRIuXe79bHt3bt3G7dLly6V1w7b/v37G7ex\nsbER3kkU5/xAM/FDKPFDKPFDKPFDKPFDKEd9a2BxcbHc247bfv78We5tR3179+5t3JaXl8tr27R9\nf7Td28mTJxu3nTt39nVP/7l161a5Hz58uHEbHx8f6LM3OEd9QDPxQyjxQyjxQyjxQyjxQyjxQyjn\n/Gvg/Pnz5b60tFTug56lD9PffG/V/8vCwsJa385G4pwfaCZ+CCV+CCV+CCV+CCV+CCV+CLV1vW9g\nM5iYmBjo+qmpqXI/depUuV+5cqVxG/TeBj3nf/r0aeP26dOn8trJyclyP3PmTLlv27at3NN58kMo\n8UMo8UMo8UMo8UMo8UMo8UMo7/PD5uN9fqCZ+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU\n+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CHU\n1hF/3qr+dDAwfJ78EEr8EEr8EEr8EEr8EEr8EEr8EEr8EEr8EEr8EEr8EEr8EEr8EEr8EEr8EEr8\nEEr8EEr8EEr8EEr8EEr8EEr8EEr8EOoPc/veOC9AtlgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7da57dc198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7da1ebaef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(image):\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary,\n",
    "        interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "visualisation_batch = mnist.train.images[:3]\n",
    "o = sess.run([outputs], feed_dict={X: visualisation_batch})\n",
    "o = np.array(o).reshape((-1, n_input_neurons))\n",
    "\n",
    "image_shape = (input_spatial_size, input_spatial_size)\n",
    "for input_data, output_data in zip(visualisation_batch, o):\n",
    "    input_image = input_data.reshape(image_shape)\n",
    "    show_image(input_image)\n",
    "    output_image = output_data.reshape(image_shape)\n",
    "    show_image(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
