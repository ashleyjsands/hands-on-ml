{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 8\n",
    "===\n",
    "Let's create an autoencoder network that pretrains on MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "%autosave 60\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib.layers import batch_norm, dropout\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import tensorflow as tf\n",
    "\n",
    "def he_normal_initialisation(n_inputs, n_outputs):\n",
    "    stddev = np.power(2 / (n_inputs + n_outputs), 1 / np.sqrt(2))\n",
    "    # truncated normal distributions limit the size of the weights, speeding up the training time.\n",
    "    return tf.truncated_normal((n_inputs, n_outputs), stddev=stddev)\n",
    "\n",
    "def he_uniform_initialisation(n_inputs, n_outputs):\n",
    "    r = np.power(6 / (n_inputs + n_outputs), 1 / np.sqrt(2))\n",
    "    # truncated normal distributions limit the size of the weights, speeding up the training time.\n",
    "    return tf.random_uniform((n_inputs, n_outputs), -r, r)\n",
    "\n",
    "def create_next_batch_fn(data, sequence_lengths, targets, batch_size):\n",
    "    assert len(data) == len(sequence_lengths) and len(data) == len(targets)\n",
    "    current_batch = 0\n",
    "    def next_batch():\n",
    "        nonlocal current_batch\n",
    "        i = current_batch\n",
    "        #print(current_batch)\n",
    "        current_batch = (current_batch + batch_size) % len(data)\n",
    "        return data[i:i+batch_size], sequence_lengths[i:i+batch_size], targets[i:i+batch_size]\n",
    "    return next_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "loss: 3.46202\n",
      "loss: 0.774912\n",
      "loss: 0.197912\n",
      "loss: 0.119607\n",
      "loss: 0.0846916\n",
      "loss: 0.0744389\n",
      "loss: 0.0693469\n",
      "loss: 0.0669694\n",
      "loss: 0.0686848\n",
      "loss: 0.0723636\n",
      "loss: 0.0671287\n",
      "loss: 0.066744\n",
      "loss: 0.0644124\n",
      "loss: 0.0642003\n",
      "loss: 0.0643159\n",
      "loss: 0.0590634\n",
      "loss: 0.0591268\n",
      "loss: 0.0567525\n",
      "loss: 0.0778305\n",
      "loss: 0.0559881\n",
      "loss: 0.0573551\n",
      "loss: 0.053682\n",
      "loss: 0.0538345\n",
      "loss: 0.0515822\n",
      "loss: 0.0509879\n",
      "loss: 0.0725925\n",
      "loss: 0.0547677\n",
      "loss: 0.0480727\n",
      "loss: 0.047959\n",
      "loss: 0.0450381\n",
      "loss: 0.0442506\n",
      "loss: 0.047284\n",
      "loss: 0.044283\n",
      "loss: 0.0444851\n",
      "loss: 0.04267\n",
      "loss: 0.0428017\n",
      "loss: 0.0442502\n",
      "loss: 0.0440253\n",
      "loss: 0.044956\n",
      "loss: 0.0472937\n",
      "loss: 0.0436741\n",
      "loss: 0.0433126\n",
      "loss: 0.041423\n",
      "loss: 0.0402948\n",
      "loss: 0.0393124\n",
      "loss: 0.0409192\n",
      "loss: 0.0382778\n",
      "loss: 0.0393489\n",
      "loss: 0.0388688\n",
      "loss: 0.0406533\n",
      "loss: 0.041378\n",
      "loss: 0.0395165\n",
      "loss: 0.0406635\n",
      "loss: 0.0404839\n",
      "loss: 0.0415501\n",
      "loss: 0.0366623\n",
      "loss: 0.0419679\n",
      "loss: 0.0379217\n",
      "loss: 0.0378793\n",
      "loss: 0.0388739\n",
      "loss: 0.0441532\n",
      "loss: 0.0377887\n",
      "loss: 0.0355047\n",
      "loss: 0.0365274\n",
      "loss: 0.0360282\n",
      "loss: 0.0400436\n",
      "loss: 0.0350772\n",
      "loss: 0.0399937\n",
      "loss: 0.0436131\n",
      "epoch 1\n",
      "loss: 0.0407091\n",
      "loss: 0.0382961\n",
      "loss: 0.0343887\n",
      "loss: 0.0350031\n",
      "loss: 0.0349875\n",
      "loss: 0.0456758\n",
      "loss: 0.0382693\n",
      "loss: 0.0369225\n",
      "loss: 0.0347587\n",
      "loss: 0.033992\n",
      "loss: 0.0322401\n",
      "loss: 0.0324866\n",
      "loss: 0.0471862\n",
      "loss: 0.03782\n",
      "loss: 0.0369162\n",
      "loss: 0.0330179\n",
      "loss: 0.0334367\n",
      "loss: 0.0354365\n",
      "loss: 0.0300894\n",
      "loss: 0.0448846\n",
      "loss: 0.0350059\n",
      "loss: 0.0342232\n",
      "loss: 0.0330106\n",
      "loss: 0.0339035\n",
      "loss: 0.0316535\n",
      "loss: 0.0326958\n",
      "loss: 0.0312066\n",
      "loss: 0.0301275\n",
      "loss: 0.0295849\n",
      "loss: 0.0363887\n",
      "loss: 0.0340681\n",
      "loss: 0.0326812\n",
      "loss: 0.030668\n",
      "loss: 0.0326297\n",
      "loss: 0.0305658\n",
      "loss: 0.0293558\n",
      "loss: 0.0283446\n",
      "loss: 0.0387296\n",
      "loss: 0.0324626\n",
      "loss: 0.0300903\n",
      "loss: 0.0309659\n",
      "loss: 0.0316363\n",
      "loss: 0.0287246\n",
      "loss: 0.0297507\n",
      "loss: 0.0281723\n",
      "loss: 0.0319901\n",
      "loss: 0.0282181\n",
      "loss: 0.0291212\n",
      "loss: 0.0295582\n",
      "loss: 0.0282355\n",
      "loss: 0.0287372\n",
      "loss: 0.0279537\n",
      "loss: 0.0289661\n",
      "loss: 0.0304993\n",
      "loss: 0.0297634\n",
      "loss: 0.0329481\n",
      "loss: 0.0312421\n",
      "loss: 0.0313856\n",
      "loss: 0.028868\n",
      "loss: 0.0326176\n",
      "loss: 0.0270147\n",
      "loss: 0.0258178\n",
      "loss: 0.02619\n",
      "loss: 0.0262286\n",
      "loss: 0.0261638\n",
      "loss: 0.0269696\n",
      "loss: 0.0334663\n",
      "loss: 0.0299309\n",
      "loss: 0.0325204\n",
      "epoch 2\n",
      "loss: 0.0311656\n",
      "loss: 0.0283559\n",
      "loss: 0.0256729\n",
      "loss: 0.0255875\n",
      "loss: 0.0277822\n",
      "loss: 0.0294437\n",
      "loss: 0.0277272\n",
      "loss: 0.0256501\n",
      "loss: 0.0257447\n",
      "loss: 0.0251407\n",
      "loss: 0.0242142\n",
      "loss: 0.0269052\n",
      "loss: 0.028554\n",
      "loss: 0.0252435\n",
      "loss: 0.0274936\n",
      "loss: 0.0304227\n",
      "loss: 0.0261266\n",
      "loss: 0.028618\n",
      "loss: 0.0280818\n",
      "loss: 0.0255464\n",
      "loss: 0.0238707\n",
      "loss: 0.0236882\n",
      "loss: 0.0260598\n",
      "loss: 0.0297054\n",
      "loss: 0.0247617\n",
      "loss: 0.0262907\n",
      "loss: 0.0255626\n",
      "loss: 0.0259634\n",
      "loss: 0.0253706\n",
      "loss: 0.0269186\n",
      "loss: 0.0253836\n",
      "loss: 0.0238542\n",
      "loss: 0.0271134\n",
      "loss: 0.0230223\n",
      "loss: 0.0225081\n",
      "loss: 0.0221988\n",
      "loss: 0.0224454\n",
      "loss: 0.02339\n",
      "loss: 0.0255188\n",
      "loss: 0.0228805\n",
      "loss: 0.022706\n",
      "loss: 0.0270216\n",
      "loss: 0.0265649\n",
      "loss: 0.0243428\n",
      "loss: 0.0243808\n",
      "loss: 0.0233581\n",
      "loss: 0.0240223\n",
      "loss: 0.0239678\n",
      "loss: 0.022797\n",
      "loss: 0.0228055\n",
      "loss: 0.0237131\n",
      "loss: 0.0245845\n",
      "loss: 0.0224046\n",
      "loss: 0.0226453\n",
      "loss: 0.0258263\n",
      "loss: 0.0227123\n",
      "loss: 0.0247456\n",
      "loss: 0.0246159\n",
      "loss: 0.0257936\n",
      "loss: 0.0224142\n",
      "loss: 0.0226837\n",
      "loss: 0.0199728\n",
      "loss: 0.0211674\n",
      "loss: 0.0221753\n",
      "loss: 0.0215566\n",
      "loss: 0.0224336\n",
      "loss: 0.0209879\n",
      "loss: 0.021269\n",
      "loss: 0.0243475\n",
      "epoch 3\n",
      "loss: 0.0211145\n",
      "loss: 0.0230008\n",
      "loss: 0.0247163\n",
      "loss: 0.021505\n",
      "loss: 0.0209156\n",
      "loss: 0.0183694\n",
      "loss: 0.0217231\n",
      "loss: 0.0234823\n",
      "loss: 0.0218412\n",
      "loss: 0.0207429\n",
      "loss: 0.0215903\n",
      "loss: 0.0209388\n",
      "loss: 0.0233322\n",
      "loss: 0.0214807\n",
      "loss: 0.0250322\n",
      "loss: 0.0231472\n",
      "loss: 0.0221529\n",
      "loss: 0.0207472\n",
      "loss: 0.0207849\n",
      "loss: 0.0207944\n",
      "loss: 0.0190892\n",
      "loss: 0.0188604\n",
      "loss: 0.0223522\n",
      "loss: 0.0203312\n",
      "loss: 0.0198719\n",
      "loss: 0.0210386\n",
      "loss: 0.0193453\n",
      "loss: 0.0216592\n",
      "loss: 0.0210219\n",
      "loss: 0.0189819\n",
      "loss: 0.0184655\n",
      "loss: 0.0195173\n",
      "loss: 0.0213633\n",
      "loss: 0.0196624\n",
      "loss: 0.0204366\n",
      "loss: 0.0185598\n",
      "loss: 0.0174777\n",
      "loss: 0.0173143\n",
      "loss: 0.0175533\n",
      "loss: 0.0192614\n",
      "loss: 0.0190479\n",
      "loss: 0.0197801\n",
      "loss: 0.0216324\n",
      "loss: 0.0194902\n",
      "loss: 0.0182063\n",
      "loss: 0.0196403\n",
      "loss: 0.0205898\n",
      "loss: 0.01848\n",
      "loss: 0.0188601\n",
      "loss: 0.018308\n",
      "loss: 0.019388\n",
      "loss: 0.0191688\n",
      "loss: 0.0198068\n",
      "loss: 0.0196978\n",
      "loss: 0.0191849\n",
      "loss: 0.0192039\n",
      "loss: 0.0205429\n",
      "loss: 0.021062\n",
      "loss: 0.019551\n",
      "loss: 0.0200575\n",
      "loss: 0.0211543\n",
      "loss: 0.0180708\n",
      "loss: 0.0177305\n",
      "loss: 0.0176154\n",
      "loss: 0.0181698\n",
      "loss: 0.0193974\n",
      "loss: 0.0171402\n",
      "loss: 0.0173878\n",
      "loss: 0.017221\n",
      "epoch 4\n",
      "loss: 0.0172896\n",
      "loss: 0.0180223\n",
      "loss: 0.0176907\n",
      "loss: 0.0176932\n",
      "loss: 0.0167413\n",
      "loss: 0.0245438\n",
      "loss: 0.0215023\n",
      "loss: 0.0217185\n",
      "loss: 0.0240776\n",
      "loss: 0.0197564\n",
      "loss: 0.0179147\n",
      "loss: 0.0167084\n",
      "loss: 0.016306\n",
      "loss: 0.017273\n",
      "loss: 0.0167099\n",
      "loss: 0.0182826\n",
      "loss: 0.017812\n",
      "loss: 0.0174241\n",
      "loss: 0.0173887\n",
      "loss: 0.019392\n",
      "loss: 0.0186266\n",
      "loss: 0.0172622\n",
      "loss: 0.0171191\n",
      "loss: 0.0178302\n",
      "loss: 0.0171632\n",
      "loss: 0.0152222\n",
      "loss: 0.0194505\n",
      "loss: 0.0156709\n",
      "loss: 0.0179766\n",
      "loss: 0.016477\n",
      "loss: 0.0164554\n",
      "loss: 0.0178151\n",
      "loss: 0.01703\n",
      "loss: 0.0153018\n",
      "loss: 0.0164828\n",
      "loss: 0.0178162\n",
      "loss: 0.0164022\n",
      "loss: 0.0172759\n",
      "loss: 0.0187004\n",
      "loss: 0.0173911\n",
      "loss: 0.0168905\n",
      "loss: 0.0163967\n",
      "loss: 0.0182653\n",
      "loss: 0.0155782\n",
      "loss: 0.0190386\n",
      "loss: 0.0173034\n",
      "loss: 0.0166101\n",
      "loss: 0.0184159\n",
      "loss: 0.0161345\n",
      "loss: 0.0198351\n",
      "loss: 0.0169454\n",
      "loss: 0.0158861\n",
      "loss: 0.0169238\n",
      "loss: 0.0152437\n",
      "loss: 0.0164464\n",
      "loss: 0.0175276\n",
      "loss: 0.0153918\n",
      "loss: 0.0158098\n",
      "loss: 0.0155092\n",
      "loss: 0.0160539\n",
      "loss: 0.0164006\n",
      "loss: 0.0170776\n",
      "loss: 0.0157652\n",
      "loss: 0.0155263\n",
      "loss: 0.015022\n",
      "loss: 0.0158903\n",
      "loss: 0.0166738\n",
      "loss: 0.0152016\n",
      "loss: 0.0153795\n",
      "epoch 5\n",
      "loss: 0.0151354\n",
      "loss: 0.0147099\n",
      "loss: 0.0188316\n",
      "loss: 0.0169934\n",
      "loss: 0.0173325\n",
      "loss: 0.0162523\n",
      "loss: 0.016536\n",
      "loss: 0.0164387\n",
      "loss: 0.0162\n",
      "loss: 0.0157935\n",
      "loss: 0.0142352\n",
      "loss: 0.0157544\n",
      "loss: 0.0177051\n",
      "loss: 0.0164125\n",
      "loss: 0.0169733\n",
      "loss: 0.0176337\n",
      "loss: 0.0187262\n",
      "loss: 0.0172085\n",
      "loss: 0.0168084\n",
      "loss: 0.0166524\n",
      "loss: 0.0157697\n",
      "loss: 0.014123\n",
      "loss: 0.0169201\n",
      "loss: 0.0156009\n",
      "loss: 0.0171829\n",
      "loss: 0.0147286\n",
      "loss: 0.0157516\n",
      "loss: 0.0153531\n",
      "loss: 0.0213516\n",
      "loss: 0.0194881\n",
      "loss: 0.0162635\n",
      "loss: 0.0184122\n",
      "loss: 0.0142734\n",
      "loss: 0.0151508\n",
      "loss: 0.0138508\n",
      "loss: 0.0153143\n",
      "loss: 0.0155619\n",
      "loss: 0.0142099\n",
      "loss: 0.0158284\n",
      "loss: 0.0158226\n",
      "loss: 0.0147084\n",
      "loss: 0.0146736\n",
      "loss: 0.0157745\n",
      "loss: 0.0187411\n",
      "loss: 0.0158078\n",
      "loss: 0.0146568\n",
      "loss: 0.0138689\n",
      "loss: 0.0155995\n",
      "loss: 0.0138417\n",
      "loss: 0.0183266\n",
      "loss: 0.015548\n",
      "loss: 0.0182986\n",
      "loss: 0.0145058\n",
      "loss: 0.0164434\n",
      "loss: 0.0154705\n",
      "loss: 0.0150262\n",
      "loss: 0.0147034\n",
      "loss: 0.0138369\n",
      "loss: 0.0175002\n",
      "loss: 0.0161961\n",
      "loss: 0.0156454\n",
      "loss: 0.0147316\n",
      "loss: 0.0142277\n",
      "loss: 0.0167476\n",
      "loss: 0.0149784\n",
      "loss: 0.0136629\n",
      "loss: 0.0150907\n",
      "loss: 0.0168556\n",
      "loss: 0.0179652\n",
      "epoch 6\n",
      "loss: 0.0188634\n",
      "loss: 0.0151373\n",
      "loss: 0.0208598\n",
      "loss: 0.0177962\n",
      "loss: 0.0206876\n",
      "loss: 0.017575\n",
      "loss: 0.0155729\n",
      "loss: 0.0173832\n",
      "loss: 0.016845\n",
      "loss: 0.0172869\n",
      "loss: 0.0157354\n",
      "loss: 0.0155131\n",
      "loss: 0.0150586\n",
      "loss: 0.0144988\n",
      "loss: 0.015924\n",
      "loss: 0.0157347\n",
      "loss: 0.016158\n",
      "loss: 0.0148261\n",
      "loss: 0.0138204\n",
      "loss: 0.0152233\n",
      "loss: 0.0151481\n",
      "loss: 0.0155421\n",
      "loss: 0.0138009\n",
      "loss: 0.0152098\n",
      "loss: 0.015917\n",
      "loss: 0.0149289\n",
      "loss: 0.0170905\n",
      "loss: 0.0170532\n",
      "loss: 0.0179729\n",
      "loss: 0.0171517\n",
      "loss: 0.0157495\n",
      "loss: 0.0166431\n",
      "loss: 0.0141293\n",
      "loss: 0.0152457\n",
      "loss: 0.016504\n",
      "loss: 0.0159756\n",
      "loss: 0.0146788\n",
      "loss: 0.0138286\n",
      "loss: 0.0137659\n",
      "loss: 0.0144723\n",
      "loss: 0.0151993\n",
      "loss: 0.0153667\n",
      "loss: 0.0143221\n",
      "loss: 0.0137527\n",
      "loss: 0.0159012\n",
      "loss: 0.0159648\n",
      "loss: 0.0152852\n",
      "loss: 0.0139567\n",
      "loss: 0.0159733\n",
      "loss: 0.0137853\n",
      "loss: 0.0151653\n",
      "loss: 0.0152179\n",
      "loss: 0.0159727\n",
      "loss: 0.0154558\n",
      "loss: 0.0189008\n",
      "loss: 0.0203751\n",
      "loss: 0.0214189\n",
      "loss: 0.0678748\n",
      "loss: 502.939\n",
      "loss: 10.3492\n",
      "loss: 3.19448\n",
      "loss: 2.55828\n",
      "loss: 1.10743\n",
      "loss: 0.257465\n",
      "loss: 0.126005\n",
      "loss: 0.113243\n",
      "loss: 0.0832035\n",
      "loss: 0.0702467\n",
      "loss: 0.074685\n",
      "epoch 7\n",
      "loss: 0.0645067\n",
      "loss: 0.0707557\n",
      "loss: 0.0680398\n",
      "loss: 0.0665096\n",
      "loss: 0.0699509\n",
      "loss: 0.0695245\n",
      "loss: 0.0701184\n",
      "loss: 0.06936\n",
      "loss: 0.0684772\n",
      "loss: 0.0678305\n",
      "loss: 0.0674708\n",
      "loss: 0.0681106\n",
      "loss: 0.0684807\n",
      "loss: 0.0723525\n",
      "loss: 0.0698208\n",
      "loss: 0.0680246\n",
      "loss: 0.0677414\n",
      "loss: 0.0681407\n",
      "loss: 0.0693918\n",
      "loss: 0.0702996\n",
      "loss: 0.0671461\n",
      "loss: 0.0691269\n",
      "loss: 0.0642217\n",
      "loss: 0.066661\n",
      "loss: 0.0665616\n",
      "loss: 0.064988\n",
      "loss: 0.0680507\n",
      "loss: 0.0707856\n",
      "loss: 0.0672002\n",
      "loss: 0.0661192\n",
      "loss: 0.0676299\n",
      "loss: 0.0665748\n",
      "loss: 0.0645013\n",
      "loss: 0.0642884\n",
      "loss: 0.0685267\n",
      "loss: 0.0713323\n",
      "loss: 0.0703674\n",
      "loss: 0.0633573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0723253\n",
      "loss: 0.0639918\n",
      "loss: 0.0681336\n",
      "loss: 0.065748\n",
      "loss: 0.0683483\n",
      "loss: 0.0673958\n",
      "loss: 0.0646077\n",
      "loss: 0.0663698\n",
      "loss: 0.0690931\n",
      "loss: 0.0709549\n",
      "loss: 0.069353\n",
      "loss: 0.0661581\n",
      "loss: 0.0678058\n",
      "loss: 0.0716743\n",
      "loss: 0.0667922\n",
      "loss: 0.0665251\n",
      "loss: 0.0701909\n",
      "loss: 0.0683281\n",
      "loss: 0.0724002\n",
      "loss: 0.0705931\n",
      "loss: 0.0745938\n",
      "loss: 0.0672026\n",
      "loss: 0.0667762\n",
      "loss: 0.0697574\n",
      "loss: 0.0697561\n",
      "loss: 0.0666261\n",
      "loss: 0.0705352\n",
      "loss: 0.0667206\n",
      "loss: 0.0703752\n",
      "loss: 0.0683686\n",
      "loss: 0.0675117\n",
      "epoch 8\n",
      "loss: 0.0703504\n",
      "loss: 0.0698116\n",
      "loss: 0.0700259\n",
      "loss: 0.0670234\n",
      "loss: 0.0687594\n",
      "loss: 0.0664144\n",
      "loss: 0.0670573\n",
      "loss: 0.0712513\n",
      "loss: 0.065425\n",
      "loss: 0.0684249\n",
      "loss: 0.070315\n",
      "loss: 0.072542\n",
      "loss: 0.0682747\n",
      "loss: 0.0678954\n",
      "loss: 0.0671698\n",
      "loss: 0.0715893\n",
      "loss: 0.0686307\n",
      "loss: 0.073184\n",
      "loss: 0.0664765\n",
      "loss: 0.0695393\n",
      "loss: 0.0643383\n",
      "loss: 0.0681753\n",
      "loss: 0.0674178\n",
      "loss: 0.0666166\n",
      "loss: 0.0648123\n",
      "loss: 0.068281\n",
      "loss: 0.0648802\n",
      "loss: 0.065208\n",
      "loss: 0.0644301\n",
      "loss: 0.071197\n",
      "loss: 0.0662013\n",
      "loss: 0.0713176\n",
      "loss: 0.0689799\n",
      "loss: 0.0671732\n",
      "loss: 0.069159\n",
      "loss: 0.0624589\n",
      "loss: 0.0654072\n",
      "loss: 0.071947\n",
      "loss: 0.0704971\n",
      "loss: 0.0699236\n",
      "loss: 0.0719162\n",
      "loss: 0.0676637\n",
      "loss: 0.0668845\n",
      "loss: 0.0706861\n",
      "loss: 0.0699012\n",
      "loss: 0.0671444\n",
      "loss: 0.0695113\n",
      "loss: 0.064124\n",
      "loss: 0.0664074\n",
      "loss: 0.0675888\n",
      "loss: 0.0687756\n",
      "loss: 0.0718343\n",
      "loss: 0.0671383\n",
      "loss: 0.0642892\n",
      "loss: 0.0655087\n",
      "loss: 0.068597\n",
      "loss: 0.067197\n",
      "loss: 0.0694028\n",
      "loss: 0.0691268\n",
      "loss: 0.0741669\n",
      "loss: 0.0651471\n",
      "loss: 0.069704\n",
      "loss: 0.0661437\n",
      "loss: 0.0706939\n",
      "loss: 0.0703013\n",
      "loss: 0.0700854\n",
      "loss: 0.0679747\n",
      "loss: 0.0668891\n",
      "loss: 0.0670482\n",
      "epoch 9\n",
      "loss: 0.0654403\n",
      "loss: 0.0677615\n",
      "loss: 0.0669593\n",
      "loss: 0.069925\n",
      "loss: 0.0759778\n",
      "loss: 0.0708448\n",
      "loss: 0.0696733\n",
      "loss: 0.0665824\n",
      "loss: 0.0666729\n",
      "loss: 0.0664194\n",
      "loss: 0.0686634\n",
      "loss: 0.0683275\n",
      "loss: 0.0690543\n",
      "loss: 0.0711338\n",
      "loss: 0.0625656\n",
      "loss: 0.0677012\n",
      "loss: 0.0712499\n",
      "loss: 0.0683666\n",
      "loss: 0.0691232\n",
      "loss: 0.073622\n",
      "loss: 0.067717\n",
      "loss: 0.0678266\n",
      "loss: 0.0676927\n",
      "loss: 0.0682304\n",
      "loss: 0.0706732\n",
      "loss: 0.0657537\n",
      "loss: 0.0670285\n",
      "loss: 0.0685322\n",
      "loss: 0.0693945\n",
      "loss: 0.0682429\n",
      "loss: 0.0704111\n",
      "loss: 0.0714389\n",
      "loss: 0.0662872\n",
      "loss: 0.0690067\n",
      "loss: 0.0657413\n",
      "Stopping early during epoch 9 with best loss: 0.0141464\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/mnist_autoencoder_model_early_stopping.ckpt\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "input_spatial_size = 28\n",
    "input_channels = 1\n",
    "batch_size = 80\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_input_neurons = input_spatial_size ** 2\n",
    "n_hidden_neurons_layer1 = 250\n",
    "n_hidden_neurons_layer2 = 150\n",
    "n_hidden_neurons_layer3 = n_hidden_neurons_layer1\n",
    "n_output_neurons = n_input_neurons\n",
    "l2_reg = 0.0001\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_input_neurons), name=\"input\")\n",
    "    noisy_X = X + tf.random_normal(tf.shape(X), mean=0.1, stddev=0.1)\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    l2_regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "    from functools import partial\n",
    "    my_dense_layer = partial(tf.layers.dense,\n",
    "                             activation=tf.nn.elu,\n",
    "                             kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(noisy_X, n_hidden_neurons_layer1)\n",
    "    hidden2 = my_dense_layer(hidden1, n_hidden_neurons_layer2)\n",
    "    hidden3 = my_dense_layer(hidden2, n_hidden_neurons_layer3)\n",
    "    outputs = my_dense_layer(hidden3, n_output_neurons, activation=None)\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        reconstruction_loss = tf.reduce_mean(tf.square(outputs - X), name=\"reconstruction_loss\")\n",
    "        #regularisation_loss = regularizer(weights1) + regularizer(weights2) \\\n",
    "        #    + regularizer(weights3) + regularizer(weights4)\n",
    "        #regularisation_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        loss = reconstruction_loss# + regularisation_loss\n",
    "\n",
    "    with tf.name_scope(\"training\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "interim_checkpoint_path = \"./checkpoints/mnist_autoencoder_model.ckpt\"\n",
    "early_stopping_checkpoint_path = \"./checkpoints/mnist_autoencoder_model_early_stopping.ckpt\"\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "log_dir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "summary_op = tf.summary.merge([loss_summary])\n",
    "file_writer = tf.summary.FileWriter(log_dir, tf.get_default_graph())\n",
    "\n",
    "epochs = 20\n",
    "n_batches = int(np.ceil(len(mnist.train.images) // batch_size))\n",
    "\n",
    "early_stopping_check_frequency = n_batches // 4\n",
    "early_stopping_check_limit = n_batches * 3\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "session = sess\n",
    "sess.run(init)\n",
    "#saver.restore(sess, interim_checkpoint_path)\n",
    "\n",
    "best_loss = 1000000000.0\n",
    "best_loss_step = 0\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch\", epoch)\n",
    "    for batch_index in range(n_batches):\n",
    "        step = epoch * n_batches + batch_index\n",
    "        # TODO: replace this with code that gets a batch from X and y.\n",
    "        X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "        if batch_index % 10 == 0:\n",
    "            summary_str = summary_op.eval(session=sess, feed_dict={X: X_batch})\n",
    "            file_writer.add_summary(summary_str, step)\n",
    "        t = sess.run([training_op], feed_dict={X: X_batch})\n",
    "        l = sess.run(reconstruction_loss, feed_dict={X: X_batch})\n",
    "        if batch_index % 10 == 0: print(\"loss:\", l)\n",
    "        # Early stopping check\n",
    "        if batch_index % early_stopping_check_frequency == 0:\n",
    "            if l < best_loss:\n",
    "                saver.save(sess, early_stopping_checkpoint_path)\n",
    "                best_loss = l\n",
    "                best_loss_step = step\n",
    "            elif step >= (best_loss_step + early_stopping_check_limit):\n",
    "                print(\"Stopping early during epoch\", epoch, \"with best loss:\", best_loss)\n",
    "                break\n",
    "    else:\n",
    "        continue\n",
    "    break\n",
    "    save_path = saver.save(sess, interim_checkpoint_path)\n",
    "saver.restore(sess, early_stopping_checkpoint_path)\n",
    "save_path = saver.save(sess, \"./checkpoints/mnist_autoencoder_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABXZJREFUeJzt3L1qFF4egOHNRv9BEMRCO20l4Cd4A4qtNkIaO/EerKxs\nvARJIVhaWPjRKLaCoKiYYGmphZVFwPjB7BXMMTuzSdy8z9P+5pwzzcspTiYLk8nkX0DPv3f7CwC7\nQ/wQJX6IEj9EiR+ixA9R4oco8UOU+CFq3w6f588JYfstbOVDbn6IEj9EiR+ixA9R4oco8UOU+CFK\n/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+i\nxA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPgh\nSvwQJX6IEj9EiR+ixA9R4oeofbv9Bf4WP378GM6Xlpa27exLly4N58vLy9t29m56+fLlcP727dvh\n/NSpU8P5u3fvps4WFxeHawvc/BAlfogSP0SJH6LED1HihyjxQ9TCZDLZyfN29LD/xq9fv4bzq1ev\nTp19+fJluPbNmzczfSfms7m5OXW2f//+HfwmO25hKx9y80OU+CFK/BAlfogSP0SJH6LED1He+f8H\nNjY2hvPPnz8P56urq3OdP3rPfvTo0XDtysrKXGf/yfr6+tTZs2fP5tr77Nmzw/nr16+nzvb47/m9\n8wPTiR+ixA9R4oco8UOU+CFK/BDlnZ9tde/evamzGzduzLX3hw8fhvOTJ0/Otf//Me/8wHTihyjx\nQ5T4IUr8ECV+iBI/RO3b7S/A3vbp06eZ1x45cmQ4P3To0Mx74+aHLPFDlPghSvwQJX6IEj9Eeepj\nLr9//x7Onz59OvPe586dG86PHTs28964+SFL/BAlfogSP0SJH6LED1Hihyjv/Mzl8ePHw/no32v/\n888/w7U3b96c6TuxNW5+iBI/RIkfosQPUeKHKPFDlPghyjs/c3nw4MHMa48ePTqcX7hwYea9+TM3\nP0SJH6LED1HihyjxQ5T4IUr8EOWdn6GNjY3h/OPHjzPvff78+ZnXMj83P0SJH6LED1HihyjxQ5T4\nIUr8EOWdn6G7d+8O5+vr6zPvfeXKlZnXMj83P0SJH6LED1HihyjxQ5T4IWphMpns5Hk7ehjzO3z4\n8HD+7du34Xz0nPfw4cPh2sXFxeGcqRa28iE3P0SJH6LED1HihyjxQ5T4IUr8EOUnvXHv378fzr9/\n/z7X/sePH586846/u9z8ECV+iBI/RIkfosQPUeKHKPFDlHf+uOfPnw/nm5ubc+1//fr1udazfdz8\nECV+iBI/RIkfosQPUeKHKPFDlHf+PW5tbW04v3379lz7X7t2bTg/ceLEXPuzfdz8ECV+iBI/RIkf\nosQPUeKHKE99e9zXr1+H842NjeH8T/9ee2VlZTg/cODAcM7ucfNDlPghSvwQJX6IEj9EiR+ixA9R\n3vn3gJ8/f06d3blzZ669T58+PZxfvnx5rv3ZPW5+iBI/RIkfosQPUeKHKPFDlPghyjv/HvDq1aup\nsxcvXsy1961bt+Zaz9/LzQ9R4oco8UOU+CFK/BAlfogSP0R5598Dnjx5MvPagwcPDucXL16ceW/+\nbm5+iBI/RIkfosQPUeKHKPFDlPghyjv/HnD//v2Z1y4vLw/nS0tLM+/N383ND1HihyjxQ5T4IUr8\nECV+iPLUtwecOXNm6mxtbW24dnV1dTj31Ld3ufkhSvwQJX6IEj9EiR+ixA9R4oeohclkspPn7ehh\nELWwlQ+5+SFK/BAlfogSP0SJH6LED1Hih6id/j3/lt4fge3n5oco8UOU+CFK/BAlfogSP0SJH6LE\nD1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+i/gNiYJ7bWH2tiwAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08ad37c400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUIQfCEX4gVCEHwj1Dzohkze84bRPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f093aa56908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABMFJREFUeJzt3bFOVFsUgOE7NybYEhqx08pIQ/QVMDaWlsbETiqfwheg\nINBMo29h9BkoTCjp1MZArE3mFreeDQicMfzf166ZnN38WcXmDLPFYvEP0PPvqg8ArIb4IUr8ECV+\niBI/RIkfosQPUeKHKPFD1J2Jn+fPCeHmzS7yIZsfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R\n4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQ\nJX6IEj9EiR+ixA9R4oco8UOU+CFK/BB1Z9UH4Op+/PixdLa5uTn87suXL4fzjx8/Dudra2vDOX8v\nmx+ixA9R4oco8UOU+CFK/BAlfoiaLRaLKZ836cMqfv78uXT28OHD4Xd//fo1nB8fHw/njx49Gs5Z\nidlFPmTzQ5T4IUr8ECV+iBI/RIkfolz13XJ7e3vD+bt374bzN2/eDOfz+fzSZ+LGueoDlhM/RIkf\nosQPUeKHKPFDlPghyk9333JPnjwZzh88eDCcf/nyZTg/PT0dztfX14dzVsfmhyjxQ5T4IUr8ECV+\niBI/RIkforzPH/f69evh/MOHD8P5/v7+cL67u3vpM3Fl3ucHlhM/RIkfosQPUeKHKPFDlPghyvv8\nXMnJycmqj8AfsvkhSvwQJX6IEj9EiR+ixA9R4oco9/xxjx8/XvURWBGbH6LED1HihyjxQ5T4IUr8\nEOWqL+68f+HN7WXzQ5T4IUr8ECV+iBI/RIkfosQPUe754zY2NobztbW1iU7C1Gx+iBI/RIkfosQP\nUeKHKPFDlPghyj1/3NOnT4fz9fX1iU7C1Gx+iBI/RIkfosQPUeKHKPFDlPgharZYLKZ83qQP43zf\nvn0bzre2tobze/fuDefHx8eXPhNXNrvIh2x+iBI/RIkfosQPUeKHKPFDlPghyvv8cffv3x/O7969\nO5yfnZ1d53GYkM0PUeKHKPFDlPghSvwQJX6IctXH0Hmv7B4dHQ3nnz59Wjp79uzZH52J62HzQ5T4\nIUr8ECV+iBI/RIkfosQPUe75GdrZ2RnOz7vn5+9l80OU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4\nIUr8ECV+iBI/RIkfosQPUd7n50Z9/vx56czv9q+WzQ9R4oco8UOU+CFK/BAlfohy1cfQ8+fPh/PD\nw8Ph/Pv379d5HK6RzQ9R4oco8UOU+CFK/BAlfogSP0TNFovFlM+b9GHcvO3t7eH89+/fS2dfv369\n7uPwv9lFPmTzQ5T4IUr8ECV+iBI/RIkfosQPUd7n50pevHgxnL9//37p7O3bt8PvHhwc/NGZuBib\nH6LED1HihyjxQ5T4IUr8ECV+iHLPz5W8evVqOJ/P50tns9mFXjvnhtj8ECV+iBI/RIkfosQPUeKH\nKPFDlN/th9vH7/YDy4kfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogS\nP0SJH6LED1HihyjxQ5T4IWrqf9HtfzLDX8LmhyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPgh\nSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6L+A3TTbOXIJo9IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08c1560710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKmX4pVKGXypl+KVShl8q9RcXfmXyGBFPbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08ad3c31d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0861b3d828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0860799e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(image):\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary,\n",
    "        interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "visualisation_batch = mnist.train.images[:3]\n",
    "o = sess.run([outputs], feed_dict={X: visualisation_batch})\n",
    "o = np.array(o).reshape((-1, n_input_neurons))\n",
    "\n",
    "image_shape = (input_spatial_size, input_spatial_size)\n",
    "for input_data, output_data in zip(visualisation_batch, o):\n",
    "    input_image = input_data.reshape(image_shape)\n",
    "    show_image(input_image)\n",
    "    output_image = output_data.reshape(image_shape)\n",
    "    show_image(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
