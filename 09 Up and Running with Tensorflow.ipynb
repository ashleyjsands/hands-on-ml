{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x * x * y + y + 2\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "print(x2.graph is graph)\n",
    "print(x2.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "moon_X, moon_y = make_moons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moon_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moon_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moon_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(w, b, x):\n",
    "    with tf.name_scope(\"logistric_regression\") as scope:\n",
    "        weighted_input_plus_bias = w * x + b\n",
    "        sigmoid = 1 / (1 + tf.exp(-weighted_input_plus_bias))\n",
    "        return sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_features = moon_X.shape[1]\n",
    "w = tf.Variable(tf.random_normal([number_of_features], name=\"weights\"))\n",
    "b = tf.Variable(0.0, name=\"bias\")\n",
    "x = tf.placeholder(tf.float32, shape=(None, number_of_features), name=\"input\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "output = logistic_regression(w, b, x)\n",
    "\n",
    "error = output - y\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.2)\n",
    "training_op = optimizer.minimize(mse)\n",
    "correctness = tf.reduce_mean(tf.cast(tf.abs(error) < 0.1, tf.float32)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.197826\n",
      "Mean squared error: 0.191941\n",
      "Mean squared error: 0.187382\n",
      "Mean squared error: 0.183767\n",
      "Mean squared error: 0.180841\n",
      "Mean squared error: 0.178429\n",
      "Mean squared error: 0.17641\n",
      "Mean squared error: 0.174695\n",
      "Mean squared error: 0.173222\n",
      "Mean squared error: 0.171943\n",
      "Mean squared error: 0.170823\n",
      "Mean squared error: 0.169834\n",
      "Mean squared error: 0.168956\n",
      "Mean squared error: 0.168173\n",
      "Mean squared error: 0.167469\n",
      "Mean squared error: 0.166836\n",
      "Mean squared error: 0.166264\n",
      "Mean squared error: 0.165746\n",
      "Mean squared error: 0.165276\n",
      "Mean squared error: 0.164849\n",
      "Mean squared error: 0.16446\n",
      "Mean squared error: 0.164106\n",
      "Mean squared error: 0.163784\n",
      "Mean squared error: 0.16349\n",
      "Mean squared error: 0.163223\n",
      "Mean squared error: 0.162979\n",
      "Mean squared error: 0.162757\n",
      "Mean squared error: 0.162556\n",
      "Mean squared error: 0.162373\n",
      "Mean squared error: 0.162207\n",
      "Mean squared error: 0.162057\n",
      "Mean squared error: 0.161922\n",
      "Mean squared error: 0.1618\n",
      "Mean squared error: 0.161691\n",
      "Mean squared error: 0.161594\n",
      "Mean squared error: 0.161507\n",
      "Mean squared error: 0.161431\n",
      "Mean squared error: 0.161364\n",
      "Mean squared error: 0.161306\n",
      "Mean squared error: 0.161256\n",
      "Mean squared error: 0.161213\n",
      "Mean squared error: 0.161178\n",
      "Mean squared error: 0.161149\n",
      "Mean squared error: 0.161127\n",
      "Mean squared error: 0.16111\n",
      "Mean squared error: 0.161098\n",
      "Mean squared error: 0.161092\n",
      "Mean squared error: 0.16109\n",
      "Mean squared error: 0.161093\n",
      "Mean squared error: 0.161099\n",
      "Mean squared error: 0.16111\n",
      "Mean squared error: 0.161124\n",
      "Mean squared error: 0.161141\n",
      "Mean squared error: 0.161161\n",
      "Mean squared error: 0.161185\n",
      "Mean squared error: 0.16121\n",
      "Mean squared error: 0.161239\n",
      "Mean squared error: 0.16127\n",
      "Mean squared error: 0.161303\n",
      "Mean squared error: 0.161337\n",
      "Mean squared error: 0.161374\n",
      "Mean squared error: 0.161413\n",
      "Mean squared error: 0.161453\n",
      "Mean squared error: 0.161495\n",
      "Mean squared error: 0.161538\n",
      "Mean squared error: 0.161582\n",
      "Mean squared error: 0.161628\n",
      "Mean squared error: 0.161674\n",
      "Mean squared error: 0.161722\n",
      "Mean squared error: 0.16177\n",
      "Mean squared error: 0.16182\n",
      "Mean squared error: 0.16187\n",
      "Mean squared error: 0.161921\n",
      "Mean squared error: 0.161973\n",
      "Mean squared error: 0.162025\n",
      "Mean squared error: 0.162078\n",
      "Mean squared error: 0.162131\n",
      "Mean squared error: 0.162185\n",
      "Mean squared error: 0.162239\n",
      "Mean squared error: 0.162293\n",
      "Mean squared error: 0.162348\n",
      "Mean squared error: 0.162403\n",
      "Mean squared error: 0.162458\n",
      "Mean squared error: 0.162514\n",
      "Mean squared error: 0.162569\n",
      "Mean squared error: 0.162625\n",
      "Mean squared error: 0.162681\n",
      "Mean squared error: 0.162737\n",
      "Mean squared error: 0.162793\n",
      "Mean squared error: 0.162849\n",
      "Mean squared error: 0.162905\n",
      "Mean squared error: 0.162961\n",
      "Mean squared error: 0.163017\n",
      "Mean squared error: 0.163073\n",
      "Mean squared error: 0.163129\n",
      "Mean squared error: 0.163185\n",
      "Mean squared error: 0.16324\n",
      "Mean squared error: 0.163296\n",
      "Mean squared error: 0.163351\n",
      "Mean squared error: 0.163407\n",
      "Mean squared error: 0.163462\n",
      "Mean squared error: 0.163517\n",
      "Mean squared error: 0.163572\n",
      "Mean squared error: 0.163627\n",
      "Mean squared error: 0.163681\n",
      "Mean squared error: 0.163735\n",
      "Mean squared error: 0.163789\n",
      "Mean squared error: 0.163843\n",
      "Mean squared error: 0.163897\n",
      "Mean squared error: 0.16395\n",
      "Mean squared error: 0.164003\n",
      "Mean squared error: 0.164056\n",
      "Mean squared error: 0.164109\n",
      "Mean squared error: 0.164161\n",
      "Mean squared error: 0.164214\n",
      "Mean squared error: 0.164266\n",
      "Mean squared error: 0.164317\n",
      "Mean squared error: 0.164369\n",
      "Mean squared error: 0.16442\n",
      "Mean squared error: 0.164471\n",
      "Mean squared error: 0.164521\n",
      "Mean squared error: 0.164572\n",
      "Mean squared error: 0.164622\n",
      "Mean squared error: 0.164671\n",
      "Mean squared error: 0.164721\n",
      "Mean squared error: 0.16477\n",
      "Mean squared error: 0.164819\n",
      "Mean squared error: 0.164868\n",
      "Mean squared error: 0.164916\n",
      "Mean squared error: 0.164964\n",
      "Mean squared error: 0.165012\n",
      "Mean squared error: 0.165059\n",
      "Mean squared error: 0.165107\n",
      "Mean squared error: 0.165154\n",
      "Mean squared error: 0.1652\n",
      "Mean squared error: 0.165247\n",
      "Mean squared error: 0.165293\n",
      "Mean squared error: 0.165339\n",
      "Mean squared error: 0.165384\n",
      "Mean squared error: 0.165429\n",
      "Mean squared error: 0.165474\n",
      "Mean squared error: 0.165519\n",
      "Mean squared error: 0.165563\n",
      "Mean squared error: 0.165608\n",
      "Mean squared error: 0.165651\n",
      "Mean squared error: 0.165695\n",
      "Mean squared error: 0.165738\n",
      "Mean squared error: 0.165781\n",
      "Mean squared error: 0.165824\n",
      "Mean squared error: 0.165867\n",
      "Mean squared error: 0.165909\n",
      "Mean squared error: 0.165951\n",
      "Mean squared error: 0.165993\n",
      "Mean squared error: 0.166034\n",
      "Mean squared error: 0.166075\n",
      "Mean squared error: 0.166116\n",
      "Mean squared error: 0.166157\n",
      "Mean squared error: 0.166197\n",
      "Mean squared error: 0.166237\n",
      "Mean squared error: 0.166277\n",
      "Mean squared error: 0.166316\n",
      "Mean squared error: 0.166356\n",
      "Mean squared error: 0.166395\n",
      "Mean squared error: 0.166434\n",
      "Mean squared error: 0.166472\n",
      "Mean squared error: 0.166511\n",
      "Mean squared error: 0.166549\n",
      "Mean squared error: 0.166587\n",
      "Mean squared error: 0.166624\n",
      "Mean squared error: 0.166661\n",
      "Mean squared error: 0.166699\n",
      "Mean squared error: 0.166735\n",
      "Mean squared error: 0.166772\n",
      "Mean squared error: 0.166808\n",
      "Mean squared error: 0.166845\n",
      "Mean squared error: 0.166881\n",
      "Mean squared error: 0.166916\n",
      "Mean squared error: 0.166952\n",
      "Mean squared error: 0.166987\n",
      "Mean squared error: 0.167022\n",
      "Mean squared error: 0.167057\n",
      "Mean squared error: 0.167091\n",
      "Mean squared error: 0.167126\n",
      "Mean squared error: 0.16716\n",
      "Mean squared error: 0.167194\n",
      "Mean squared error: 0.167227\n",
      "Mean squared error: 0.167261\n",
      "Mean squared error: 0.167294\n",
      "Mean squared error: 0.167327\n",
      "Mean squared error: 0.16736\n",
      "Mean squared error: 0.167393\n",
      "Mean squared error: 0.167425\n",
      "Mean squared error: 0.167457\n",
      "Mean squared error: 0.167489\n",
      "Mean squared error: 0.167521\n",
      "Mean squared error: 0.167553\n",
      "Mean squared error: 0.167584\n",
      "Mean squared error: 0.167615\n",
      "Mean squared error: 0.167646\n",
      "Mean squared error: 0.167677\n",
      "Mean squared error: 0.167708\n",
      "Mean squared error: 0.167738\n",
      "Mean squared error: 0.167768\n",
      "Mean squared error: 0.167798\n",
      "Mean squared error: 0.167828\n",
      "Mean squared error: 0.167858\n",
      "Mean squared error: 0.167887\n",
      "Mean squared error: 0.167917\n",
      "Mean squared error: 0.167946\n",
      "Mean squared error: 0.167975\n",
      "Mean squared error: 0.168004\n",
      "Mean squared error: 0.168032\n",
      "Mean squared error: 0.168061\n",
      "Mean squared error: 0.168089\n",
      "Mean squared error: 0.168117\n",
      "Mean squared error: 0.168145\n",
      "Mean squared error: 0.168173\n",
      "Mean squared error: 0.1682\n",
      "Mean squared error: 0.168227\n",
      "Mean squared error: 0.168255\n",
      "Mean squared error: 0.168282\n",
      "Mean squared error: 0.168309\n",
      "Mean squared error: 0.168335\n",
      "Mean squared error: 0.168362\n",
      "Mean squared error: 0.168388\n",
      "Mean squared error: 0.168414\n",
      "Mean squared error: 0.16844\n",
      "Mean squared error: 0.168466\n",
      "Mean squared error: 0.168492\n",
      "Mean squared error: 0.168518\n",
      "Mean squared error: 0.168543\n",
      "Mean squared error: 0.168568\n",
      "Mean squared error: 0.168594\n",
      "Mean squared error: 0.168619\n",
      "Mean squared error: 0.168643\n",
      "Mean squared error: 0.168668\n",
      "Mean squared error: 0.168693\n",
      "Mean squared error: 0.168717\n",
      "Mean squared error: 0.168741\n",
      "Mean squared error: 0.168765\n",
      "Mean squared error: 0.168789\n",
      "Mean squared error: 0.168813\n",
      "Mean squared error: 0.168837\n",
      "Mean squared error: 0.16886\n",
      "Mean squared error: 0.168884\n",
      "Mean squared error: 0.168907\n",
      "Mean squared error: 0.16893\n",
      "Mean squared error: 0.168953\n",
      "Mean squared error: 0.168976\n",
      "Mean squared error: 0.168999\n",
      "Mean squared error: 0.169021\n",
      "Mean squared error: 0.169044\n",
      "Mean squared error: 0.169066\n",
      "Mean squared error: 0.169088\n",
      "Mean squared error: 0.16911\n",
      "Mean squared error: 0.169132\n",
      "Mean squared error: 0.169154\n",
      "Mean squared error: 0.169176\n",
      "Mean squared error: 0.169197\n",
      "Mean squared error: 0.169219\n",
      "Mean squared error: 0.16924\n",
      "Mean squared error: 0.169261\n",
      "Mean squared error: 0.169282\n",
      "Mean squared error: 0.169303\n",
      "Mean squared error: 0.169324\n",
      "Mean squared error: 0.169345\n",
      "Mean squared error: 0.169365\n",
      "Mean squared error: 0.169386\n",
      "Mean squared error: 0.169406\n",
      "Mean squared error: 0.169426\n",
      "Mean squared error: 0.169446\n",
      "Mean squared error: 0.169466\n",
      "Mean squared error: 0.169486\n",
      "Mean squared error: 0.169506\n",
      "Mean squared error: 0.169526\n",
      "Mean squared error: 0.169545\n",
      "Mean squared error: 0.169565\n",
      "Mean squared error: 0.169584\n",
      "Mean squared error: 0.169603\n",
      "Mean squared error: 0.169622\n",
      "Mean squared error: 0.169641\n",
      "Mean squared error: 0.16966\n",
      "Mean squared error: 0.169679\n",
      "Mean squared error: 0.169698\n",
      "Mean squared error: 0.169716\n",
      "Mean squared error: 0.169735\n",
      "Mean squared error: 0.169753\n",
      "Mean squared error: 0.169771\n",
      "Mean squared error: 0.169789\n",
      "Mean squared error: 0.169808\n",
      "Mean squared error: 0.169825\n",
      "Mean squared error: 0.169843\n",
      "Mean squared error: 0.169861\n",
      "Mean squared error: 0.169879\n",
      "Mean squared error: 0.169896\n",
      "Mean squared error: 0.169914\n",
      "Mean squared error: 0.169931\n",
      "Mean squared error: 0.169948\n",
      "Mean squared error: 0.169966\n",
      "Mean squared error: 0.169983\n",
      "Mean squared error: 0.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.170017\n",
      "Mean squared error: 0.170034\n",
      "Mean squared error: 0.17005\n",
      "Mean squared error: 0.170067\n",
      "Mean squared error: 0.170083\n",
      "Mean squared error: 0.1701\n",
      "Mean squared error: 0.170116\n",
      "Mean squared error: 0.170132\n",
      "Mean squared error: 0.170149\n",
      "Mean squared error: 0.170165\n",
      "Mean squared error: 0.170181\n",
      "Mean squared error: 0.170197\n",
      "Mean squared error: 0.170213\n",
      "Mean squared error: 0.170228\n",
      "Mean squared error: 0.170244\n",
      "Mean squared error: 0.17026\n",
      "Mean squared error: 0.170275\n",
      "Mean squared error: 0.17029\n",
      "Mean squared error: 0.170306\n",
      "Mean squared error: 0.170321\n",
      "Mean squared error: 0.170336\n",
      "Mean squared error: 0.170351\n",
      "Mean squared error: 0.170366\n",
      "Mean squared error: 0.170381\n",
      "Mean squared error: 0.170396\n",
      "Mean squared error: 0.170411\n",
      "Mean squared error: 0.170426\n",
      "Mean squared error: 0.17044\n",
      "Mean squared error: 0.170455\n",
      "Mean squared error: 0.170469\n",
      "Mean squared error: 0.170484\n",
      "Mean squared error: 0.170498\n",
      "Mean squared error: 0.170512\n",
      "Mean squared error: 0.170526\n",
      "Mean squared error: 0.17054\n",
      "Mean squared error: 0.170554\n",
      "Mean squared error: 0.170568\n",
      "Mean squared error: 0.170582\n",
      "Mean squared error: 0.170596\n",
      "Mean squared error: 0.17061\n",
      "Mean squared error: 0.170623\n",
      "Mean squared error: 0.170637\n",
      "Mean squared error: 0.170651\n",
      "Mean squared error: 0.170664\n",
      "Mean squared error: 0.170677\n",
      "Mean squared error: 0.170691\n",
      "Mean squared error: 0.170704\n",
      "Mean squared error: 0.170717\n",
      "Mean squared error: 0.17073\n",
      "Mean squared error: 0.170743\n",
      "Mean squared error: 0.170756\n",
      "Mean squared error: 0.170769\n",
      "Mean squared error: 0.170782\n",
      "Mean squared error: 0.170795\n",
      "Mean squared error: 0.170807\n",
      "Mean squared error: 0.17082\n",
      "Mean squared error: 0.170832\n",
      "Mean squared error: 0.170845\n",
      "Mean squared error: 0.170857\n",
      "Mean squared error: 0.17087\n",
      "Mean squared error: 0.170882\n",
      "Mean squared error: 0.170894\n",
      "Mean squared error: 0.170907\n",
      "Mean squared error: 0.170919\n",
      "Mean squared error: 0.170931\n",
      "Mean squared error: 0.170943\n",
      "Mean squared error: 0.170955\n",
      "Mean squared error: 0.170967\n",
      "Mean squared error: 0.170978\n",
      "Mean squared error: 0.17099\n",
      "Mean squared error: 0.171002\n",
      "Mean squared error: 0.171014\n",
      "Mean squared error: 0.171025\n",
      "Mean squared error: 0.171037\n",
      "Mean squared error: 0.171048\n",
      "Mean squared error: 0.171059\n",
      "Mean squared error: 0.171071\n",
      "Mean squared error: 0.171082\n",
      "Mean squared error: 0.171093\n",
      "Mean squared error: 0.171105\n",
      "Mean squared error: 0.171116\n",
      "Mean squared error: 0.171127\n",
      "Mean squared error: 0.171138\n",
      "Mean squared error: 0.171149\n",
      "Mean squared error: 0.17116\n",
      "Mean squared error: 0.17117\n",
      "Mean squared error: 0.171181\n",
      "Mean squared error: 0.171192\n",
      "Mean squared error: 0.171203\n",
      "Mean squared error: 0.171213\n",
      "Mean squared error: 0.171224\n",
      "Mean squared error: 0.171234\n",
      "Mean squared error: 0.171245\n",
      "Mean squared error: 0.171255\n",
      "Mean squared error: 0.171266\n",
      "Mean squared error: 0.171276\n",
      "Mean squared error: 0.171286\n",
      "Mean squared error: 0.171297\n",
      "Mean squared error: 0.171307\n",
      "Mean squared error: 0.171317\n",
      "Mean squared error: 0.171327\n",
      "Mean squared error: 0.171337\n",
      "Mean squared error: 0.171347\n",
      "Mean squared error: 0.171357\n",
      "Mean squared error: 0.171367\n",
      "Mean squared error: 0.171377\n",
      "Mean squared error: 0.171386\n",
      "Mean squared error: 0.171396\n",
      "Mean squared error: 0.171406\n",
      "Mean squared error: 0.171415\n",
      "Mean squared error: 0.171425\n",
      "Mean squared error: 0.171435\n",
      "Mean squared error: 0.171444\n",
      "Mean squared error: 0.171453\n",
      "Mean squared error: 0.171463\n",
      "Mean squared error: 0.171472\n",
      "Mean squared error: 0.171482\n",
      "Mean squared error: 0.171491\n",
      "Mean squared error: 0.1715\n",
      "Mean squared error: 0.171509\n",
      "Mean squared error: 0.171518\n",
      "Mean squared error: 0.171527\n",
      "Mean squared error: 0.171537\n",
      "Mean squared error: 0.171546\n",
      "Mean squared error: 0.171554\n",
      "Mean squared error: 0.171563\n",
      "Mean squared error: 0.171572\n",
      "Mean squared error: 0.171581\n",
      "Mean squared error: 0.17159\n",
      "Mean squared error: 0.171599\n",
      "Mean squared error: 0.171607\n",
      "Mean squared error: 0.171616\n",
      "Mean squared error: 0.171625\n",
      "Mean squared error: 0.171633\n",
      "Mean squared error: 0.171642\n",
      "Mean squared error: 0.17165\n",
      "Mean squared error: 0.171659\n",
      "Mean squared error: 0.171667\n",
      "Mean squared error: 0.171675\n",
      "Mean squared error: 0.171684\n",
      "Mean squared error: 0.171692\n",
      "Mean squared error: 0.1717\n",
      "Mean squared error: 0.171709\n",
      "Mean squared error: 0.171717\n",
      "Mean squared error: 0.171725\n",
      "Mean squared error: 0.171733\n",
      "Mean squared error: 0.171741\n",
      "Mean squared error: 0.171749\n",
      "Mean squared error: 0.171757\n",
      "Mean squared error: 0.171765\n",
      "Mean squared error: 0.171773\n",
      "Mean squared error: 0.171781\n",
      "Mean squared error: 0.171789\n",
      "Mean squared error: 0.171797\n",
      "Mean squared error: 0.171804\n",
      "Mean squared error: 0.171812\n",
      "Mean squared error: 0.17182\n",
      "Mean squared error: 0.171827\n",
      "Mean squared error: 0.171835\n",
      "Mean squared error: 0.171843\n",
      "Mean squared error: 0.17185\n",
      "Mean squared error: 0.171858\n",
      "Mean squared error: 0.171865\n",
      "Mean squared error: 0.171873\n",
      "Mean squared error: 0.17188\n",
      "Mean squared error: 0.171887\n",
      "Mean squared error: 0.171895\n",
      "Mean squared error: 0.171902\n",
      "Mean squared error: 0.171909\n",
      "Mean squared error: 0.171916\n",
      "Mean squared error: 0.171924\n",
      "Mean squared error: 0.171931\n",
      "Mean squared error: 0.171938\n",
      "Mean squared error: 0.171945\n",
      "Mean squared error: 0.171952\n",
      "Mean squared error: 0.171959\n",
      "Mean squared error: 0.171966\n",
      "Mean squared error: 0.171973\n",
      "Mean squared error: 0.17198\n",
      "Mean squared error: 0.171987\n",
      "Mean squared error: 0.171994\n",
      "Mean squared error: 0.172001\n",
      "Mean squared error: 0.172008\n",
      "Mean squared error: 0.172014\n",
      "Mean squared error: 0.172021\n",
      "Mean squared error: 0.172028\n",
      "Mean squared error: 0.172035\n",
      "Mean squared error: 0.172041\n",
      "Mean squared error: 0.172048\n",
      "Mean squared error: 0.172054\n",
      "Mean squared error: 0.172061\n",
      "Mean squared error: 0.172068\n",
      "Mean squared error: 0.172074\n",
      "Mean squared error: 0.172081\n",
      "Mean squared error: 0.172087\n",
      "Mean squared error: 0.172093\n",
      "Mean squared error: 0.1721\n",
      "Mean squared error: 0.172106\n",
      "Mean squared error: 0.172112\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 10\n",
    "n_batches = int(np.ceil(moon_X.shape[0] / batch_size))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "interim_checkpoint_path = \"./checkpoints/logistic_regression.ckpt\"\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "log_dir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "correctness_summary = tf.summary.scalar(\"correctness\", correctness)\n",
    "summary_op = tf.summary.merge([mse_summary, correctness_summary])\n",
    "file_writer = tf.summary.FileWriter(log_dir, tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #saver.restore(sess, interim_checkpoint_path)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            batch_X = moon_X[batch_index * batch_size:(batch_index + 1) * batch_size]\n",
    "            #print(\"batch_X shape:\", batch_X.shape)\n",
    "            batch_y = moon_y[batch_index * batch_size:(batch_index + 1) * batch_size].reshape((-1, 1))\n",
    "            #print(\"batch_Y shape:\", batch_y.shape)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = summary_op.eval(feed_dict={x: batch_X, y: batch_y})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            t, m = sess.run([training_op, mse], feed_dict={x: batch_X, y: batch_y})\n",
    "            \n",
    "            #print(\"Batch performance: \", batch_correctness)\n",
    "            if batch_index == 0: print(\"Mean squared error:\", m)\n",
    "        if epoch % 100 == 0:\n",
    "            save_path = saver.save(sess, interim_checkpoint_path)\n",
    "\n",
    "    save_path = saver.save(sess, \"./checkpoints/logistic_regression_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
