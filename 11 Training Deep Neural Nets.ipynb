{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "#  Create a test graph\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_inputs = 28 * 28\n",
    "n_hidden_per_layer = [100, 100, 100, 100, 100]\n",
    "n_output = 10\n",
    "\n",
    "def he_normal_initialisation(n_inputs, n_outputs):\n",
    "    stddev = np.power(2 / (n_inputs + n_outputs), 1 / np.sqrt(2))\n",
    "    # truncated normal distributions limit the size of the weights, speeding up the training time.\n",
    "    return tf.truncated_normal((n_inputs, n_outputs), stddev=stddev)\n",
    "\n",
    "def he_uniform_initialisation(n_inputs, n_outputs):\n",
    "    r = np.power(6 / (n_inputs + n_outputs), 1 / np.sqrt(2))\n",
    "    # truncated normal distributions limit the size of the weights, speeding up the training time.\n",
    "    return tf.random_uniform((n_inputs, n_outputs), -r, r)\n",
    "\n",
    "def neuron_layer(X, n_neurons, name):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        W = tf.Variable(he_normal_initialisation(n_inputs, n_neurons), name=\"weights\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"biases\")\n",
    "        z = tf.matmul(X, W) + b\n",
    "        return tf.nn.elu(z)\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    x = tf.placeholder(tf.float32, shape=(None, number_of_inputs), name=\"input\")\n",
    "    y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "    with tf.name_scope(\"dnn\"):\n",
    "        input_tensor = x\n",
    "        for i in range(len(n_hidden_per_layer)):\n",
    "            input_tensor = neuron_layer(input_tensor, n_hidden_per_layer[i], \"hidden\" + str(i + 1))\n",
    "        logits = neuron_layer(input_tensor, n_output, \"output\")\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "        loss = tf.reduce_mean(cross_entropy, name=\"loss\")\n",
    "\n",
    "    with tf.name_scope(\"training\"):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    k = 1\n",
    "    correctness = tf.nn.in_top_k(logits, y, k)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correctness, tf.float32)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "interim_checkpoint_path = \"./checkpoints/mnist_model.ckpt\"\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "log_dir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "summary_op = tf.summary.merge([loss_summary, accuracy_summary])\n",
    "file_writer = tf.summary.FileWriter(log_dir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "loss: 2.30251 accuracy: 8.0\n",
      "loss: 2.30269 accuracy: 6.0\n",
      "loss: 2.3025 accuracy: 11.0\n",
      "loss: 2.30195 accuracy: 9.0\n",
      "loss: 2.3027 accuracy: 7.0\n",
      "loss: 2.30182 accuracy: 12.0\n",
      "loss: 2.30049 accuracy: 14.0\n",
      "loss: 2.30121 accuracy: 9.0\n",
      "loss: 2.30358 accuracy: 9.0\n",
      "loss: 2.30344 accuracy: 5.0\n",
      "loss: 2.30097 accuracy: 17.0\n",
      "loss: 2.30379 accuracy: 8.0\n",
      "loss: 2.30156 accuracy: 11.0\n",
      "loss: 2.30132 accuracy: 11.0\n",
      "loss: 2.30303 accuracy: 4.0\n",
      "loss: 2.30413 accuracy: 10.0\n",
      "loss: 2.30222 accuracy: 13.0\n",
      "loss: 2.3008 accuracy: 14.0\n",
      "loss: 2.30152 accuracy: 13.0\n",
      "loss: 2.29999 accuracy: 14.0\n",
      "loss: 2.30085 accuracy: 13.0\n",
      "loss: 2.30523 accuracy: 7.0\n",
      "loss: 2.30345 accuracy: 14.0\n",
      "loss: 2.2994 accuracy: 15.0\n",
      "loss: 2.30276 accuracy: 10.0\n",
      "loss: 2.3013 accuracy: 14.0\n",
      "loss: 2.29428 accuracy: 17.0\n",
      "loss: 2.30139 accuracy: 11.0\n",
      "loss: 2.30102 accuracy: 9.0\n",
      "loss: 2.30092 accuracy: 12.0\n",
      "loss: 2.29768 accuracy: 12.0\n",
      "loss: 2.30196 accuracy: 9.0\n",
      "loss: 2.30756 accuracy: 7.0\n",
      "loss: 2.29712 accuracy: 17.0\n",
      "loss: 2.29816 accuracy: 11.0\n",
      "loss: 2.29948 accuracy: 11.0\n",
      "loss: 2.30416 accuracy: 9.0\n",
      "loss: 2.30083 accuracy: 12.0\n",
      "loss: 2.30331 accuracy: 14.0\n",
      "loss: 2.30078 accuracy: 11.0\n",
      "loss: 2.30151 accuracy: 15.0\n",
      "loss: 2.29896 accuracy: 13.0\n",
      "loss: 2.29483 accuracy: 13.0\n",
      "loss: 2.29951 accuracy: 14.0\n",
      "loss: 2.30581 accuracy: 8.0\n",
      "loss: 2.30158 accuracy: 9.0\n",
      "loss: 2.30108 accuracy: 10.0\n",
      "loss: 2.29508 accuracy: 16.0\n",
      "loss: 2.29462 accuracy: 16.0\n",
      "loss: 2.30345 accuracy: 10.0\n",
      "loss: 2.30409 accuracy: 9.0\n",
      "loss: 2.30691 accuracy: 7.0\n",
      "loss: 2.31029 accuracy: 8.0\n",
      "loss: 2.30322 accuracy: 11.0\n",
      "loss: 2.29756 accuracy: 12.0\n",
      "loss: 2.30094 accuracy: 10.0\n",
      "loss: 2.30084 accuracy: 13.0\n",
      "loss: 2.30367 accuracy: 9.0\n",
      "loss: 2.30633 accuracy: 8.0\n",
      "loss: 2.30729 accuracy: 4.0\n",
      "loss: 2.3071 accuracy: 6.0\n",
      "loss: 2.30116 accuracy: 13.0\n",
      "loss: 2.30007 accuracy: 12.0\n",
      "loss: 2.30326 accuracy: 13.0\n",
      "loss: 2.30762 accuracy: 5.0\n",
      "loss: 2.29883 accuracy: 13.0\n",
      "loss: 2.30118 accuracy: 14.0\n",
      "loss: 2.3025 accuracy: 7.0\n",
      "loss: 2.29846 accuracy: 13.0\n",
      "loss: 2.30551 accuracy: 7.0\n",
      "loss: 2.30244 accuracy: 13.0\n",
      "loss: 2.30055 accuracy: 13.0\n",
      "loss: 2.30533 accuracy: 7.0\n",
      "loss: 2.30411 accuracy: 9.0\n",
      "loss: 2.29512 accuracy: 21.0\n",
      "loss: 2.30205 accuracy: 10.0\n",
      "loss: 2.29608 accuracy: 15.0\n",
      "loss: 2.30065 accuracy: 11.0\n",
      "loss: 2.29849 accuracy: 14.0\n",
      "loss: 2.29756 accuracy: 13.0\n",
      "loss: 2.29628 accuracy: 13.0\n",
      "loss: 2.29996 accuracy: 14.0\n",
      "loss: 2.29412 accuracy: 16.0\n",
      "loss: 2.29209 accuracy: 15.0\n",
      "loss: 2.3027 accuracy: 11.0\n",
      "loss: 2.29929 accuracy: 12.0\n",
      "loss: 2.2983 accuracy: 13.0\n",
      "loss: 2.31234 accuracy: 7.0\n",
      "loss: 2.30145 accuracy: 7.0\n",
      "loss: 2.29893 accuracy: 13.0\n",
      "loss: 2.30269 accuracy: 10.0\n",
      "loss: 2.29074 accuracy: 16.0\n",
      "loss: 2.2994 accuracy: 12.0\n",
      "loss: 2.30194 accuracy: 11.0\n",
      "loss: 2.29551 accuracy: 12.0\n",
      "loss: 2.30372 accuracy: 14.0\n",
      "loss: 2.29137 accuracy: 17.0\n",
      "loss: 2.30611 accuracy: 7.0\n",
      "loss: 2.30325 accuracy: 7.0\n",
      "loss: 2.30692 accuracy: 7.0\n",
      "loss: 2.29684 accuracy: 12.0\n",
      "loss: 2.29828 accuracy: 15.0\n",
      "loss: 2.2963 accuracy: 14.0\n",
      "loss: 2.30005 accuracy: 13.0\n",
      "loss: 2.30838 accuracy: 8.0\n",
      "loss: 2.3027 accuracy: 13.0\n",
      "loss: 2.30803 accuracy: 6.0\n",
      "loss: 2.29319 accuracy: 12.0\n",
      "loss: 2.30344 accuracy: 6.0\n",
      "loss: 2.30353 accuracy: 9.0\n",
      "loss: 2.30189 accuracy: 8.0\n",
      "loss: 2.30126 accuracy: 9.0\n",
      "loss: 2.30204 accuracy: 8.0\n",
      "loss: 2.30378 accuracy: 14.0\n",
      "loss: 2.28787 accuracy: 15.0\n",
      "loss: 2.29867 accuracy: 10.0\n",
      "loss: 2.30461 accuracy: 9.0\n",
      "loss: 2.30201 accuracy: 10.0\n",
      "loss: 2.30034 accuracy: 12.0\n",
      "loss: 2.29779 accuracy: 13.0\n",
      "loss: 2.30549 accuracy: 8.0\n",
      "loss: 2.29734 accuracy: 11.0\n",
      "loss: 2.29442 accuracy: 12.0\n",
      "loss: 2.30751 accuracy: 11.0\n",
      "loss: 2.29873 accuracy: 16.0\n",
      "loss: 2.303 accuracy: 13.0\n",
      "loss: 2.30835 accuracy: 12.0\n",
      "loss: 2.3058 accuracy: 9.0\n",
      "loss: 2.30552 accuracy: 12.0\n",
      "loss: 2.29855 accuracy: 13.0\n",
      "loss: 2.30639 accuracy: 12.0\n",
      "loss: 2.30118 accuracy: 12.0\n",
      "loss: 2.30462 accuracy: 14.0\n",
      "loss: 2.30602 accuracy: 9.0\n",
      "loss: 2.29954 accuracy: 8.0\n",
      "loss: 2.29968 accuracy: 14.0\n",
      "loss: 2.29914 accuracy: 13.0\n",
      "loss: 2.29564 accuracy: 14.0\n",
      "loss: 2.30226 accuracy: 9.0\n",
      "loss: 2.3033 accuracy: 10.0\n",
      "loss: 2.29762 accuracy: 14.0\n",
      "loss: 2.30397 accuracy: 5.0\n",
      "loss: 2.30328 accuracy: 8.0\n",
      "loss: 2.29973 accuracy: 8.0\n",
      "loss: 2.29927 accuracy: 16.0\n",
      "loss: 2.30053 accuracy: 8.0\n",
      "loss: 2.29817 accuracy: 10.0\n",
      "loss: 2.30664 accuracy: 12.0\n",
      "loss: 2.30699 accuracy: 8.0\n",
      "loss: 2.28645 accuracy: 18.0\n",
      "loss: 2.3133 accuracy: 6.0\n",
      "loss: 2.29306 accuracy: 17.0\n",
      "loss: 2.29227 accuracy: 15.0\n",
      "loss: 2.29347 accuracy: 14.0\n",
      "loss: 2.29703 accuracy: 15.0\n",
      "loss: 2.29521 accuracy: 10.0\n",
      "loss: 2.30806 accuracy: 8.0\n",
      "loss: 2.30129 accuracy: 13.0\n",
      "loss: 2.30642 accuracy: 4.0\n",
      "loss: 2.30849 accuracy: 9.0\n",
      "loss: 2.30984 accuracy: 7.0\n",
      "loss: 2.2975 accuracy: 14.0\n",
      "loss: 2.30048 accuracy: 12.0\n",
      "loss: 2.29168 accuracy: 17.0\n",
      "loss: 2.30372 accuracy: 14.0\n",
      "loss: 2.30342 accuracy: 14.0\n",
      "loss: 2.30712 accuracy: 6.0\n",
      "loss: 2.29003 accuracy: 17.0\n",
      "loss: 2.30125 accuracy: 11.0\n",
      "loss: 2.2991 accuracy: 13.0\n",
      "loss: 2.29936 accuracy: 8.0\n",
      "loss: 2.29486 accuracy: 12.0\n",
      "loss: 2.30867 accuracy: 10.0\n",
      "loss: 2.29473 accuracy: 14.0\n",
      "loss: 2.29706 accuracy: 11.0\n",
      "loss: 2.29383 accuracy: 14.0\n",
      "loss: 2.28846 accuracy: 18.0\n",
      "loss: 2.30171 accuracy: 11.0\n",
      "loss: 2.29382 accuracy: 17.0\n",
      "loss: 2.29827 accuracy: 11.0\n",
      "loss: 2.29544 accuracy: 12.0\n",
      "loss: 2.29976 accuracy: 10.0\n",
      "loss: 2.30793 accuracy: 9.0\n",
      "loss: 2.29281 accuracy: 13.0\n",
      "loss: 2.30018 accuracy: 13.0\n",
      "loss: 2.29566 accuracy: 12.0\n",
      "loss: 2.29768 accuracy: 14.0\n",
      "loss: 2.29956 accuracy: 10.0\n",
      "loss: 2.30258 accuracy: 11.0\n",
      "loss: 2.29352 accuracy: 15.0\n",
      "loss: 2.30424 accuracy: 10.0\n",
      "loss: 2.28387 accuracy: 21.0\n",
      "loss: 2.30157 accuracy: 12.0\n",
      "loss: 2.29625 accuracy: 15.0\n",
      "loss: 2.30359 accuracy: 9.0\n",
      "loss: 2.30597 accuracy: 10.0\n",
      "loss: 2.30795 accuracy: 8.0\n",
      "loss: 2.3004 accuracy: 13.0\n",
      "loss: 2.29272 accuracy: 11.0\n",
      "loss: 2.30609 accuracy: 10.0\n",
      "loss: 2.28112 accuracy: 18.0\n",
      "loss: 2.29909 accuracy: 13.0\n",
      "loss: 2.30825 accuracy: 9.0\n",
      "loss: 2.30313 accuracy: 13.0\n",
      "loss: 2.30452 accuracy: 10.0\n",
      "loss: 2.30013 accuracy: 10.0\n",
      "loss: 2.30147 accuracy: 10.0\n",
      "loss: 2.29686 accuracy: 12.0\n",
      "loss: 2.29811 accuracy: 11.0\n",
      "loss: 2.30688 accuracy: 8.0\n",
      "loss: 2.30686 accuracy: 8.0\n",
      "loss: 2.30567 accuracy: 9.0\n",
      "loss: 2.30464 accuracy: 7.0\n",
      "loss: 2.29614 accuracy: 12.0\n",
      "loss: 2.30146 accuracy: 8.0\n",
      "loss: 2.30507 accuracy: 7.0\n",
      "loss: 2.3015 accuracy: 11.0\n",
      "loss: 2.30545 accuracy: 12.0\n",
      "loss: 2.30154 accuracy: 12.0\n",
      "loss: 2.29751 accuracy: 9.0\n",
      "loss: 2.3019 accuracy: 11.0\n",
      "loss: 2.30501 accuracy: 5.0\n",
      "loss: 2.29495 accuracy: 14.0\n",
      "loss: 2.29989 accuracy: 8.0\n",
      "loss: 2.30164 accuracy: 11.0\n",
      "loss: 2.3062 accuracy: 6.0\n",
      "loss: 2.30096 accuracy: 7.0\n",
      "loss: 2.29983 accuracy: 11.0\n",
      "loss: 2.30673 accuracy: 7.0\n",
      "loss: 2.30101 accuracy: 8.0\n",
      "loss: 2.30129 accuracy: 8.0\n",
      "loss: 2.29969 accuracy: 12.0\n",
      "loss: 2.30434 accuracy: 9.0\n",
      "loss: 2.29461 accuracy: 11.0\n",
      "loss: 2.30166 accuracy: 14.0\n",
      "loss: 2.29853 accuracy: 13.0\n",
      "loss: 2.30284 accuracy: 9.0\n",
      "loss: 2.30017 accuracy: 11.0\n",
      "loss: 2.29564 accuracy: 12.0\n",
      "loss: 2.29781 accuracy: 11.0\n",
      "loss: 2.29729 accuracy: 10.0\n",
      "loss: 2.29831 accuracy: 12.0\n",
      "loss: 2.3036 accuracy: 7.0\n",
      "loss: 2.29248 accuracy: 17.0\n",
      "loss: 2.2927 accuracy: 14.0\n",
      "loss: 2.30325 accuracy: 9.0\n",
      "loss: 2.30392 accuracy: 8.0\n",
      "loss: 2.2958 accuracy: 10.0\n",
      "loss: 2.2996 accuracy: 11.0\n",
      "loss: 2.29998 accuracy: 12.0\n",
      "loss: 2.29922 accuracy: 7.0\n",
      "loss: 2.30275 accuracy: 10.0\n",
      "loss: 2.29339 accuracy: 11.0\n",
      "loss: 2.30572 accuracy: 7.0\n",
      "loss: 2.3014 accuracy: 10.0\n",
      "loss: 2.30301 accuracy: 13.0\n",
      "loss: 2.30015 accuracy: 8.0\n",
      "loss: 2.30852 accuracy: 8.0\n",
      "loss: 2.30174 accuracy: 7.0\n",
      "loss: 2.29996 accuracy: 7.0\n",
      "loss: 2.30156 accuracy: 17.0\n",
      "loss: 2.30145 accuracy: 9.0\n",
      "loss: 2.30728 accuracy: 7.0\n",
      "loss: 2.29039 accuracy: 14.0\n",
      "loss: 2.29777 accuracy: 7.0\n",
      "loss: 2.3035 accuracy: 13.0\n",
      "loss: 2.29753 accuracy: 12.0\n",
      "loss: 2.30277 accuracy: 8.0\n",
      "loss: 2.29856 accuracy: 14.0\n",
      "loss: 2.30122 accuracy: 11.0\n",
      "loss: 2.28941 accuracy: 12.0\n",
      "loss: 2.30503 accuracy: 10.0\n",
      "loss: 2.30327 accuracy: 14.0\n",
      "loss: 2.29935 accuracy: 20.0\n",
      "loss: 2.29471 accuracy: 22.0\n",
      "loss: 2.29935 accuracy: 20.0\n",
      "loss: 2.30205 accuracy: 10.0\n",
      "loss: 2.30267 accuracy: 5.0\n",
      "loss: 2.30275 accuracy: 20.0\n",
      "loss: 2.29902 accuracy: 19.0\n",
      "loss: 2.2928 accuracy: 26.0\n",
      "loss: 2.29453 accuracy: 21.0\n",
      "loss: 2.29995 accuracy: 12.0\n",
      "loss: 2.29989 accuracy: 18.0\n",
      "loss: 2.30201 accuracy: 9.0\n",
      "loss: 2.30425 accuracy: 10.0\n",
      "loss: 2.29575 accuracy: 24.0\n",
      "loss: 2.29698 accuracy: 15.0\n",
      "loss: 2.30234 accuracy: 7.0\n",
      "loss: 2.29978 accuracy: 13.0\n",
      "loss: 2.29598 accuracy: 14.0\n",
      "loss: 2.29493 accuracy: 18.0\n",
      "loss: 2.30274 accuracy: 7.0\n",
      "loss: 2.29777 accuracy: 8.0\n",
      "loss: 2.29924 accuracy: 9.0\n",
      "loss: 2.2959 accuracy: 13.0\n",
      "loss: 2.30043 accuracy: 9.0\n",
      "loss: 2.29601 accuracy: 15.0\n",
      "loss: 2.29813 accuracy: 6.0\n",
      "loss: 2.29609 accuracy: 14.0\n",
      "loss: 2.30247 accuracy: 8.0\n",
      "loss: 2.29687 accuracy: 10.0\n",
      "loss: 2.29735 accuracy: 11.0\n",
      "loss: 2.2989 accuracy: 9.0\n",
      "loss: 2.29953 accuracy: 10.0\n",
      "loss: 2.30567 accuracy: 7.0\n",
      "loss: 2.28981 accuracy: 15.0\n",
      "loss: 2.30151 accuracy: 11.0\n",
      "loss: 2.29676 accuracy: 15.0\n",
      "loss: 2.29941 accuracy: 10.0\n",
      "loss: 2.29687 accuracy: 14.0\n",
      "loss: 2.29349 accuracy: 11.0\n",
      "loss: 2.29549 accuracy: 11.0\n",
      "loss: 2.2979 accuracy: 10.0\n",
      "loss: 2.29509 accuracy: 15.0\n",
      "loss: 2.29434 accuracy: 11.0\n",
      "loss: 2.29563 accuracy: 12.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.29923 accuracy: 6.0\n",
      "loss: 2.29368 accuracy: 14.0\n",
      "loss: 2.30963 accuracy: 2.0\n",
      "loss: 2.29714 accuracy: 8.0\n",
      "loss: 2.29992 accuracy: 7.0\n",
      "loss: 2.28978 accuracy: 15.0\n",
      "loss: 2.29998 accuracy: 10.0\n",
      "loss: 2.28847 accuracy: 13.0\n",
      "loss: 2.3026 accuracy: 7.0\n",
      "loss: 2.29745 accuracy: 13.0\n",
      "loss: 2.30063 accuracy: 9.0\n",
      "loss: 2.29459 accuracy: 14.0\n",
      "loss: 2.2983 accuracy: 12.0\n",
      "loss: 2.29393 accuracy: 13.0\n",
      "loss: 2.29566 accuracy: 11.0\n",
      "loss: 2.29562 accuracy: 12.0\n",
      "loss: 2.30321 accuracy: 3.0\n",
      "loss: 2.30063 accuracy: 12.0\n",
      "loss: 2.29527 accuracy: 13.0\n",
      "loss: 2.29568 accuracy: 7.0\n",
      "loss: 2.29299 accuracy: 12.0\n",
      "loss: 2.29768 accuracy: 6.0\n",
      "loss: 2.29007 accuracy: 12.0\n",
      "loss: 2.29215 accuracy: 12.0\n",
      "loss: 2.29971 accuracy: 8.0\n",
      "loss: 2.29043 accuracy: 17.0\n",
      "loss: 2.29398 accuracy: 11.0\n",
      "loss: 2.29074 accuracy: 16.0\n",
      "loss: 2.2907 accuracy: 11.0\n",
      "loss: 2.29413 accuracy: 16.0\n",
      "loss: 2.2927 accuracy: 15.0\n",
      "loss: 2.29016 accuracy: 12.0\n",
      "loss: 2.29335 accuracy: 16.0\n",
      "loss: 2.29248 accuracy: 14.0\n",
      "loss: 2.29567 accuracy: 9.0\n",
      "loss: 2.29563 accuracy: 10.0\n",
      "loss: 2.29102 accuracy: 10.0\n",
      "loss: 2.29377 accuracy: 11.0\n",
      "loss: 2.29581 accuracy: 13.0\n",
      "loss: 2.2886 accuracy: 12.0\n",
      "loss: 2.28965 accuracy: 12.0\n",
      "loss: 2.29023 accuracy: 14.0\n",
      "loss: 2.29957 accuracy: 7.0\n",
      "loss: 2.29174 accuracy: 13.0\n",
      "loss: 2.29677 accuracy: 7.0\n",
      "loss: 2.29572 accuracy: 10.0\n",
      "loss: 2.2925 accuracy: 10.0\n",
      "loss: 2.28846 accuracy: 10.0\n",
      "loss: 2.29495 accuracy: 8.0\n",
      "loss: 2.29114 accuracy: 15.0\n",
      "loss: 2.28819 accuracy: 16.0\n",
      "loss: 2.28645 accuracy: 13.0\n",
      "loss: 2.28576 accuracy: 9.0\n",
      "loss: 2.29216 accuracy: 14.0\n",
      "loss: 2.2837 accuracy: 12.0\n",
      "loss: 2.29121 accuracy: 11.0\n",
      "loss: 2.28609 accuracy: 13.0\n",
      "loss: 2.28086 accuracy: 16.0\n",
      "loss: 2.29982 accuracy: 10.0\n",
      "loss: 2.2821 accuracy: 15.0\n",
      "loss: 2.28718 accuracy: 12.0\n",
      "loss: 2.28617 accuracy: 13.0\n",
      "loss: 2.29 accuracy: 13.0\n",
      "loss: 2.28142 accuracy: 17.0\n",
      "loss: 2.28131 accuracy: 13.0\n",
      "loss: 2.28736 accuracy: 10.0\n",
      "loss: 2.28394 accuracy: 13.0\n",
      "loss: 2.282 accuracy: 15.0\n",
      "loss: 2.28669 accuracy: 11.0\n",
      "loss: 2.28181 accuracy: 11.0\n",
      "loss: 2.28036 accuracy: 17.0\n",
      "loss: 2.27681 accuracy: 17.0\n",
      "loss: 2.27937 accuracy: 14.0\n",
      "loss: 2.28504 accuracy: 8.0\n",
      "loss: 2.27484 accuracy: 14.0\n",
      "loss: 2.27643 accuracy: 12.0\n",
      "loss: 2.28321 accuracy: 11.0\n",
      "loss: 2.28065 accuracy: 13.0\n",
      "loss: 2.28147 accuracy: 16.0\n",
      "loss: 2.26997 accuracy: 16.0\n",
      "loss: 2.28107 accuracy: 16.0\n",
      "loss: 2.28396 accuracy: 7.0\n",
      "loss: 2.26147 accuracy: 28.0\n",
      "loss: 2.27376 accuracy: 17.0\n",
      "loss: 2.28955 accuracy: 12.0\n",
      "loss: 2.28458 accuracy: 13.0\n",
      "loss: 2.28988 accuracy: 16.0\n",
      "loss: 2.27567 accuracy: 14.0\n",
      "loss: 2.27417 accuracy: 18.0\n",
      "loss: 2.2579 accuracy: 26.0\n",
      "loss: 2.27357 accuracy: 20.0\n",
      "loss: 2.27076 accuracy: 13.0\n",
      "loss: 2.27595 accuracy: 15.0\n",
      "loss: 2.26038 accuracy: 23.0\n",
      "loss: 2.25759 accuracy: 20.0\n",
      "loss: 2.27472 accuracy: 15.0\n",
      "loss: 2.24337 accuracy: 22.0\n",
      "loss: 2.26077 accuracy: 17.0\n",
      "loss: 2.27194 accuracy: 16.0\n",
      "loss: 2.26821 accuracy: 16.0\n",
      "loss: 2.25666 accuracy: 20.0\n",
      "loss: 2.26173 accuracy: 23.0\n",
      "loss: 2.26058 accuracy: 22.0\n",
      "loss: 2.25281 accuracy: 21.0\n",
      "loss: 2.25066 accuracy: 22.0\n",
      "loss: 2.2616 accuracy: 22.0\n",
      "loss: 2.226 accuracy: 28.0\n",
      "loss: 2.26437 accuracy: 16.0\n",
      "loss: 2.23365 accuracy: 22.0\n",
      "loss: 2.24671 accuracy: 21.0\n",
      "loss: 2.23514 accuracy: 22.0\n",
      "loss: 2.23833 accuracy: 15.0\n",
      "loss: 2.23846 accuracy: 20.0\n",
      "loss: 2.25159 accuracy: 17.0\n",
      "loss: 2.22818 accuracy: 19.0\n",
      "loss: 2.20157 accuracy: 22.0\n",
      "loss: 2.23323 accuracy: 15.0\n",
      "loss: 2.21209 accuracy: 18.0\n",
      "loss: 2.20177 accuracy: 24.0\n",
      "loss: 2.17764 accuracy: 25.0\n",
      "loss: 2.19725 accuracy: 19.0\n",
      "loss: 2.20759 accuracy: 11.0\n",
      "loss: 2.20145 accuracy: 17.0\n",
      "loss: 2.14873 accuracy: 24.0\n",
      "loss: 2.13511 accuracy: 25.0\n",
      "loss: 2.12734 accuracy: 21.0\n",
      "loss: 2.12682 accuracy: 26.0\n",
      "loss: 2.08786 accuracy: 26.0\n",
      "loss: 2.05127 accuracy: 30.0\n",
      "loss: 2.08517 accuracy: 21.0\n",
      "loss: 2.05689 accuracy: 25.0\n",
      "loss: 2.07352 accuracy: 22.0\n",
      "loss: 1.99707 accuracy: 23.0\n",
      "loss: 2.00522 accuracy: 25.0\n",
      "loss: 2.01091 accuracy: 22.0\n",
      "loss: 2.02784 accuracy: 21.0\n",
      "loss: 1.96516 accuracy: 20.0\n",
      "loss: 2.01696 accuracy: 21.0\n",
      "loss: 1.94961 accuracy: 24.0\n",
      "loss: 1.9497 accuracy: 28.0\n",
      "loss: 1.93143 accuracy: 25.0\n",
      "loss: 1.83674 accuracy: 29.0\n",
      "loss: 1.9281 accuracy: 25.0\n",
      "loss: 1.93023 accuracy: 25.0\n",
      "loss: 1.98674 accuracy: 20.0\n",
      "loss: 1.98063 accuracy: 17.0\n",
      "loss: 1.83854 accuracy: 22.0\n",
      "loss: 1.90462 accuracy: 21.0\n",
      "loss: 2.01289 accuracy: 16.0\n",
      "loss: 1.8327 accuracy: 25.0\n",
      "loss: 1.97052 accuracy: 21.0\n",
      "loss: 1.81968 accuracy: 27.0\n",
      "loss: 1.91258 accuracy: 25.0\n",
      "loss: 1.80632 accuracy: 22.0\n",
      "loss: 1.89164 accuracy: 21.0\n",
      "loss: 1.87446 accuracy: 18.0\n",
      "loss: 1.83015 accuracy: 21.0\n",
      "loss: 1.81913 accuracy: 20.0\n",
      "loss: 1.81783 accuracy: 31.0\n",
      "loss: 1.79756 accuracy: 31.0\n",
      "loss: 1.8473 accuracy: 23.0\n",
      "loss: 1.894 accuracy: 23.0\n",
      "loss: 1.78615 accuracy: 26.0\n",
      "loss: 1.86645 accuracy: 24.0\n",
      "loss: 1.78324 accuracy: 24.0\n",
      "loss: 1.96811 accuracy: 14.0\n",
      "loss: 1.8111 accuracy: 19.0\n",
      "loss: 1.84195 accuracy: 21.0\n",
      "loss: 1.91508 accuracy: 18.0\n",
      "loss: 1.85766 accuracy: 18.0\n",
      "loss: 1.74807 accuracy: 25.0\n",
      "loss: 1.72421 accuracy: 28.0\n",
      "loss: 1.8108 accuracy: 16.0\n",
      "loss: 1.82379 accuracy: 20.0\n",
      "loss: 1.83546 accuracy: 26.0\n",
      "loss: 1.75825 accuracy: 24.0\n",
      "loss: 1.68669 accuracy: 34.0\n",
      "loss: 1.78143 accuracy: 18.0\n",
      "loss: 1.72123 accuracy: 21.0\n",
      "loss: 1.76082 accuracy: 31.0\n",
      "loss: 1.76732 accuracy: 26.0\n",
      "loss: 1.80043 accuracy: 33.0\n",
      "loss: 1.86103 accuracy: 20.0\n",
      "loss: 1.86567 accuracy: 26.0\n",
      "loss: 1.79153 accuracy: 16.0\n",
      "loss: 1.93241 accuracy: 20.0\n",
      "loss: 1.80677 accuracy: 22.0\n",
      "loss: 1.86434 accuracy: 26.0\n",
      "loss: 1.80851 accuracy: 19.0\n",
      "loss: 1.7093 accuracy: 23.0\n",
      "loss: 1.79647 accuracy: 21.0\n",
      "loss: 1.81312 accuracy: 22.0\n",
      "loss: 1.73963 accuracy: 17.0\n",
      "loss: 1.75216 accuracy: 23.0\n",
      "loss: 1.73977 accuracy: 19.0\n",
      "loss: 1.77529 accuracy: 27.0\n",
      "loss: 1.74865 accuracy: 31.0\n",
      "loss: 1.80729 accuracy: 24.0\n",
      "loss: 1.81403 accuracy: 16.0\n",
      "loss: 1.83666 accuracy: 21.0\n",
      "loss: 1.79393 accuracy: 23.0\n",
      "loss: 1.73855 accuracy: 23.0\n",
      "loss: 1.74308 accuracy: 33.0\n",
      "loss: 1.71837 accuracy: 28.0\n",
      "loss: 1.73763 accuracy: 21.0\n",
      "loss: 1.71257 accuracy: 22.0\n",
      "loss: 1.70841 accuracy: 23.0\n",
      "loss: 1.65679 accuracy: 31.0\n",
      "loss: 1.79795 accuracy: 26.0\n",
      "loss: 1.69726 accuracy: 27.0\n",
      "loss: 1.77107 accuracy: 31.0\n",
      "loss: 1.9283 accuracy: 21.0\n",
      "loss: 1.7696 accuracy: 29.0\n",
      "loss: 1.72231 accuracy: 30.0\n",
      "loss: 1.73096 accuracy: 27.0\n",
      "loss: 1.74079 accuracy: 26.0\n",
      "loss: 1.73856 accuracy: 33.0\n",
      "loss: 1.80107 accuracy: 25.0\n",
      "loss: 1.71499 accuracy: 34.0\n",
      "loss: 1.68502 accuracy: 36.0\n",
      "loss: 1.7586 accuracy: 27.0\n",
      "loss: 1.72018 accuracy: 18.0\n",
      "loss: 1.7511 accuracy: 29.0\n",
      "loss: 1.76935 accuracy: 31.0\n",
      "loss: 1.68701 accuracy: 35.0\n",
      "loss: 1.61899 accuracy: 29.0\n",
      "loss: 1.66317 accuracy: 31.0\n",
      "loss: 1.66446 accuracy: 33.0\n",
      "loss: 1.81937 accuracy: 28.0\n",
      "loss: 1.67191 accuracy: 20.0\n",
      "loss: 1.66775 accuracy: 25.0\n",
      "loss: 1.65966 accuracy: 34.0\n",
      "epoch 1\n",
      "loss: 1.68238 accuracy: 38.0\n",
      "loss: 1.57772 accuracy: 31.0\n",
      "loss: 1.64494 accuracy: 34.0\n",
      "loss: 1.77274 accuracy: 26.0\n",
      "loss: 1.59493 accuracy: 35.0\n",
      "loss: 1.71479 accuracy: 22.0\n",
      "loss: 1.75652 accuracy: 37.0\n",
      "loss: 1.9794 accuracy: 24.0\n",
      "loss: 1.89432 accuracy: 19.0\n",
      "loss: 1.66723 accuracy: 36.0\n",
      "loss: 1.61354 accuracy: 37.0\n",
      "loss: 1.75734 accuracy: 34.0\n",
      "loss: 1.74856 accuracy: 31.0\n",
      "loss: 1.6215 accuracy: 32.0\n",
      "loss: 1.61774 accuracy: 36.0\n",
      "loss: 1.75547 accuracy: 31.0\n",
      "loss: 1.69486 accuracy: 32.0\n",
      "loss: 1.64062 accuracy: 34.0\n",
      "loss: 1.732 accuracy: 26.0\n",
      "loss: 1.7733 accuracy: 27.0\n",
      "loss: 1.6102 accuracy: 40.0\n",
      "loss: 1.65541 accuracy: 33.0\n",
      "loss: 1.70061 accuracy: 40.0\n",
      "loss: 1.68264 accuracy: 37.0\n",
      "loss: 1.63654 accuracy: 35.0\n",
      "loss: 1.73148 accuracy: 36.0\n",
      "loss: 1.74925 accuracy: 31.0\n",
      "loss: 1.60463 accuracy: 39.0\n",
      "loss: 1.57837 accuracy: 52.0\n",
      "loss: 1.64702 accuracy: 36.0\n",
      "loss: 1.69352 accuracy: 38.0\n",
      "loss: 1.65279 accuracy: 42.0\n",
      "loss: 1.66305 accuracy: 37.0\n",
      "loss: 1.57142 accuracy: 47.0\n",
      "loss: 1.468 accuracy: 40.0\n",
      "loss: 1.56512 accuracy: 43.0\n",
      "loss: 1.50096 accuracy: 40.0\n",
      "loss: 1.55319 accuracy: 45.0\n",
      "loss: 1.46495 accuracy: 44.0\n",
      "loss: 1.57234 accuracy: 42.0\n",
      "loss: 1.51515 accuracy: 39.0\n",
      "loss: 1.54099 accuracy: 35.0\n",
      "loss: 1.58894 accuracy: 36.0\n",
      "loss: 1.55523 accuracy: 36.0\n",
      "loss: 1.53559 accuracy: 42.0\n",
      "loss: 1.59703 accuracy: 48.0\n",
      "loss: 1.52318 accuracy: 43.0\n",
      "loss: 1.5563 accuracy: 46.0\n",
      "loss: 1.40894 accuracy: 47.0\n",
      "loss: 1.47272 accuracy: 37.0\n",
      "loss: 1.38315 accuracy: 53.0\n",
      "loss: 1.51047 accuracy: 37.0\n",
      "loss: 1.41193 accuracy: 47.0\n",
      "loss: 1.57515 accuracy: 32.0\n",
      "loss: 1.42311 accuracy: 43.0\n",
      "loss: 1.4075 accuracy: 48.0\n",
      "loss: 1.50042 accuracy: 40.0\n",
      "loss: 1.36497 accuracy: 45.0\n",
      "loss: 1.53248 accuracy: 34.0\n",
      "loss: 1.47006 accuracy: 43.0\n",
      "loss: 1.38361 accuracy: 50.0\n",
      "loss: 1.39146 accuracy: 39.0\n",
      "loss: 1.41672 accuracy: 55.0\n",
      "loss: 1.64776 accuracy: 36.0\n",
      "loss: 1.44768 accuracy: 43.0\n",
      "loss: 1.44919 accuracy: 40.0\n",
      "loss: 1.2894 accuracy: 53.0\n",
      "loss: 1.47733 accuracy: 43.0\n",
      "loss: 1.50371 accuracy: 37.0\n",
      "loss: 1.56393 accuracy: 43.0\n",
      "loss: 1.30752 accuracy: 52.0\n",
      "loss: 1.36043 accuracy: 53.0\n",
      "loss: 1.26496 accuracy: 49.0\n",
      "loss: 1.2666 accuracy: 48.0\n",
      "loss: 1.12836 accuracy: 62.0\n",
      "loss: 1.30702 accuracy: 46.0\n",
      "loss: 1.31984 accuracy: 40.0\n",
      "loss: 1.2814 accuracy: 53.0\n",
      "loss: 1.36833 accuracy: 40.0\n",
      "loss: 1.28149 accuracy: 54.0\n",
      "loss: 1.41091 accuracy: 45.0\n",
      "loss: 1.30259 accuracy: 49.0\n",
      "loss: 1.41461 accuracy: 46.0\n",
      "loss: 1.20441 accuracy: 53.0\n",
      "loss: 1.26641 accuracy: 46.0\n",
      "loss: 1.15147 accuracy: 60.0\n",
      "loss: 1.46944 accuracy: 41.0\n",
      "loss: 1.30546 accuracy: 42.0\n",
      "loss: 1.1283 accuracy: 55.0\n",
      "loss: 1.18004 accuracy: 55.0\n",
      "loss: 1.14609 accuracy: 51.0\n",
      "loss: 1.18406 accuracy: 59.0\n",
      "loss: 1.18359 accuracy: 51.0\n",
      "loss: 1.10518 accuracy: 56.0\n",
      "loss: 1.44131 accuracy: 42.0\n",
      "loss: 1.29137 accuracy: 48.0\n",
      "loss: 1.23103 accuracy: 46.0\n",
      "loss: 1.26379 accuracy: 55.0\n",
      "loss: 1.10344 accuracy: 56.0\n",
      "loss: 1.24906 accuracy: 54.0\n",
      "loss: 1.1984 accuracy: 53.0\n",
      "loss: 1.15504 accuracy: 54.0\n",
      "loss: 1.22069 accuracy: 55.0\n",
      "loss: 1.08994 accuracy: 58.0\n",
      "loss: 1.16031 accuracy: 54.0\n",
      "loss: 1.06833 accuracy: 61.0\n",
      "loss: 1.49935 accuracy: 38.0\n",
      "loss: 1.3479 accuracy: 45.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.27723 accuracy: 56.0\n",
      "loss: 1.1999 accuracy: 57.0\n",
      "loss: 1.2636 accuracy: 48.0\n",
      "loss: 1.41318 accuracy: 50.0\n",
      "loss: 1.15579 accuracy: 55.0\n",
      "loss: 1.13439 accuracy: 58.0\n",
      "loss: 1.1615 accuracy: 55.0\n",
      "loss: 1.22973 accuracy: 53.0\n",
      "loss: 1.07883 accuracy: 58.0\n",
      "loss: 1.0867 accuracy: 59.0\n",
      "loss: 1.34135 accuracy: 53.0\n",
      "loss: 1.41001 accuracy: 49.0\n",
      "loss: 1.40076 accuracy: 40.0\n",
      "loss: 1.23199 accuracy: 48.0\n",
      "loss: 1.24943 accuracy: 50.0\n",
      "loss: 1.11413 accuracy: 59.0\n",
      "loss: 1.15062 accuracy: 61.0\n",
      "loss: 1.11444 accuracy: 57.0\n",
      "loss: 1.07061 accuracy: 59.0\n",
      "loss: 1.2485 accuracy: 53.0\n",
      "loss: 1.08311 accuracy: 60.0\n",
      "loss: 1.17301 accuracy: 55.0\n",
      "loss: 1.20767 accuracy: 58.0\n",
      "loss: 1.24957 accuracy: 57.0\n",
      "loss: 1.09283 accuracy: 59.0\n",
      "loss: 1.02179 accuracy: 61.0\n",
      "loss: 1.1732 accuracy: 56.0\n",
      "loss: 1.04197 accuracy: 66.0\n",
      "loss: 1.04237 accuracy: 65.0\n",
      "loss: 1.13006 accuracy: 64.0\n",
      "loss: 1.12813 accuracy: 60.0\n",
      "loss: 0.962546 accuracy: 65.0\n",
      "loss: 0.985602 accuracy: 65.0\n",
      "loss: 1.05792 accuracy: 62.0\n",
      "loss: 1.00818 accuracy: 66.0\n",
      "loss: 1.16383 accuracy: 59.0\n",
      "loss: 0.964739 accuracy: 72.0\n",
      "loss: 1.16917 accuracy: 56.0\n",
      "loss: 0.904499 accuracy: 70.0\n",
      "loss: 1.1649 accuracy: 59.0\n",
      "loss: 0.818569 accuracy: 68.0\n",
      "loss: 0.90013 accuracy: 68.0\n",
      "loss: 1.1082 accuracy: 66.0\n",
      "loss: 1.10643 accuracy: 55.0\n",
      "loss: 1.0313 accuracy: 63.0\n",
      "loss: 0.946258 accuracy: 71.0\n",
      "loss: 0.915305 accuracy: 68.0\n",
      "loss: 0.997936 accuracy: 74.0\n",
      "loss: 1.10243 accuracy: 62.0\n",
      "loss: 1.09248 accuracy: 58.0\n",
      "loss: 0.892795 accuracy: 68.0\n",
      "loss: 0.977542 accuracy: 61.0\n",
      "loss: 0.938339 accuracy: 64.0\n",
      "loss: 0.922497 accuracy: 68.0\n",
      "loss: 1.05525 accuracy: 59.0\n",
      "loss: 1.09586 accuracy: 65.0\n",
      "loss: 0.980368 accuracy: 70.0\n",
      "loss: 0.835911 accuracy: 69.0\n",
      "loss: 0.817339 accuracy: 69.0\n",
      "loss: 0.870699 accuracy: 67.0\n",
      "loss: 1.03105 accuracy: 69.0\n",
      "loss: 1.02775 accuracy: 58.0\n",
      "loss: 1.43876 accuracy: 37.0\n",
      "loss: 1.36423 accuracy: 49.0\n",
      "loss: 1.15751 accuracy: 59.0\n",
      "loss: 0.965827 accuracy: 70.0\n",
      "loss: 0.986625 accuracy: 71.0\n",
      "loss: 0.7789 accuracy: 76.0\n",
      "loss: 1.0433 accuracy: 65.0\n",
      "loss: 1.1341 accuracy: 59.0\n",
      "loss: 1.02051 accuracy: 65.0\n",
      "loss: 1.20046 accuracy: 60.0\n",
      "loss: 1.01599 accuracy: 57.0\n",
      "loss: 1.03277 accuracy: 71.0\n",
      "loss: 0.863892 accuracy: 69.0\n",
      "loss: 0.922209 accuracy: 67.0\n",
      "loss: 1.01437 accuracy: 64.0\n",
      "loss: 1.08059 accuracy: 60.0\n",
      "loss: 0.984828 accuracy: 65.0\n",
      "loss: 0.919524 accuracy: 72.0\n",
      "loss: 0.828296 accuracy: 70.0\n",
      "loss: 1.06933 accuracy: 63.0\n",
      "loss: 1.03759 accuracy: 68.0\n",
      "loss: 0.770401 accuracy: 76.0\n",
      "loss: 0.836348 accuracy: 72.0\n",
      "loss: 0.835075 accuracy: 75.0\n",
      "loss: 0.779613 accuracy: 69.0\n",
      "loss: 0.919181 accuracy: 66.0\n",
      "loss: 0.930247 accuracy: 66.0\n",
      "loss: 0.98521 accuracy: 63.0\n",
      "loss: 1.01267 accuracy: 67.0\n",
      "loss: 0.724331 accuracy: 75.0\n",
      "loss: 0.906678 accuracy: 76.0\n",
      "loss: 0.72186 accuracy: 75.0\n",
      "loss: 0.905278 accuracy: 68.0\n",
      "loss: 0.859204 accuracy: 71.0\n",
      "loss: 0.712349 accuracy: 81.0\n",
      "loss: 0.988908 accuracy: 63.0\n",
      "loss: 0.736595 accuracy: 78.0\n",
      "loss: 0.747618 accuracy: 71.0\n",
      "loss: 0.867841 accuracy: 75.0\n",
      "loss: 0.87396 accuracy: 76.0\n",
      "loss: 0.732947 accuracy: 72.0\n",
      "loss: 0.805594 accuracy: 69.0\n",
      "loss: 0.811355 accuracy: 72.0\n",
      "loss: 0.881247 accuracy: 65.0\n",
      "loss: 0.873438 accuracy: 68.0\n",
      "loss: 0.963562 accuracy: 64.0\n",
      "loss: 1.16882 accuracy: 65.0\n",
      "loss: 0.861147 accuracy: 69.0\n",
      "loss: 0.784223 accuracy: 69.0\n",
      "loss: 0.865255 accuracy: 69.0\n",
      "loss: 0.601779 accuracy: 78.0\n",
      "loss: 0.875756 accuracy: 68.0\n",
      "loss: 0.813572 accuracy: 74.0\n",
      "loss: 0.749507 accuracy: 75.0\n",
      "loss: 0.806255 accuracy: 66.0\n",
      "loss: 0.996252 accuracy: 69.0\n",
      "loss: 1.08441 accuracy: 66.0\n",
      "loss: 0.928874 accuracy: 69.0\n",
      "loss: 0.954587 accuracy: 66.0\n",
      "loss: 0.936497 accuracy: 71.0\n",
      "loss: 0.656452 accuracy: 80.0\n",
      "loss: 0.761465 accuracy: 74.0\n",
      "loss: 0.743575 accuracy: 77.0\n",
      "loss: 0.644244 accuracy: 80.0\n",
      "loss: 0.707844 accuracy: 75.0\n",
      "loss: 0.752577 accuracy: 74.0\n",
      "loss: 0.689406 accuracy: 80.0\n",
      "loss: 0.570842 accuracy: 83.0\n",
      "loss: 0.844095 accuracy: 77.0\n",
      "loss: 0.808313 accuracy: 71.0\n",
      "loss: 0.709187 accuracy: 74.0\n",
      "loss: 0.802336 accuracy: 74.0\n",
      "loss: 0.521717 accuracy: 82.0\n",
      "loss: 0.861659 accuracy: 71.0\n",
      "loss: 0.668113 accuracy: 75.0\n",
      "loss: 0.721966 accuracy: 74.0\n",
      "loss: 0.761062 accuracy: 71.0\n",
      "loss: 1.17645 accuracy: 60.0\n",
      "loss: 0.919708 accuracy: 72.0\n",
      "loss: 0.924944 accuracy: 65.0\n",
      "loss: 0.808768 accuracy: 76.0\n",
      "loss: 0.68232 accuracy: 80.0\n",
      "loss: 0.854752 accuracy: 70.0\n",
      "loss: 0.5333 accuracy: 86.0\n",
      "loss: 0.79969 accuracy: 72.0\n",
      "loss: 0.82999 accuracy: 72.0\n",
      "loss: 0.921139 accuracy: 71.0\n",
      "loss: 0.783045 accuracy: 75.0\n",
      "loss: 0.832562 accuracy: 72.0\n",
      "loss: 0.732041 accuracy: 78.0\n",
      "loss: 0.760307 accuracy: 68.0\n",
      "loss: 0.627646 accuracy: 76.0\n",
      "loss: 0.831861 accuracy: 76.0\n",
      "loss: 0.602822 accuracy: 80.0\n",
      "loss: 0.775858 accuracy: 70.0\n",
      "loss: 0.942874 accuracy: 69.0\n",
      "loss: 0.55987 accuracy: 81.0\n",
      "loss: 0.8135 accuracy: 71.0\n",
      "loss: 0.649814 accuracy: 76.0\n",
      "loss: 0.778426 accuracy: 76.0\n",
      "loss: 0.698285 accuracy: 69.0\n",
      "loss: 0.696102 accuracy: 73.0\n",
      "loss: 0.567129 accuracy: 77.0\n",
      "loss: 0.767708 accuracy: 71.0\n",
      "loss: 0.619994 accuracy: 80.0\n",
      "loss: 0.612288 accuracy: 81.0\n",
      "loss: 0.843597 accuracy: 71.0\n",
      "loss: 0.621163 accuracy: 81.0\n",
      "loss: 0.703037 accuracy: 77.0\n",
      "loss: 0.658457 accuracy: 75.0\n",
      "loss: 0.691817 accuracy: 83.0\n",
      "loss: 0.827236 accuracy: 76.0\n",
      "loss: 0.62181 accuracy: 79.0\n",
      "loss: 0.63702 accuracy: 77.0\n",
      "loss: 0.574376 accuracy: 81.0\n",
      "loss: 0.829407 accuracy: 78.0\n",
      "loss: 0.725035 accuracy: 74.0\n",
      "loss: 0.601941 accuracy: 83.0\n",
      "loss: 0.828038 accuracy: 76.0\n",
      "loss: 0.740268 accuracy: 76.0\n",
      "loss: 0.551527 accuracy: 80.0\n",
      "loss: 0.587687 accuracy: 81.0\n",
      "loss: 0.759921 accuracy: 82.0\n",
      "loss: 0.70579 accuracy: 80.0\n",
      "loss: 0.372633 accuracy: 90.0\n",
      "loss: 0.770668 accuracy: 75.0\n",
      "loss: 0.560542 accuracy: 82.0\n",
      "loss: 0.581161 accuracy: 77.0\n",
      "loss: 0.771474 accuracy: 76.0\n",
      "loss: 0.705784 accuracy: 75.0\n",
      "loss: 0.820585 accuracy: 70.0\n",
      "loss: 1.01585 accuracy: 66.0\n",
      "loss: 0.671855 accuracy: 83.0\n",
      "loss: 0.70399 accuracy: 78.0\n",
      "loss: 0.739387 accuracy: 71.0\n",
      "loss: 0.665469 accuracy: 81.0\n",
      "loss: 0.570489 accuracy: 83.0\n",
      "loss: 0.593846 accuracy: 79.0\n",
      "loss: 0.713146 accuracy: 81.0\n",
      "loss: 0.541625 accuracy: 84.0\n",
      "loss: 0.844685 accuracy: 70.0\n",
      "loss: 0.762106 accuracy: 73.0\n",
      "loss: 0.807613 accuracy: 74.0\n",
      "loss: 0.808669 accuracy: 76.0\n",
      "loss: 0.69909 accuracy: 75.0\n",
      "loss: 0.898103 accuracy: 75.0\n",
      "loss: 0.741456 accuracy: 75.0\n",
      "loss: 0.645217 accuracy: 78.0\n",
      "loss: 0.652392 accuracy: 77.0\n",
      "loss: 0.622626 accuracy: 82.0\n",
      "loss: 0.719854 accuracy: 80.0\n",
      "loss: 0.586021 accuracy: 82.0\n",
      "loss: 0.690886 accuracy: 78.0\n",
      "loss: 0.539223 accuracy: 85.0\n",
      "loss: 0.762527 accuracy: 76.0\n",
      "loss: 0.64914 accuracy: 80.0\n",
      "loss: 0.658231 accuracy: 77.0\n",
      "loss: 0.595938 accuracy: 77.0\n",
      "loss: 0.735769 accuracy: 75.0\n",
      "loss: 0.831562 accuracy: 76.0\n",
      "loss: 0.703512 accuracy: 76.0\n",
      "loss: 0.736485 accuracy: 79.0\n",
      "loss: 0.618582 accuracy: 80.0\n",
      "loss: 0.831155 accuracy: 69.0\n",
      "loss: 0.670351 accuracy: 76.0\n",
      "loss: 0.637807 accuracy: 80.0\n",
      "loss: 0.533583 accuracy: 84.0\n",
      "loss: 0.685773 accuracy: 78.0\n",
      "loss: 0.713977 accuracy: 80.0\n",
      "loss: 0.609001 accuracy: 78.0\n",
      "loss: 0.593469 accuracy: 78.0\n",
      "loss: 0.686184 accuracy: 79.0\n",
      "loss: 0.672031 accuracy: 80.0\n",
      "loss: 0.423548 accuracy: 89.0\n",
      "loss: 0.700234 accuracy: 77.0\n",
      "loss: 0.620714 accuracy: 84.0\n",
      "loss: 0.598161 accuracy: 81.0\n",
      "loss: 0.779936 accuracy: 74.0\n",
      "loss: 0.684374 accuracy: 83.0\n",
      "loss: 0.699392 accuracy: 75.0\n",
      "loss: 0.444862 accuracy: 87.0\n",
      "loss: 0.56825 accuracy: 86.0\n",
      "loss: 0.549357 accuracy: 84.0\n",
      "loss: 0.55279 accuracy: 81.0\n",
      "loss: 0.668527 accuracy: 75.0\n",
      "loss: 0.555703 accuracy: 77.0\n",
      "loss: 0.688441 accuracy: 80.0\n",
      "loss: 0.444756 accuracy: 86.0\n",
      "loss: 0.786883 accuracy: 80.0\n",
      "loss: 0.752127 accuracy: 75.0\n",
      "loss: 0.552092 accuracy: 79.0\n",
      "loss: 0.739626 accuracy: 78.0\n",
      "loss: 0.869812 accuracy: 72.0\n",
      "loss: 0.753851 accuracy: 72.0\n",
      "loss: 0.976634 accuracy: 68.0\n",
      "loss: 0.752058 accuracy: 77.0\n",
      "loss: 0.657468 accuracy: 78.0\n",
      "loss: 0.58161 accuracy: 84.0\n",
      "loss: 0.553266 accuracy: 84.0\n",
      "loss: 0.62164 accuracy: 78.0\n",
      "loss: 0.547357 accuracy: 83.0\n",
      "loss: 0.708242 accuracy: 73.0\n",
      "loss: 0.506739 accuracy: 81.0\n",
      "loss: 0.565403 accuracy: 84.0\n",
      "loss: 0.696445 accuracy: 79.0\n",
      "loss: 0.446022 accuracy: 88.0\n",
      "loss: 0.487199 accuracy: 85.0\n",
      "loss: 0.61284 accuracy: 79.0\n",
      "loss: 0.41631 accuracy: 83.0\n",
      "loss: 0.602365 accuracy: 84.0\n",
      "loss: 0.520462 accuracy: 82.0\n",
      "loss: 0.630912 accuracy: 77.0\n",
      "loss: 0.555219 accuracy: 85.0\n",
      "loss: 0.553308 accuracy: 84.0\n",
      "loss: 0.673276 accuracy: 79.0\n",
      "loss: 0.578628 accuracy: 80.0\n",
      "loss: 0.649179 accuracy: 78.0\n",
      "loss: 0.60328 accuracy: 83.0\n",
      "loss: 0.641847 accuracy: 77.0\n",
      "loss: 0.702502 accuracy: 78.0\n",
      "loss: 0.947515 accuracy: 74.0\n",
      "loss: 0.609586 accuracy: 84.0\n",
      "loss: 0.746019 accuracy: 75.0\n",
      "loss: 0.755868 accuracy: 74.0\n",
      "loss: 0.904478 accuracy: 75.0\n",
      "loss: 0.677279 accuracy: 81.0\n",
      "loss: 0.573334 accuracy: 82.0\n",
      "loss: 0.706242 accuracy: 69.0\n",
      "loss: 0.536331 accuracy: 82.0\n",
      "loss: 0.417068 accuracy: 88.0\n",
      "loss: 0.62139 accuracy: 80.0\n",
      "loss: 0.561991 accuracy: 87.0\n",
      "loss: 0.412609 accuracy: 88.0\n",
      "loss: 0.679782 accuracy: 81.0\n",
      "loss: 0.703661 accuracy: 79.0\n",
      "loss: 0.684079 accuracy: 81.0\n",
      "loss: 0.589332 accuracy: 80.0\n",
      "loss: 0.652233 accuracy: 81.0\n",
      "loss: 0.413732 accuracy: 84.0\n",
      "loss: 0.663109 accuracy: 79.0\n",
      "loss: 0.516064 accuracy: 87.0\n",
      "loss: 0.646386 accuracy: 81.0\n",
      "loss: 0.77436 accuracy: 81.0\n",
      "loss: 0.467166 accuracy: 85.0\n",
      "loss: 0.589561 accuracy: 81.0\n",
      "loss: 0.725703 accuracy: 84.0\n",
      "loss: 0.497452 accuracy: 86.0\n",
      "loss: 0.472656 accuracy: 84.0\n",
      "loss: 0.449897 accuracy: 89.0\n",
      "loss: 0.446571 accuracy: 84.0\n",
      "loss: 0.575678 accuracy: 82.0\n",
      "loss: 0.841376 accuracy: 73.0\n",
      "loss: 0.854981 accuracy: 76.0\n",
      "loss: 0.433274 accuracy: 87.0\n",
      "loss: 0.529951 accuracy: 86.0\n",
      "loss: 0.518385 accuracy: 85.0\n",
      "loss: 0.427007 accuracy: 86.0\n",
      "loss: 0.6341 accuracy: 80.0\n",
      "loss: 0.457822 accuracy: 86.0\n",
      "loss: 0.725405 accuracy: 82.0\n",
      "loss: 0.55283 accuracy: 84.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.646149 accuracy: 82.0\n",
      "loss: 0.621902 accuracy: 81.0\n",
      "loss: 0.574681 accuracy: 86.0\n",
      "loss: 0.44973 accuracy: 88.0\n",
      "loss: 0.548429 accuracy: 82.0\n",
      "loss: 0.503128 accuracy: 83.0\n",
      "loss: 0.518677 accuracy: 82.0\n",
      "loss: 0.49524 accuracy: 83.0\n",
      "loss: 0.641269 accuracy: 79.0\n",
      "loss: 0.436432 accuracy: 88.0\n",
      "loss: 0.708863 accuracy: 82.0\n",
      "loss: 0.610228 accuracy: 80.0\n",
      "loss: 0.650899 accuracy: 84.0\n",
      "loss: 0.823725 accuracy: 75.0\n",
      "loss: 0.813352 accuracy: 71.0\n",
      "loss: 0.659655 accuracy: 79.0\n",
      "loss: 0.514451 accuracy: 85.0\n",
      "loss: 0.534129 accuracy: 86.0\n",
      "loss: 0.670923 accuracy: 79.0\n",
      "loss: 0.674923 accuracy: 78.0\n",
      "loss: 0.723838 accuracy: 83.0\n",
      "loss: 0.478418 accuracy: 84.0\n",
      "loss: 0.643194 accuracy: 78.0\n",
      "loss: 0.667668 accuracy: 80.0\n",
      "loss: 0.597882 accuracy: 78.0\n",
      "loss: 0.471797 accuracy: 84.0\n",
      "loss: 0.510707 accuracy: 84.0\n",
      "loss: 0.466958 accuracy: 83.0\n",
      "loss: 0.573412 accuracy: 81.0\n",
      "loss: 0.527393 accuracy: 85.0\n",
      "loss: 0.556579 accuracy: 82.0\n",
      "loss: 0.486233 accuracy: 87.0\n",
      "loss: 0.649318 accuracy: 85.0\n",
      "loss: 0.550756 accuracy: 83.0\n",
      "loss: 0.668499 accuracy: 79.0\n",
      "loss: 0.532427 accuracy: 81.0\n",
      "loss: 0.604871 accuracy: 84.0\n",
      "loss: 0.431416 accuracy: 87.0\n",
      "loss: 0.515965 accuracy: 82.0\n",
      "loss: 0.54513 accuracy: 83.0\n",
      "loss: 0.413858 accuracy: 90.0\n",
      "loss: 0.37056 accuracy: 90.0\n",
      "loss: 0.542952 accuracy: 82.0\n",
      "loss: 0.4086 accuracy: 89.0\n",
      "loss: 0.609594 accuracy: 81.0\n",
      "loss: 0.531302 accuracy: 79.0\n",
      "loss: 0.641581 accuracy: 77.0\n",
      "loss: 0.483291 accuracy: 85.0\n",
      "loss: 0.590881 accuracy: 84.0\n",
      "loss: 0.692185 accuracy: 79.0\n",
      "loss: 0.397238 accuracy: 91.0\n",
      "loss: 0.586931 accuracy: 83.0\n",
      "loss: 0.667667 accuracy: 83.0\n",
      "loss: 0.78283 accuracy: 79.0\n",
      "loss: 0.47834 accuracy: 83.0\n",
      "loss: 0.689666 accuracy: 82.0\n",
      "loss: 0.635651 accuracy: 82.0\n",
      "loss: 0.796877 accuracy: 79.0\n",
      "loss: 0.658344 accuracy: 79.0\n",
      "loss: 0.623368 accuracy: 86.0\n",
      "loss: 0.47735 accuracy: 87.0\n",
      "loss: 0.599415 accuracy: 82.0\n",
      "loss: 0.754772 accuracy: 79.0\n",
      "loss: 0.4762 accuracy: 82.0\n",
      "loss: 0.416361 accuracy: 88.0\n",
      "loss: 0.566932 accuracy: 79.0\n",
      "loss: 0.495691 accuracy: 86.0\n",
      "loss: 0.627983 accuracy: 79.0\n",
      "loss: 0.59309 accuracy: 85.0\n",
      "loss: 0.498748 accuracy: 87.0\n",
      "loss: 0.65273 accuracy: 86.0\n",
      "loss: 0.503647 accuracy: 85.0\n",
      "loss: 0.642827 accuracy: 85.0\n",
      "loss: 0.49997 accuracy: 88.0\n",
      "loss: 0.523343 accuracy: 84.0\n",
      "loss: 0.52228 accuracy: 84.0\n",
      "loss: 0.34576 accuracy: 93.0\n",
      "loss: 0.525277 accuracy: 87.0\n",
      "loss: 0.540435 accuracy: 83.0\n",
      "loss: 0.496146 accuracy: 82.0\n",
      "loss: 0.45202 accuracy: 84.0\n",
      "loss: 0.377564 accuracy: 90.0\n",
      "loss: 0.374475 accuracy: 89.0\n",
      "loss: 0.471827 accuracy: 89.0\n",
      "loss: 0.613887 accuracy: 86.0\n",
      "loss: 0.518836 accuracy: 84.0\n",
      "loss: 0.520421 accuracy: 82.0\n",
      "loss: 0.481489 accuracy: 90.0\n",
      "loss: 0.486081 accuracy: 83.0\n",
      "loss: 0.520166 accuracy: 83.0\n",
      "loss: 0.615592 accuracy: 82.0\n",
      "loss: 0.6454 accuracy: 79.0\n",
      "loss: 0.588361 accuracy: 83.0\n",
      "loss: 0.598221 accuracy: 85.0\n",
      "loss: 0.345258 accuracy: 88.0\n",
      "loss: 0.457443 accuracy: 86.0\n",
      "loss: 0.54419 accuracy: 85.0\n",
      "loss: 0.495951 accuracy: 86.0\n",
      "loss: 0.638292 accuracy: 80.0\n",
      "loss: 0.6187 accuracy: 86.0\n",
      "loss: 0.611037 accuracy: 87.0\n",
      "loss: 0.665544 accuracy: 84.0\n",
      "loss: 0.61229 accuracy: 83.0\n",
      "loss: 0.660967 accuracy: 75.0\n",
      "loss: 0.329824 accuracy: 91.0\n",
      "loss: 0.740381 accuracy: 78.0\n",
      "loss: 0.352073 accuracy: 89.0\n",
      "loss: 0.625395 accuracy: 83.0\n",
      "loss: 0.549352 accuracy: 75.0\n",
      "loss: 0.50461 accuracy: 87.0\n",
      "loss: 0.542223 accuracy: 87.0\n",
      "loss: 0.432615 accuracy: 87.0\n",
      "loss: 0.433492 accuracy: 88.0\n",
      "loss: 0.603788 accuracy: 83.0\n",
      "loss: 0.539372 accuracy: 86.0\n",
      "loss: 0.531146 accuracy: 88.0\n",
      "loss: 0.463761 accuracy: 87.0\n",
      "loss: 0.500384 accuracy: 88.0\n",
      "epoch 2\n",
      "loss: 0.517444 accuracy: 85.0\n",
      "loss: 0.473443 accuracy: 86.0\n",
      "loss: 0.632588 accuracy: 81.0\n",
      "loss: 0.604743 accuracy: 78.0\n",
      "loss: 0.486791 accuracy: 86.0\n",
      "loss: 0.42619 accuracy: 86.0\n",
      "loss: 0.546816 accuracy: 81.0\n",
      "loss: 0.560845 accuracy: 82.0\n",
      "loss: 0.301868 accuracy: 93.0\n",
      "loss: 0.576783 accuracy: 82.0\n",
      "loss: 0.58005 accuracy: 81.0\n",
      "loss: 0.502098 accuracy: 86.0\n",
      "loss: 0.356132 accuracy: 89.0\n",
      "loss: 0.442091 accuracy: 86.0\n",
      "loss: 0.385906 accuracy: 86.0\n",
      "loss: 0.522535 accuracy: 88.0\n",
      "loss: 0.484521 accuracy: 86.0\n",
      "loss: 0.659742 accuracy: 82.0\n",
      "loss: 0.329947 accuracy: 87.0\n",
      "loss: 0.520648 accuracy: 82.0\n",
      "loss: 0.443821 accuracy: 87.0\n",
      "loss: 0.372234 accuracy: 88.0\n",
      "loss: 0.469768 accuracy: 85.0\n",
      "loss: 0.510496 accuracy: 87.0\n",
      "loss: 0.434519 accuracy: 86.0\n",
      "loss: 0.548672 accuracy: 79.0\n",
      "loss: 0.648914 accuracy: 78.0\n",
      "loss: 0.387123 accuracy: 90.0\n",
      "loss: 0.380108 accuracy: 89.0\n",
      "loss: 0.4428 accuracy: 82.0\n",
      "loss: 0.381013 accuracy: 92.0\n",
      "loss: 0.484774 accuracy: 84.0\n",
      "loss: 0.577417 accuracy: 85.0\n",
      "loss: 0.535406 accuracy: 80.0\n",
      "loss: 0.393761 accuracy: 87.0\n",
      "loss: 0.364287 accuracy: 88.0\n",
      "loss: 0.493927 accuracy: 84.0\n",
      "loss: 0.541898 accuracy: 89.0\n",
      "loss: 0.294343 accuracy: 90.0\n",
      "loss: 0.467689 accuracy: 86.0\n",
      "loss: 0.475099 accuracy: 82.0\n",
      "loss: 0.347593 accuracy: 88.0\n",
      "loss: 0.538633 accuracy: 85.0\n",
      "loss: 0.499448 accuracy: 86.0\n",
      "loss: 0.413384 accuracy: 89.0\n",
      "loss: 0.537296 accuracy: 88.0\n",
      "loss: 0.554806 accuracy: 86.0\n",
      "loss: 0.2941 accuracy: 89.0\n",
      "loss: 0.406069 accuracy: 90.0\n",
      "loss: 0.363421 accuracy: 89.0\n",
      "loss: 0.355276 accuracy: 84.0\n",
      "loss: 0.364773 accuracy: 92.0\n",
      "loss: 0.320364 accuracy: 93.0\n",
      "loss: 0.360493 accuracy: 90.0\n",
      "loss: 0.382749 accuracy: 85.0\n",
      "loss: 0.438178 accuracy: 84.0\n",
      "loss: 0.535514 accuracy: 86.0\n",
      "loss: 0.487258 accuracy: 81.0\n",
      "loss: 0.466262 accuracy: 88.0\n",
      "loss: 0.567099 accuracy: 86.0\n",
      "loss: 0.319636 accuracy: 93.0\n",
      "loss: 0.356053 accuracy: 88.0\n",
      "loss: 0.412615 accuracy: 90.0\n",
      "loss: 0.488119 accuracy: 84.0\n",
      "loss: 0.445403 accuracy: 90.0\n",
      "loss: 0.462224 accuracy: 87.0\n",
      "loss: 0.293854 accuracy: 91.0\n",
      "loss: 0.577111 accuracy: 86.0\n",
      "loss: 0.333724 accuracy: 88.0\n",
      "loss: 0.479126 accuracy: 87.0\n",
      "loss: 0.613698 accuracy: 87.0\n",
      "loss: 0.616412 accuracy: 84.0\n",
      "loss: 0.40897 accuracy: 91.0\n",
      "loss: 0.236051 accuracy: 92.0\n",
      "loss: 0.562979 accuracy: 87.0\n",
      "loss: 0.522448 accuracy: 87.0\n",
      "loss: 0.365525 accuracy: 90.0\n",
      "loss: 0.42467 accuracy: 89.0\n",
      "loss: 0.405928 accuracy: 86.0\n",
      "loss: 0.418544 accuracy: 83.0\n",
      "loss: 0.416418 accuracy: 90.0\n",
      "loss: 0.506051 accuracy: 83.0\n",
      "loss: 0.500739 accuracy: 84.0\n",
      "loss: 0.39624 accuracy: 90.0\n",
      "loss: 0.521812 accuracy: 88.0\n",
      "loss: 0.45908 accuracy: 85.0\n",
      "loss: 0.53739 accuracy: 89.0\n",
      "loss: 0.382036 accuracy: 90.0\n",
      "loss: 0.575893 accuracy: 84.0\n",
      "loss: 0.378227 accuracy: 89.0\n",
      "loss: 0.396597 accuracy: 88.0\n",
      "loss: 0.544572 accuracy: 82.0\n",
      "loss: 0.574447 accuracy: 87.0\n",
      "loss: 0.366919 accuracy: 89.0\n",
      "loss: 0.539412 accuracy: 86.0\n",
      "loss: 0.628892 accuracy: 85.0\n",
      "loss: 0.436264 accuracy: 85.0\n",
      "loss: 0.478963 accuracy: 88.0\n",
      "loss: 0.483521 accuracy: 88.0\n",
      "loss: 0.51298 accuracy: 85.0\n",
      "loss: 0.419526 accuracy: 91.0\n",
      "loss: 0.325822 accuracy: 91.0\n",
      "loss: 0.586395 accuracy: 87.0\n",
      "loss: 0.335237 accuracy: 90.0\n",
      "loss: 0.473375 accuracy: 86.0\n",
      "loss: 0.538677 accuracy: 82.0\n",
      "loss: 0.321522 accuracy: 92.0\n",
      "loss: 0.51682 accuracy: 86.0\n",
      "loss: 0.394219 accuracy: 87.0\n",
      "loss: 0.637429 accuracy: 83.0\n",
      "loss: 0.447709 accuracy: 86.0\n",
      "loss: 0.346061 accuracy: 91.0\n",
      "loss: 0.507039 accuracy: 84.0\n",
      "loss: 0.451178 accuracy: 88.0\n",
      "loss: 0.564352 accuracy: 84.0\n",
      "loss: 0.481726 accuracy: 87.0\n",
      "loss: 0.536283 accuracy: 88.0\n",
      "loss: 0.474003 accuracy: 88.0\n",
      "loss: 0.39355 accuracy: 88.0\n",
      "loss: 0.594176 accuracy: 86.0\n",
      "loss: 0.583566 accuracy: 84.0\n",
      "loss: 0.526821 accuracy: 84.0\n",
      "loss: 0.454981 accuracy: 86.0\n",
      "loss: 0.61152 accuracy: 82.0\n",
      "loss: 0.398531 accuracy: 89.0\n",
      "loss: 0.235413 accuracy: 94.0\n",
      "loss: 0.307566 accuracy: 90.0\n",
      "loss: 0.314086 accuracy: 91.0\n",
      "loss: 0.703491 accuracy: 83.0\n",
      "loss: 0.551148 accuracy: 85.0\n",
      "loss: 0.639479 accuracy: 78.0\n",
      "loss: 0.596615 accuracy: 84.0\n",
      "loss: 0.388587 accuracy: 88.0\n",
      "loss: 0.402777 accuracy: 88.0\n",
      "loss: 0.565096 accuracy: 81.0\n",
      "loss: 0.380796 accuracy: 90.0\n",
      "loss: 0.446054 accuracy: 87.0\n",
      "loss: 0.339171 accuracy: 91.0\n",
      "loss: 0.548666 accuracy: 84.0\n",
      "loss: 0.565376 accuracy: 81.0\n",
      "loss: 0.393426 accuracy: 90.0\n",
      "loss: 0.361502 accuracy: 88.0\n",
      "loss: 0.282416 accuracy: 91.0\n",
      "loss: 0.40116 accuracy: 86.0\n",
      "loss: 0.621075 accuracy: 83.0\n",
      "loss: 0.347836 accuracy: 91.0\n",
      "loss: 0.358378 accuracy: 91.0\n",
      "loss: 0.428162 accuracy: 88.0\n",
      "loss: 0.433789 accuracy: 85.0\n",
      "loss: 0.511038 accuracy: 86.0\n",
      "loss: 0.441279 accuracy: 83.0\n",
      "loss: 0.671608 accuracy: 81.0\n",
      "loss: 0.622308 accuracy: 78.0\n",
      "loss: 0.416686 accuracy: 87.0\n",
      "loss: 0.62982 accuracy: 84.0\n",
      "loss: 0.296631 accuracy: 90.0\n",
      "loss: 0.550751 accuracy: 82.0\n",
      "loss: 0.450536 accuracy: 88.0\n",
      "loss: 0.39982 accuracy: 88.0\n",
      "loss: 0.405019 accuracy: 89.0\n",
      "loss: 0.526452 accuracy: 85.0\n",
      "loss: 0.427525 accuracy: 80.0\n",
      "loss: 0.401463 accuracy: 88.0\n",
      "loss: 0.369971 accuracy: 92.0\n",
      "loss: 0.508625 accuracy: 88.0\n",
      "loss: 0.535558 accuracy: 80.0\n",
      "loss: 0.468353 accuracy: 84.0\n",
      "loss: 0.327899 accuracy: 89.0\n",
      "loss: 0.381152 accuracy: 89.0\n",
      "loss: 0.674154 accuracy: 84.0\n",
      "loss: 0.315557 accuracy: 89.0\n",
      "loss: 0.421534 accuracy: 88.0\n",
      "loss: 0.303896 accuracy: 90.0\n",
      "loss: 0.410984 accuracy: 89.0\n",
      "loss: 0.424715 accuracy: 93.0\n",
      "loss: 0.375872 accuracy: 91.0\n",
      "loss: 0.33361 accuracy: 89.0\n",
      "loss: 0.527625 accuracy: 87.0\n",
      "loss: 0.368007 accuracy: 89.0\n",
      "loss: 0.423258 accuracy: 90.0\n",
      "loss: 0.388864 accuracy: 87.0\n",
      "loss: 0.298513 accuracy: 93.0\n",
      "loss: 0.367352 accuracy: 91.0\n",
      "loss: 0.376112 accuracy: 88.0\n",
      "loss: 0.327736 accuracy: 89.0\n",
      "loss: 0.53315 accuracy: 88.0\n",
      "loss: 0.495177 accuracy: 85.0\n",
      "loss: 0.340582 accuracy: 88.0\n",
      "loss: 0.260055 accuracy: 93.0\n",
      "loss: 0.527295 accuracy: 81.0\n",
      "loss: 0.409115 accuracy: 86.0\n",
      "loss: 0.383036 accuracy: 86.0\n",
      "loss: 0.421463 accuracy: 89.0\n",
      "loss: 0.582457 accuracy: 81.0\n",
      "loss: 0.378109 accuracy: 88.0\n",
      "loss: 0.34794 accuracy: 87.0\n",
      "loss: 0.38183 accuracy: 90.0\n",
      "loss: 0.569434 accuracy: 84.0\n",
      "loss: 0.519434 accuracy: 85.0\n",
      "loss: 0.328317 accuracy: 88.0\n",
      "loss: 0.542044 accuracy: 82.0\n",
      "loss: 0.434159 accuracy: 88.0\n",
      "loss: 0.302752 accuracy: 96.0\n",
      "loss: 0.3402 accuracy: 88.0\n",
      "loss: 0.483239 accuracy: 89.0\n",
      "loss: 0.383089 accuracy: 90.0\n",
      "loss: 0.346371 accuracy: 90.0\n",
      "loss: 0.427923 accuracy: 83.0\n",
      "loss: 0.516604 accuracy: 85.0\n",
      "loss: 0.402712 accuracy: 88.0\n",
      "loss: 0.320074 accuracy: 91.0\n",
      "loss: 0.489874 accuracy: 91.0\n",
      "loss: 0.453626 accuracy: 85.0\n",
      "loss: 0.459287 accuracy: 89.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.339096 accuracy: 91.0\n",
      "loss: 0.627132 accuracy: 81.0\n",
      "loss: 0.272423 accuracy: 93.0\n",
      "loss: 0.316135 accuracy: 90.0\n",
      "loss: 0.500695 accuracy: 86.0\n",
      "loss: 0.481726 accuracy: 86.0\n",
      "loss: 0.573603 accuracy: 84.0\n",
      "loss: 0.396408 accuracy: 87.0\n",
      "loss: 0.27981 accuracy: 91.0\n",
      "loss: 0.550941 accuracy: 86.0\n",
      "loss: 0.364517 accuracy: 90.0\n",
      "loss: 0.48782 accuracy: 88.0\n",
      "loss: 0.295309 accuracy: 91.0\n",
      "loss: 0.266669 accuracy: 94.0\n",
      "loss: 0.467092 accuracy: 89.0\n",
      "loss: 0.236238 accuracy: 92.0\n",
      "loss: 0.509121 accuracy: 87.0\n",
      "loss: 0.233575 accuracy: 94.0\n",
      "loss: 0.283318 accuracy: 92.0\n",
      "loss: 0.415919 accuracy: 90.0\n",
      "loss: 0.369294 accuracy: 88.0\n",
      "loss: 0.642046 accuracy: 85.0\n",
      "loss: 0.370543 accuracy: 88.0\n",
      "loss: 0.594221 accuracy: 81.0\n",
      "loss: 0.445222 accuracy: 85.0\n",
      "loss: 0.479537 accuracy: 89.0\n",
      "loss: 0.284906 accuracy: 93.0\n",
      "loss: 0.459336 accuracy: 88.0\n",
      "loss: 0.326922 accuracy: 88.0\n",
      "loss: 0.30149 accuracy: 94.0\n",
      "loss: 0.484342 accuracy: 85.0\n",
      "loss: 0.436363 accuracy: 88.0\n",
      "loss: 0.245489 accuracy: 93.0\n",
      "loss: 0.662924 accuracy: 80.0\n",
      "loss: 0.50669 accuracy: 88.0\n",
      "loss: 0.267477 accuracy: 93.0\n",
      "loss: 0.393754 accuracy: 86.0\n",
      "loss: 0.397837 accuracy: 90.0\n",
      "loss: 0.312811 accuracy: 92.0\n",
      "loss: 0.624379 accuracy: 87.0\n",
      "loss: 0.650336 accuracy: 82.0\n",
      "loss: 0.533756 accuracy: 80.0\n",
      "loss: 0.438521 accuracy: 89.0\n",
      "loss: 0.496121 accuracy: 85.0\n",
      "loss: 0.388111 accuracy: 87.0\n",
      "loss: 0.468888 accuracy: 89.0\n",
      "loss: 0.316223 accuracy: 92.0\n",
      "loss: 0.369528 accuracy: 85.0\n",
      "loss: 0.436721 accuracy: 87.0\n",
      "loss: 0.464023 accuracy: 84.0\n",
      "loss: 0.313109 accuracy: 92.0\n",
      "loss: 0.473611 accuracy: 85.0\n",
      "loss: 0.252105 accuracy: 93.0\n",
      "loss: 0.474618 accuracy: 86.0\n",
      "loss: 0.452001 accuracy: 86.0\n",
      "loss: 0.318585 accuracy: 90.0\n",
      "loss: 0.243853 accuracy: 93.0\n",
      "loss: 0.325808 accuracy: 89.0\n",
      "loss: 0.403455 accuracy: 86.0\n",
      "loss: 0.480614 accuracy: 88.0\n",
      "loss: 0.276755 accuracy: 92.0\n",
      "loss: 0.573432 accuracy: 83.0\n",
      "loss: 0.488606 accuracy: 88.0\n",
      "loss: 0.541763 accuracy: 86.0\n",
      "loss: 0.302219 accuracy: 92.0\n",
      "loss: 0.396199 accuracy: 89.0\n",
      "loss: 0.506807 accuracy: 77.0\n",
      "loss: 0.518856 accuracy: 85.0\n",
      "loss: 0.434469 accuracy: 86.0\n",
      "loss: 0.330151 accuracy: 91.0\n",
      "loss: 0.347187 accuracy: 90.0\n",
      "loss: 0.349685 accuracy: 90.0\n",
      "loss: 0.53057 accuracy: 88.0\n",
      "loss: 0.413408 accuracy: 86.0\n",
      "loss: 0.254333 accuracy: 92.0\n",
      "loss: 0.25437 accuracy: 94.0\n",
      "loss: 0.214054 accuracy: 91.0\n",
      "loss: 0.478444 accuracy: 89.0\n",
      "loss: 0.303977 accuracy: 91.0\n",
      "loss: 0.380671 accuracy: 91.0\n",
      "loss: 0.479797 accuracy: 89.0\n",
      "loss: 0.317868 accuracy: 91.0\n",
      "loss: 0.399474 accuracy: 86.0\n",
      "loss: 0.375452 accuracy: 87.0\n",
      "loss: 0.330636 accuracy: 92.0\n",
      "loss: 0.370042 accuracy: 90.0\n",
      "loss: 0.616068 accuracy: 79.0\n",
      "loss: 0.483671 accuracy: 86.0\n",
      "loss: 0.360836 accuracy: 89.0\n",
      "loss: 0.600973 accuracy: 89.0\n",
      "loss: 0.362808 accuracy: 91.0\n",
      "loss: 0.333202 accuracy: 89.0\n",
      "loss: 0.387709 accuracy: 88.0\n",
      "loss: 0.589209 accuracy: 85.0\n",
      "loss: 0.34294 accuracy: 89.0\n",
      "loss: 0.353818 accuracy: 90.0\n",
      "loss: 0.365949 accuracy: 90.0\n",
      "loss: 0.29971 accuracy: 95.0\n",
      "loss: 0.346198 accuracy: 88.0\n",
      "loss: 0.286477 accuracy: 90.0\n",
      "loss: 0.425286 accuracy: 83.0\n",
      "loss: 0.453874 accuracy: 90.0\n",
      "loss: 0.399607 accuracy: 85.0\n",
      "loss: 0.459426 accuracy: 84.0\n",
      "loss: 0.173851 accuracy: 97.0\n",
      "loss: 0.627878 accuracy: 86.0\n",
      "loss: 0.317073 accuracy: 90.0\n",
      "loss: 0.530464 accuracy: 85.0\n",
      "loss: 0.192101 accuracy: 96.0\n",
      "loss: 0.398612 accuracy: 85.0\n",
      "loss: 0.379241 accuracy: 93.0\n",
      "loss: 0.449044 accuracy: 85.0\n",
      "loss: 0.353964 accuracy: 87.0\n",
      "loss: 0.455937 accuracy: 84.0\n",
      "loss: 0.385053 accuracy: 88.0\n",
      "loss: 0.284704 accuracy: 94.0\n",
      "loss: 0.384033 accuracy: 92.0\n",
      "loss: 0.278131 accuracy: 93.0\n",
      "loss: 0.470015 accuracy: 82.0\n",
      "loss: 0.272715 accuracy: 92.0\n",
      "loss: 0.367244 accuracy: 89.0\n",
      "loss: 0.504367 accuracy: 83.0\n",
      "loss: 0.252777 accuracy: 92.0\n",
      "loss: 0.313386 accuracy: 88.0\n",
      "loss: 0.298329 accuracy: 88.0\n",
      "loss: 0.573746 accuracy: 84.0\n",
      "loss: 0.371439 accuracy: 95.0\n",
      "loss: 0.300515 accuracy: 88.0\n",
      "loss: 0.210224 accuracy: 91.0\n",
      "loss: 0.389655 accuracy: 92.0\n",
      "loss: 0.227025 accuracy: 93.0\n",
      "loss: 0.273988 accuracy: 93.0\n",
      "loss: 0.405448 accuracy: 92.0\n",
      "loss: 0.400638 accuracy: 88.0\n",
      "loss: 0.505508 accuracy: 83.0\n",
      "loss: 0.350533 accuracy: 88.0\n",
      "loss: 0.353582 accuracy: 93.0\n",
      "loss: 0.230949 accuracy: 94.0\n",
      "loss: 0.423461 accuracy: 88.0\n",
      "loss: 0.410086 accuracy: 86.0\n",
      "loss: 0.330774 accuracy: 88.0\n",
      "loss: 0.397063 accuracy: 90.0\n",
      "loss: 0.471389 accuracy: 86.0\n",
      "loss: 0.275708 accuracy: 90.0\n",
      "loss: 0.219377 accuracy: 93.0\n",
      "loss: 0.336958 accuracy: 93.0\n",
      "loss: 0.383914 accuracy: 91.0\n",
      "loss: 0.47255 accuracy: 84.0\n",
      "loss: 0.447582 accuracy: 87.0\n",
      "loss: 0.210933 accuracy: 95.0\n",
      "loss: 0.248578 accuracy: 94.0\n",
      "loss: 0.289115 accuracy: 88.0\n",
      "loss: 0.23614 accuracy: 93.0\n",
      "loss: 0.244797 accuracy: 91.0\n",
      "loss: 0.323826 accuracy: 92.0\n",
      "loss: 0.319918 accuracy: 88.0\n",
      "loss: 0.396739 accuracy: 91.0\n",
      "loss: 0.317816 accuracy: 88.0\n",
      "loss: 0.190924 accuracy: 94.0\n",
      "loss: 0.290862 accuracy: 90.0\n",
      "loss: 0.418284 accuracy: 87.0\n",
      "loss: 0.336273 accuracy: 91.0\n",
      "loss: 0.530358 accuracy: 85.0\n",
      "loss: 0.489146 accuracy: 85.0\n",
      "loss: 0.540048 accuracy: 81.0\n",
      "loss: 0.353942 accuracy: 89.0\n",
      "loss: 0.463685 accuracy: 88.0\n",
      "loss: 0.266451 accuracy: 93.0\n",
      "loss: 0.343618 accuracy: 92.0\n",
      "loss: 0.434827 accuracy: 91.0\n",
      "loss: 0.442119 accuracy: 88.0\n",
      "loss: 0.404463 accuracy: 91.0\n",
      "loss: 0.346499 accuracy: 90.0\n",
      "loss: 0.258651 accuracy: 92.0\n",
      "loss: 0.447192 accuracy: 86.0\n",
      "loss: 0.499383 accuracy: 87.0\n",
      "loss: 0.420353 accuracy: 85.0\n",
      "loss: 0.244519 accuracy: 94.0\n",
      "loss: 0.347389 accuracy: 89.0\n",
      "loss: 0.258046 accuracy: 91.0\n",
      "loss: 0.504661 accuracy: 90.0\n",
      "loss: 0.366859 accuracy: 87.0\n",
      "loss: 0.316772 accuracy: 91.0\n",
      "loss: 0.176602 accuracy: 95.0\n",
      "loss: 0.237797 accuracy: 90.0\n",
      "loss: 0.403857 accuracy: 88.0\n",
      "loss: 0.311942 accuracy: 94.0\n",
      "loss: 0.339174 accuracy: 90.0\n",
      "loss: 0.305707 accuracy: 92.0\n",
      "loss: 0.323127 accuracy: 88.0\n",
      "loss: 0.354375 accuracy: 89.0\n",
      "loss: 0.501124 accuracy: 85.0\n",
      "loss: 0.268537 accuracy: 92.0\n",
      "loss: 0.208679 accuracy: 95.0\n",
      "loss: 0.366587 accuracy: 88.0\n",
      "loss: 0.327001 accuracy: 91.0\n",
      "loss: 0.279052 accuracy: 90.0\n",
      "loss: 0.396204 accuracy: 89.0\n",
      "loss: 0.283246 accuracy: 92.0\n",
      "loss: 0.162264 accuracy: 94.0\n",
      "loss: 0.482302 accuracy: 85.0\n",
      "loss: 0.408854 accuracy: 87.0\n",
      "loss: 0.364334 accuracy: 87.0\n",
      "loss: 0.304559 accuracy: 94.0\n",
      "loss: 0.336404 accuracy: 90.0\n",
      "loss: 0.451039 accuracy: 89.0\n",
      "loss: 0.420376 accuracy: 87.0\n",
      "loss: 0.698295 accuracy: 80.0\n",
      "loss: 0.29082 accuracy: 93.0\n",
      "loss: 0.318745 accuracy: 89.0\n",
      "loss: 0.504585 accuracy: 86.0\n",
      "loss: 0.439622 accuracy: 90.0\n",
      "loss: 0.241976 accuracy: 93.0\n",
      "loss: 0.281753 accuracy: 87.0\n",
      "loss: 0.346138 accuracy: 88.0\n",
      "loss: 0.415785 accuracy: 89.0\n",
      "loss: 0.444848 accuracy: 89.0\n",
      "loss: 0.313566 accuracy: 93.0\n",
      "loss: 0.413124 accuracy: 91.0\n",
      "loss: 0.303904 accuracy: 89.0\n",
      "loss: 0.222703 accuracy: 95.0\n",
      "loss: 0.427065 accuracy: 87.0\n",
      "loss: 0.304207 accuracy: 93.0\n",
      "loss: 0.47732 accuracy: 86.0\n",
      "loss: 0.36049 accuracy: 90.0\n",
      "loss: 0.439943 accuracy: 86.0\n",
      "loss: 0.471197 accuracy: 87.0\n",
      "loss: 0.342067 accuracy: 91.0\n",
      "loss: 0.389123 accuracy: 91.0\n",
      "loss: 0.280857 accuracy: 88.0\n",
      "loss: 0.346373 accuracy: 90.0\n",
      "loss: 0.459313 accuracy: 91.0\n",
      "loss: 0.272849 accuracy: 92.0\n",
      "loss: 0.504333 accuracy: 86.0\n",
      "loss: 0.497594 accuracy: 90.0\n",
      "loss: 0.240798 accuracy: 93.0\n",
      "loss: 0.449153 accuracy: 84.0\n",
      "loss: 0.343077 accuracy: 88.0\n",
      "loss: 0.359061 accuracy: 96.0\n",
      "loss: 0.401238 accuracy: 92.0\n",
      "loss: 0.26523 accuracy: 93.0\n",
      "loss: 0.35186 accuracy: 87.0\n",
      "loss: 0.403209 accuracy: 90.0\n",
      "loss: 0.3301 accuracy: 85.0\n",
      "loss: 0.266355 accuracy: 92.0\n",
      "loss: 0.182681 accuracy: 94.0\n",
      "loss: 0.400533 accuracy: 87.0\n",
      "loss: 0.339173 accuracy: 91.0\n",
      "loss: 0.354168 accuracy: 88.0\n",
      "loss: 0.464723 accuracy: 88.0\n",
      "loss: 0.464478 accuracy: 88.0\n",
      "loss: 0.175823 accuracy: 94.0\n",
      "loss: 0.35973 accuracy: 88.0\n",
      "loss: 0.262728 accuracy: 91.0\n",
      "loss: 0.453155 accuracy: 88.0\n",
      "loss: 0.3812 accuracy: 88.0\n",
      "loss: 0.356095 accuracy: 88.0\n",
      "loss: 0.465843 accuracy: 85.0\n",
      "loss: 0.389348 accuracy: 90.0\n",
      "loss: 0.303943 accuracy: 90.0\n",
      "loss: 0.568755 accuracy: 90.0\n",
      "loss: 0.324408 accuracy: 90.0\n",
      "loss: 0.465834 accuracy: 88.0\n",
      "loss: 0.42725 accuracy: 88.0\n",
      "loss: 0.303119 accuracy: 91.0\n",
      "loss: 0.287313 accuracy: 91.0\n",
      "loss: 0.501935 accuracy: 87.0\n",
      "loss: 0.196573 accuracy: 94.0\n",
      "loss: 0.402397 accuracy: 88.0\n",
      "loss: 0.288436 accuracy: 89.0\n",
      "loss: 0.321818 accuracy: 90.0\n",
      "loss: 0.368169 accuracy: 88.0\n",
      "loss: 0.30226 accuracy: 91.0\n",
      "loss: 0.365088 accuracy: 93.0\n",
      "loss: 0.19646 accuracy: 92.0\n",
      "loss: 0.245738 accuracy: 95.0\n",
      "loss: 0.15741 accuracy: 95.0\n",
      "loss: 0.280519 accuracy: 90.0\n",
      "loss: 0.36487 accuracy: 87.0\n",
      "loss: 0.329354 accuracy: 91.0\n",
      "loss: 0.312759 accuracy: 91.0\n",
      "loss: 0.18742 accuracy: 93.0\n",
      "loss: 0.246679 accuracy: 92.0\n",
      "loss: 0.35523 accuracy: 91.0\n",
      "loss: 0.509601 accuracy: 88.0\n",
      "loss: 0.24086 accuracy: 92.0\n",
      "loss: 0.355902 accuracy: 92.0\n",
      "loss: 0.49269 accuracy: 89.0\n",
      "loss: 0.180623 accuracy: 94.0\n",
      "loss: 0.264193 accuracy: 92.0\n",
      "loss: 0.205645 accuracy: 95.0\n",
      "loss: 0.243213 accuracy: 92.0\n",
      "loss: 0.288581 accuracy: 93.0\n",
      "loss: 0.190392 accuracy: 95.0\n",
      "loss: 0.249949 accuracy: 93.0\n",
      "loss: 0.243696 accuracy: 93.0\n",
      "loss: 0.369343 accuracy: 89.0\n",
      "loss: 0.250119 accuracy: 89.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.369572 accuracy: 89.0\n",
      "loss: 0.305478 accuracy: 89.0\n",
      "loss: 0.224194 accuracy: 93.0\n",
      "loss: 0.334292 accuracy: 91.0\n",
      "loss: 0.413194 accuracy: 90.0\n",
      "loss: 0.388757 accuracy: 84.0\n",
      "loss: 0.262424 accuracy: 90.0\n",
      "loss: 0.302153 accuracy: 93.0\n",
      "loss: 0.23759 accuracy: 94.0\n",
      "loss: 0.207405 accuracy: 94.0\n",
      "loss: 0.394198 accuracy: 91.0\n",
      "loss: 0.243603 accuracy: 90.0\n",
      "loss: 0.179547 accuracy: 94.0\n",
      "loss: 0.449457 accuracy: 88.0\n",
      "loss: 0.268721 accuracy: 94.0\n",
      "loss: 0.399767 accuracy: 92.0\n",
      "loss: 0.262522 accuracy: 91.0\n",
      "loss: 0.362744 accuracy: 90.0\n",
      "loss: 0.255853 accuracy: 92.0\n",
      "loss: 0.338351 accuracy: 89.0\n",
      "loss: 0.317667 accuracy: 89.0\n",
      "loss: 0.305344 accuracy: 88.0\n",
      "loss: 0.211418 accuracy: 93.0\n",
      "loss: 0.329497 accuracy: 90.0\n",
      "loss: 0.223952 accuracy: 93.0\n",
      "loss: 0.424498 accuracy: 91.0\n",
      "loss: 0.285891 accuracy: 93.0\n",
      "loss: 0.331538 accuracy: 91.0\n",
      "loss: 0.314662 accuracy: 89.0\n",
      "loss: 0.282446 accuracy: 90.0\n",
      "loss: 0.216539 accuracy: 95.0\n",
      "loss: 0.228776 accuracy: 93.0\n",
      "loss: 0.376232 accuracy: 91.0\n",
      "loss: 0.234331 accuracy: 93.0\n",
      "loss: 0.247435 accuracy: 92.0\n",
      "loss: 0.182066 accuracy: 96.0\n",
      "loss: 0.339451 accuracy: 90.0\n",
      "epoch 3\n",
      "loss: 0.232535 accuracy: 91.0\n",
      "loss: 0.350306 accuracy: 90.0\n",
      "loss: 0.267355 accuracy: 88.0\n",
      "loss: 0.24158 accuracy: 92.0\n",
      "loss: 0.271715 accuracy: 93.0\n",
      "loss: 0.481776 accuracy: 87.0\n",
      "loss: 0.361007 accuracy: 94.0\n",
      "loss: 0.19446 accuracy: 94.0\n",
      "loss: 0.497893 accuracy: 85.0\n",
      "loss: 0.329304 accuracy: 91.0\n",
      "loss: 0.219968 accuracy: 95.0\n",
      "loss: 0.260101 accuracy: 91.0\n",
      "loss: 0.343075 accuracy: 90.0\n",
      "loss: 0.334992 accuracy: 90.0\n",
      "loss: 0.381081 accuracy: 84.0\n",
      "loss: 0.389083 accuracy: 90.0\n",
      "loss: 0.213058 accuracy: 94.0\n",
      "loss: 0.353942 accuracy: 89.0\n",
      "loss: 0.300938 accuracy: 90.0\n",
      "loss: 0.180007 accuracy: 96.0\n",
      "loss: 0.318399 accuracy: 88.0\n",
      "loss: 0.32891 accuracy: 88.0\n",
      "loss: 0.29415 accuracy: 91.0\n",
      "loss: 0.195329 accuracy: 95.0\n",
      "loss: 0.399326 accuracy: 89.0\n",
      "loss: 0.352277 accuracy: 91.0\n",
      "loss: 0.333984 accuracy: 94.0\n",
      "loss: 0.290395 accuracy: 91.0\n",
      "loss: 0.193945 accuracy: 92.0\n",
      "loss: 0.282739 accuracy: 92.0\n",
      "loss: 0.290085 accuracy: 88.0\n",
      "loss: 0.399863 accuracy: 91.0\n",
      "loss: 0.227499 accuracy: 92.0\n",
      "loss: 0.280819 accuracy: 90.0\n",
      "loss: 0.414269 accuracy: 91.0\n",
      "loss: 0.234764 accuracy: 95.0\n",
      "loss: 0.357277 accuracy: 85.0\n",
      "loss: 0.274611 accuracy: 92.0\n",
      "loss: 0.423128 accuracy: 89.0\n",
      "loss: 0.129132 accuracy: 96.0\n",
      "loss: 0.346405 accuracy: 90.0\n",
      "loss: 0.212345 accuracy: 94.0\n",
      "loss: 0.138156 accuracy: 97.0\n",
      "loss: 0.364785 accuracy: 92.0\n",
      "loss: 0.336264 accuracy: 91.0\n",
      "loss: 0.445239 accuracy: 88.0\n",
      "loss: 0.278014 accuracy: 94.0\n",
      "loss: 0.335154 accuracy: 90.0\n",
      "loss: 0.201372 accuracy: 92.0\n",
      "loss: 0.206188 accuracy: 94.0\n",
      "loss: 0.250991 accuracy: 89.0\n",
      "loss: 0.388024 accuracy: 88.0\n",
      "loss: 0.375956 accuracy: 86.0\n",
      "loss: 0.204035 accuracy: 94.0\n",
      "loss: 0.387161 accuracy: 90.0\n",
      "loss: 0.147117 accuracy: 96.0\n",
      "loss: 0.379166 accuracy: 87.0\n",
      "loss: 0.310456 accuracy: 89.0\n",
      "loss: 0.221932 accuracy: 96.0\n",
      "loss: 0.536502 accuracy: 89.0\n",
      "loss: 0.174559 accuracy: 94.0\n",
      "loss: 0.291968 accuracy: 92.0\n",
      "loss: 0.192898 accuracy: 94.0\n",
      "loss: 0.211464 accuracy: 93.0\n",
      "loss: 0.349525 accuracy: 89.0\n",
      "loss: 0.314449 accuracy: 88.0\n",
      "loss: 0.262407 accuracy: 93.0\n",
      "loss: 0.239725 accuracy: 93.0\n",
      "loss: 0.35985 accuracy: 90.0\n",
      "loss: 0.359768 accuracy: 89.0\n",
      "loss: 0.280724 accuracy: 93.0\n",
      "loss: 0.163231 accuracy: 95.0\n",
      "loss: 0.256596 accuracy: 91.0\n",
      "loss: 0.224758 accuracy: 93.0\n",
      "loss: 0.421797 accuracy: 87.0\n",
      "loss: 0.474371 accuracy: 82.0\n",
      "loss: 0.266437 accuracy: 93.0\n",
      "loss: 0.237143 accuracy: 93.0\n",
      "loss: 0.208386 accuracy: 93.0\n",
      "loss: 0.246027 accuracy: 94.0\n",
      "loss: 0.357556 accuracy: 94.0\n",
      "loss: 0.28863 accuracy: 94.0\n",
      "loss: 0.426439 accuracy: 88.0\n",
      "loss: 0.338107 accuracy: 87.0\n",
      "loss: 0.526391 accuracy: 84.0\n",
      "loss: 0.472017 accuracy: 83.0\n",
      "loss: 0.388749 accuracy: 91.0\n",
      "loss: 0.236595 accuracy: 92.0\n",
      "loss: 0.194512 accuracy: 92.0\n",
      "loss: 0.567331 accuracy: 85.0\n",
      "loss: 0.173698 accuracy: 97.0\n",
      "loss: 0.159108 accuracy: 96.0\n",
      "loss: 0.25239 accuracy: 93.0\n",
      "loss: 0.140028 accuracy: 94.0\n",
      "loss: 0.272964 accuracy: 93.0\n",
      "loss: 0.230922 accuracy: 96.0\n",
      "loss: 0.426906 accuracy: 89.0\n",
      "loss: 0.324042 accuracy: 88.0\n",
      "loss: 0.476421 accuracy: 88.0\n",
      "loss: 0.172989 accuracy: 95.0\n",
      "loss: 0.364052 accuracy: 89.0\n",
      "loss: 0.217139 accuracy: 92.0\n",
      "loss: 0.36758 accuracy: 89.0\n",
      "loss: 0.238905 accuracy: 94.0\n",
      "loss: 0.423418 accuracy: 86.0\n",
      "loss: 0.422945 accuracy: 89.0\n",
      "loss: 0.251702 accuracy: 92.0\n",
      "loss: 0.255434 accuracy: 92.0\n",
      "loss: 0.225651 accuracy: 93.0\n",
      "loss: 0.310102 accuracy: 91.0\n",
      "loss: 0.233904 accuracy: 94.0\n",
      "loss: 0.273504 accuracy: 94.0\n",
      "loss: 0.210605 accuracy: 93.0\n",
      "loss: 0.27495 accuracy: 95.0\n",
      "loss: 0.1565 accuracy: 95.0\n",
      "loss: 0.263697 accuracy: 91.0\n",
      "loss: 0.2303 accuracy: 95.0\n",
      "loss: 0.342899 accuracy: 89.0\n",
      "loss: 0.248942 accuracy: 90.0\n",
      "loss: 0.309636 accuracy: 91.0\n",
      "loss: 0.332261 accuracy: 91.0\n",
      "loss: 0.114506 accuracy: 96.0\n",
      "loss: 0.220677 accuracy: 94.0\n",
      "loss: 0.2959 accuracy: 93.0\n",
      "loss: 0.446745 accuracy: 88.0\n",
      "loss: 0.204387 accuracy: 96.0\n",
      "loss: 0.311085 accuracy: 90.0\n",
      "loss: 0.174987 accuracy: 97.0\n",
      "loss: 0.344189 accuracy: 90.0\n",
      "loss: 0.306503 accuracy: 91.0\n",
      "loss: 0.253584 accuracy: 90.0\n",
      "loss: 0.309552 accuracy: 89.0\n",
      "loss: 0.263707 accuracy: 92.0\n",
      "loss: 0.357299 accuracy: 89.0\n",
      "loss: 0.336683 accuracy: 93.0\n",
      "loss: 0.406062 accuracy: 87.0\n",
      "loss: 0.286227 accuracy: 90.0\n",
      "loss: 0.359006 accuracy: 90.0\n",
      "loss: 0.259857 accuracy: 93.0\n",
      "loss: 0.155342 accuracy: 92.0\n",
      "loss: 0.125619 accuracy: 95.0\n",
      "loss: 0.141747 accuracy: 96.0\n",
      "loss: 0.376502 accuracy: 89.0\n",
      "loss: 0.29454 accuracy: 92.0\n",
      "loss: 0.309896 accuracy: 90.0\n",
      "loss: 0.343054 accuracy: 90.0\n",
      "loss: 0.335876 accuracy: 92.0\n",
      "loss: 0.315368 accuracy: 90.0\n",
      "loss: 0.279486 accuracy: 93.0\n",
      "loss: 0.139554 accuracy: 95.0\n",
      "loss: 0.109847 accuracy: 97.0\n",
      "loss: 0.284342 accuracy: 89.0\n",
      "loss: 0.287282 accuracy: 90.0\n",
      "loss: 0.171801 accuracy: 97.0\n",
      "loss: 0.351889 accuracy: 90.0\n",
      "loss: 0.268205 accuracy: 94.0\n",
      "loss: 0.274744 accuracy: 92.0\n",
      "loss: 0.330662 accuracy: 90.0\n",
      "loss: 0.319004 accuracy: 91.0\n",
      "loss: 0.580011 accuracy: 85.0\n",
      "loss: 0.3841 accuracy: 86.0\n",
      "loss: 0.260861 accuracy: 90.0\n",
      "loss: 0.218856 accuracy: 94.0\n",
      "loss: 0.307208 accuracy: 93.0\n",
      "loss: 0.265628 accuracy: 91.0\n",
      "loss: 0.168325 accuracy: 94.0\n",
      "loss: 0.478972 accuracy: 92.0\n",
      "loss: 0.240575 accuracy: 94.0\n",
      "loss: 0.229714 accuracy: 93.0\n",
      "loss: 0.22709 accuracy: 95.0\n",
      "loss: 0.188587 accuracy: 96.0\n",
      "loss: 0.245565 accuracy: 93.0\n",
      "loss: 0.272577 accuracy: 91.0\n",
      "loss: 0.324063 accuracy: 91.0\n",
      "loss: 0.266005 accuracy: 93.0\n",
      "loss: 0.357267 accuracy: 90.0\n",
      "loss: 0.231346 accuracy: 94.0\n",
      "loss: 0.374635 accuracy: 87.0\n",
      "loss: 0.469592 accuracy: 83.0\n",
      "loss: 0.34533 accuracy: 88.0\n",
      "loss: 0.511611 accuracy: 85.0\n",
      "loss: 0.151119 accuracy: 95.0\n",
      "loss: 0.372888 accuracy: 91.0\n",
      "loss: 0.160972 accuracy: 97.0\n",
      "loss: 0.256379 accuracy: 95.0\n",
      "loss: 0.150275 accuracy: 95.0\n",
      "loss: 0.257006 accuracy: 94.0\n",
      "loss: 0.253212 accuracy: 94.0\n",
      "loss: 0.325937 accuracy: 93.0\n",
      "loss: 0.3391 accuracy: 91.0\n",
      "loss: 0.283055 accuracy: 91.0\n",
      "loss: 0.293525 accuracy: 90.0\n",
      "loss: 0.202272 accuracy: 93.0\n",
      "loss: 0.354983 accuracy: 91.0\n",
      "loss: 0.300212 accuracy: 90.0\n",
      "loss: 0.389404 accuracy: 92.0\n",
      "loss: 0.249897 accuracy: 93.0\n",
      "loss: 0.244963 accuracy: 93.0\n",
      "loss: 0.37316 accuracy: 92.0\n",
      "loss: 0.249277 accuracy: 92.0\n",
      "loss: 0.220848 accuracy: 92.0\n",
      "loss: 0.310095 accuracy: 89.0\n",
      "loss: 0.433107 accuracy: 88.0\n",
      "loss: 0.260367 accuracy: 94.0\n",
      "loss: 0.153996 accuracy: 95.0\n",
      "loss: 0.280957 accuracy: 89.0\n",
      "loss: 0.199172 accuracy: 95.0\n",
      "loss: 0.362517 accuracy: 91.0\n",
      "loss: 0.290504 accuracy: 90.0\n",
      "loss: 0.276829 accuracy: 91.0\n",
      "loss: 0.166616 accuracy: 93.0\n",
      "loss: 0.366567 accuracy: 88.0\n",
      "loss: 0.225883 accuracy: 93.0\n",
      "loss: 0.234192 accuracy: 94.0\n",
      "loss: 0.318074 accuracy: 89.0\n",
      "loss: 0.30799 accuracy: 91.0\n",
      "loss: 0.259093 accuracy: 94.0\n",
      "loss: 0.281359 accuracy: 93.0\n",
      "loss: 0.323357 accuracy: 90.0\n",
      "loss: 0.208256 accuracy: 93.0\n",
      "loss: 0.164945 accuracy: 97.0\n",
      "loss: 0.178622 accuracy: 98.0\n",
      "loss: 0.449382 accuracy: 89.0\n",
      "loss: 0.407545 accuracy: 87.0\n",
      "loss: 0.322215 accuracy: 92.0\n",
      "loss: 0.300005 accuracy: 90.0\n",
      "loss: 0.213028 accuracy: 95.0\n",
      "loss: 0.386355 accuracy: 87.0\n",
      "loss: 0.187908 accuracy: 94.0\n",
      "loss: 0.176297 accuracy: 96.0\n",
      "loss: 0.141414 accuracy: 96.0\n",
      "loss: 0.22396 accuracy: 91.0\n",
      "loss: 0.247676 accuracy: 91.0\n",
      "loss: 0.130272 accuracy: 94.0\n",
      "loss: 0.187316 accuracy: 96.0\n",
      "loss: 0.315335 accuracy: 91.0\n",
      "loss: 0.155925 accuracy: 96.0\n",
      "loss: 0.318052 accuracy: 89.0\n",
      "loss: 0.245601 accuracy: 93.0\n",
      "loss: 0.213332 accuracy: 91.0\n",
      "loss: 0.455178 accuracy: 87.0\n",
      "loss: 0.210794 accuracy: 91.0\n",
      "loss: 0.362228 accuracy: 92.0\n",
      "loss: 0.208997 accuracy: 92.0\n",
      "loss: 0.210342 accuracy: 93.0\n",
      "loss: 0.170118 accuracy: 97.0\n",
      "loss: 0.200419 accuracy: 95.0\n",
      "loss: 0.178287 accuracy: 95.0\n",
      "loss: 0.211006 accuracy: 94.0\n",
      "loss: 0.173837 accuracy: 95.0\n",
      "loss: 0.304855 accuracy: 90.0\n",
      "loss: 0.129758 accuracy: 95.0\n",
      "loss: 0.302879 accuracy: 90.0\n",
      "loss: 0.285769 accuracy: 91.0\n",
      "loss: 0.407523 accuracy: 91.0\n",
      "loss: 0.295044 accuracy: 92.0\n",
      "loss: 0.281718 accuracy: 91.0\n",
      "loss: 0.1927 accuracy: 94.0\n",
      "loss: 0.317952 accuracy: 90.0\n",
      "loss: 0.200544 accuracy: 94.0\n",
      "loss: 0.383517 accuracy: 87.0\n",
      "loss: 0.223522 accuracy: 92.0\n",
      "loss: 0.262243 accuracy: 91.0\n",
      "loss: 0.205292 accuracy: 93.0\n",
      "loss: 0.401724 accuracy: 90.0\n",
      "loss: 0.255328 accuracy: 93.0\n",
      "loss: 0.263186 accuracy: 91.0\n",
      "loss: 0.231099 accuracy: 93.0\n",
      "loss: 0.456072 accuracy: 88.0\n",
      "loss: 0.348562 accuracy: 87.0\n",
      "loss: 0.444356 accuracy: 89.0\n",
      "loss: 0.172542 accuracy: 95.0\n",
      "loss: 0.158382 accuracy: 97.0\n",
      "loss: 0.208835 accuracy: 93.0\n",
      "loss: 0.221385 accuracy: 94.0\n",
      "loss: 0.260423 accuracy: 92.0\n",
      "loss: 0.133881 accuracy: 98.0\n",
      "loss: 0.309834 accuracy: 91.0\n",
      "loss: 0.112183 accuracy: 96.0\n",
      "loss: 0.311112 accuracy: 94.0\n",
      "loss: 0.22728 accuracy: 92.0\n",
      "loss: 0.138912 accuracy: 97.0\n",
      "loss: 0.24602 accuracy: 94.0\n",
      "loss: 0.1293 accuracy: 96.0\n",
      "loss: 0.183598 accuracy: 91.0\n",
      "loss: 0.107165 accuracy: 96.0\n",
      "loss: 0.166939 accuracy: 96.0\n",
      "loss: 0.231453 accuracy: 94.0\n",
      "loss: 0.209983 accuracy: 92.0\n",
      "loss: 0.3175 accuracy: 90.0\n",
      "loss: 0.259843 accuracy: 90.0\n",
      "loss: 0.191884 accuracy: 94.0\n",
      "loss: 0.345015 accuracy: 89.0\n",
      "loss: 0.210883 accuracy: 96.0\n",
      "loss: 0.265202 accuracy: 92.0\n",
      "loss: 0.260255 accuracy: 93.0\n",
      "loss: 0.131983 accuracy: 96.0\n",
      "loss: 0.174128 accuracy: 96.0\n",
      "loss: 0.458871 accuracy: 85.0\n",
      "loss: 0.264636 accuracy: 93.0\n",
      "loss: 0.300767 accuracy: 86.0\n",
      "loss: 0.254671 accuracy: 92.0\n",
      "loss: 0.294266 accuracy: 93.0\n",
      "loss: 0.213749 accuracy: 95.0\n",
      "loss: 0.305442 accuracy: 91.0\n",
      "loss: 0.254888 accuracy: 91.0\n",
      "loss: 0.131589 accuracy: 98.0\n",
      "loss: 0.165832 accuracy: 96.0\n",
      "loss: 0.259073 accuracy: 92.0\n",
      "loss: 0.242976 accuracy: 93.0\n",
      "loss: 0.28145 accuracy: 93.0\n",
      "loss: 0.265283 accuracy: 93.0\n",
      "loss: 0.143557 accuracy: 96.0\n",
      "loss: 0.25689 accuracy: 92.0\n",
      "loss: 0.161676 accuracy: 96.0\n",
      "loss: 0.296308 accuracy: 93.0\n",
      "loss: 0.315746 accuracy: 89.0\n",
      "loss: 0.307178 accuracy: 91.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.185203 accuracy: 93.0\n",
      "loss: 0.347196 accuracy: 93.0\n",
      "loss: 0.303016 accuracy: 89.0\n",
      "loss: 0.231958 accuracy: 90.0\n",
      "loss: 0.164293 accuracy: 96.0\n",
      "loss: 0.133068 accuracy: 96.0\n",
      "loss: 0.327676 accuracy: 92.0\n",
      "loss: 0.181713 accuracy: 93.0\n",
      "loss: 0.171973 accuracy: 95.0\n",
      "loss: 0.223511 accuracy: 92.0\n",
      "loss: 0.175575 accuracy: 92.0\n",
      "loss: 0.298933 accuracy: 92.0\n",
      "loss: 0.301141 accuracy: 92.0\n",
      "loss: 0.235369 accuracy: 92.0\n",
      "loss: 0.425707 accuracy: 87.0\n",
      "loss: 0.187754 accuracy: 92.0\n",
      "loss: 0.348821 accuracy: 89.0\n",
      "loss: 0.273327 accuracy: 94.0\n",
      "loss: 0.386757 accuracy: 91.0\n",
      "loss: 0.372553 accuracy: 88.0\n",
      "loss: 0.388882 accuracy: 89.0\n",
      "loss: 0.0887185 accuracy: 97.0\n",
      "loss: 0.277046 accuracy: 89.0\n",
      "loss: 0.285424 accuracy: 95.0\n",
      "loss: 0.328951 accuracy: 87.0\n",
      "loss: 0.223167 accuracy: 94.0\n",
      "loss: 0.253117 accuracy: 93.0\n",
      "loss: 0.503045 accuracy: 86.0\n",
      "loss: 0.229297 accuracy: 93.0\n",
      "loss: 0.275408 accuracy: 92.0\n",
      "loss: 0.282477 accuracy: 94.0\n",
      "loss: 0.308946 accuracy: 93.0\n",
      "loss: 0.228682 accuracy: 95.0\n",
      "loss: 0.173396 accuracy: 95.0\n",
      "loss: 0.307736 accuracy: 93.0\n",
      "loss: 0.27901 accuracy: 91.0\n",
      "loss: 0.220449 accuracy: 94.0\n",
      "loss: 0.271178 accuracy: 92.0\n",
      "loss: 0.223702 accuracy: 92.0\n",
      "loss: 0.228476 accuracy: 93.0\n",
      "loss: 0.169265 accuracy: 95.0\n",
      "loss: 0.156466 accuracy: 96.0\n",
      "loss: 0.148044 accuracy: 98.0\n",
      "loss: 0.217808 accuracy: 92.0\n",
      "loss: 0.359958 accuracy: 91.0\n",
      "loss: 0.175876 accuracy: 92.0\n",
      "loss: 0.224448 accuracy: 94.0\n",
      "loss: 0.273572 accuracy: 90.0\n",
      "loss: 0.276109 accuracy: 94.0\n",
      "loss: 0.256796 accuracy: 91.0\n",
      "loss: 0.157076 accuracy: 96.0\n",
      "loss: 0.255209 accuracy: 92.0\n",
      "loss: 0.258189 accuracy: 92.0\n",
      "loss: 0.175464 accuracy: 92.0\n",
      "loss: 0.302333 accuracy: 93.0\n",
      "loss: 0.203396 accuracy: 94.0\n",
      "loss: 0.366682 accuracy: 90.0\n",
      "loss: 0.412 accuracy: 85.0\n",
      "loss: 0.189045 accuracy: 92.0\n",
      "loss: 0.12362 accuracy: 96.0\n",
      "loss: 0.244284 accuracy: 95.0\n",
      "loss: 0.262273 accuracy: 92.0\n",
      "loss: 0.225207 accuracy: 93.0\n",
      "loss: 0.144489 accuracy: 97.0\n",
      "loss: 0.302083 accuracy: 93.0\n",
      "loss: 0.252429 accuracy: 93.0\n",
      "loss: 0.160052 accuracy: 91.0\n",
      "loss: 0.339598 accuracy: 92.0\n",
      "loss: 0.185438 accuracy: 96.0\n",
      "loss: 0.261572 accuracy: 91.0\n",
      "loss: 0.14207 accuracy: 96.0\n",
      "loss: 0.156897 accuracy: 94.0\n",
      "loss: 0.18475 accuracy: 96.0\n",
      "loss: 0.257918 accuracy: 94.0\n",
      "loss: 0.169849 accuracy: 96.0\n",
      "loss: 0.199551 accuracy: 91.0\n",
      "loss: 0.174641 accuracy: 95.0\n",
      "loss: 0.170088 accuracy: 97.0\n",
      "loss: 0.115587 accuracy: 97.0\n",
      "loss: 0.0801107 accuracy: 99.0\n",
      "loss: 0.29594 accuracy: 90.0\n",
      "loss: 0.145136 accuracy: 96.0\n",
      "loss: 0.276433 accuracy: 93.0\n",
      "loss: 0.233575 accuracy: 94.0\n",
      "loss: 0.582069 accuracy: 85.0\n",
      "loss: 0.338194 accuracy: 91.0\n",
      "loss: 0.141095 accuracy: 96.0\n",
      "loss: 0.145918 accuracy: 94.0\n",
      "loss: 0.283641 accuracy: 94.0\n",
      "loss: 0.29985 accuracy: 92.0\n",
      "loss: 0.289306 accuracy: 92.0\n",
      "loss: 0.310906 accuracy: 93.0\n",
      "loss: 0.156861 accuracy: 95.0\n",
      "loss: 0.32346 accuracy: 91.0\n",
      "loss: 0.299262 accuracy: 92.0\n",
      "loss: 0.304789 accuracy: 91.0\n",
      "loss: 0.215909 accuracy: 91.0\n",
      "loss: 0.382946 accuracy: 88.0\n",
      "loss: 0.216376 accuracy: 93.0\n",
      "loss: 0.186473 accuracy: 93.0\n",
      "loss: 0.121632 accuracy: 97.0\n",
      "loss: 0.359121 accuracy: 88.0\n",
      "loss: 0.244755 accuracy: 95.0\n",
      "loss: 0.149668 accuracy: 97.0\n",
      "loss: 0.304907 accuracy: 92.0\n",
      "loss: 0.277249 accuracy: 90.0\n",
      "loss: 0.308495 accuracy: 93.0\n",
      "loss: 0.226083 accuracy: 95.0\n",
      "loss: 0.223222 accuracy: 90.0\n",
      "loss: 0.247992 accuracy: 93.0\n",
      "loss: 0.14207 accuracy: 95.0\n",
      "loss: 0.348761 accuracy: 88.0\n",
      "loss: 0.406624 accuracy: 90.0\n",
      "loss: 0.273215 accuracy: 94.0\n",
      "loss: 0.24964 accuracy: 95.0\n",
      "loss: 0.299525 accuracy: 92.0\n",
      "loss: 0.111901 accuracy: 97.0\n",
      "loss: 0.324489 accuracy: 90.0\n",
      "loss: 0.162536 accuracy: 94.0\n",
      "loss: 0.28782 accuracy: 92.0\n",
      "loss: 0.238382 accuracy: 92.0\n",
      "loss: 0.284188 accuracy: 94.0\n",
      "loss: 0.171289 accuracy: 93.0\n",
      "loss: 0.224474 accuracy: 93.0\n",
      "loss: 0.136096 accuracy: 96.0\n",
      "loss: 0.317815 accuracy: 91.0\n",
      "loss: 0.223213 accuracy: 92.0\n",
      "loss: 0.134309 accuracy: 94.0\n",
      "loss: 0.371077 accuracy: 89.0\n",
      "loss: 0.270561 accuracy: 93.0\n",
      "loss: 0.256085 accuracy: 91.0\n",
      "loss: 0.201192 accuracy: 93.0\n",
      "loss: 0.181559 accuracy: 95.0\n",
      "loss: 0.238452 accuracy: 92.0\n",
      "loss: 0.191342 accuracy: 94.0\n",
      "loss: 0.234656 accuracy: 93.0\n",
      "loss: 0.148492 accuracy: 97.0\n",
      "loss: 0.158753 accuracy: 95.0\n",
      "loss: 0.18688 accuracy: 93.0\n",
      "loss: 0.170159 accuracy: 94.0\n",
      "loss: 0.152711 accuracy: 96.0\n",
      "loss: 0.308553 accuracy: 93.0\n",
      "loss: 0.330508 accuracy: 91.0\n",
      "loss: 0.0717476 accuracy: 98.0\n",
      "loss: 0.162971 accuracy: 95.0\n",
      "loss: 0.168211 accuracy: 97.0\n",
      "loss: 0.380274 accuracy: 90.0\n",
      "loss: 0.42293 accuracy: 88.0\n",
      "loss: 0.256121 accuracy: 95.0\n",
      "loss: 0.0962204 accuracy: 95.0\n",
      "loss: 0.135353 accuracy: 98.0\n",
      "loss: 0.249883 accuracy: 93.0\n",
      "loss: 0.300733 accuracy: 88.0\n",
      "loss: 0.30081 accuracy: 92.0\n",
      "loss: 0.341772 accuracy: 88.0\n",
      "loss: 0.23893 accuracy: 90.0\n",
      "loss: 0.439092 accuracy: 90.0\n",
      "loss: 0.399272 accuracy: 88.0\n",
      "loss: 0.150565 accuracy: 95.0\n",
      "loss: 0.177509 accuracy: 94.0\n",
      "loss: 0.263951 accuracy: 94.0\n",
      "loss: 0.186757 accuracy: 93.0\n",
      "loss: 0.155409 accuracy: 95.0\n",
      "loss: 0.257746 accuracy: 92.0\n",
      "loss: 0.282189 accuracy: 93.0\n",
      "loss: 0.235526 accuracy: 90.0\n",
      "loss: 0.157141 accuracy: 96.0\n",
      "loss: 0.107538 accuracy: 97.0\n",
      "loss: 0.165778 accuracy: 94.0\n",
      "loss: 0.167711 accuracy: 94.0\n",
      "loss: 0.218113 accuracy: 95.0\n",
      "loss: 0.246682 accuracy: 92.0\n",
      "loss: 0.234225 accuracy: 93.0\n",
      "loss: 0.270214 accuracy: 94.0\n",
      "loss: 0.220342 accuracy: 94.0\n",
      "loss: 0.21228 accuracy: 93.0\n",
      "loss: 0.270182 accuracy: 91.0\n",
      "loss: 0.232271 accuracy: 96.0\n",
      "loss: 0.260272 accuracy: 93.0\n",
      "loss: 0.24973 accuracy: 95.0\n",
      "loss: 0.193614 accuracy: 95.0\n",
      "loss: 0.194209 accuracy: 94.0\n",
      "loss: 0.206182 accuracy: 93.0\n",
      "loss: 0.230379 accuracy: 91.0\n",
      "loss: 0.325308 accuracy: 93.0\n",
      "loss: 0.140347 accuracy: 97.0\n",
      "loss: 0.172139 accuracy: 94.0\n",
      "loss: 0.463209 accuracy: 88.0\n",
      "loss: 0.382619 accuracy: 90.0\n",
      "loss: 0.184814 accuracy: 95.0\n",
      "loss: 0.229707 accuracy: 90.0\n",
      "loss: 0.324055 accuracy: 91.0\n",
      "loss: 0.154434 accuracy: 97.0\n",
      "loss: 0.179255 accuracy: 95.0\n",
      "loss: 0.195369 accuracy: 93.0\n",
      "loss: 0.40145 accuracy: 91.0\n",
      "loss: 0.107541 accuracy: 96.0\n",
      "loss: 0.318045 accuracy: 89.0\n",
      "loss: 0.249429 accuracy: 88.0\n",
      "loss: 0.215526 accuracy: 93.0\n",
      "loss: 0.321667 accuracy: 90.0\n",
      "loss: 0.221888 accuracy: 91.0\n",
      "loss: 0.200429 accuracy: 93.0\n",
      "loss: 0.298152 accuracy: 92.0\n",
      "loss: 0.0749257 accuracy: 99.0\n",
      "loss: 0.141848 accuracy: 96.0\n",
      "loss: 0.302365 accuracy: 92.0\n",
      "loss: 0.350395 accuracy: 89.0\n",
      "loss: 0.154323 accuracy: 95.0\n",
      "loss: 0.246129 accuracy: 94.0\n",
      "loss: 0.215561 accuracy: 92.0\n",
      "loss: 0.334941 accuracy: 89.0\n",
      "loss: 0.374276 accuracy: 90.0\n",
      "loss: 0.210616 accuracy: 95.0\n",
      "loss: 0.183295 accuracy: 94.0\n",
      "loss: 0.155894 accuracy: 94.0\n",
      "loss: 0.205944 accuracy: 96.0\n",
      "loss: 0.113711 accuracy: 96.0\n",
      "loss: 0.209461 accuracy: 93.0\n",
      "loss: 0.229834 accuracy: 93.0\n",
      "loss: 0.118427 accuracy: 96.0\n",
      "loss: 0.204967 accuracy: 94.0\n",
      "loss: 0.232999 accuracy: 90.0\n",
      "loss: 0.316613 accuracy: 90.0\n",
      "loss: 0.136055 accuracy: 95.0\n",
      "loss: 0.378422 accuracy: 94.0\n",
      "loss: 0.159086 accuracy: 97.0\n",
      "loss: 0.239113 accuracy: 92.0\n",
      "loss: 0.153285 accuracy: 94.0\n",
      "loss: 0.140756 accuracy: 94.0\n",
      "loss: 0.242852 accuracy: 90.0\n",
      "epoch 4\n",
      "loss: 0.205103 accuracy: 93.0\n",
      "loss: 0.180583 accuracy: 95.0\n",
      "loss: 0.293439 accuracy: 93.0\n",
      "loss: 0.229019 accuracy: 92.0\n",
      "loss: 0.311035 accuracy: 90.0\n",
      "loss: 0.130022 accuracy: 95.0\n",
      "loss: 0.163127 accuracy: 96.0\n",
      "loss: 0.35726 accuracy: 90.0\n",
      "loss: 0.266467 accuracy: 89.0\n",
      "loss: 0.201619 accuracy: 93.0\n",
      "loss: 0.18478 accuracy: 96.0\n",
      "loss: 0.169255 accuracy: 93.0\n",
      "loss: 0.222506 accuracy: 95.0\n",
      "loss: 0.168483 accuracy: 95.0\n",
      "loss: 0.278947 accuracy: 91.0\n",
      "loss: 0.397261 accuracy: 86.0\n",
      "loss: 0.258941 accuracy: 91.0\n",
      "loss: 0.477856 accuracy: 86.0\n",
      "loss: 0.395357 accuracy: 89.0\n",
      "loss: 0.282974 accuracy: 88.0\n",
      "loss: 0.159573 accuracy: 93.0\n",
      "loss: 0.0501445 accuracy: 99.0\n",
      "loss: 0.11807 accuracy: 96.0\n",
      "loss: 0.205598 accuracy: 93.0\n",
      "loss: 0.27972 accuracy: 94.0\n",
      "loss: 0.216864 accuracy: 93.0\n",
      "loss: 0.321865 accuracy: 93.0\n",
      "loss: 0.199041 accuracy: 92.0\n",
      "loss: 0.207793 accuracy: 92.0\n",
      "loss: 0.158551 accuracy: 95.0\n",
      "loss: 0.113633 accuracy: 96.0\n",
      "loss: 0.175178 accuracy: 96.0\n",
      "loss: 0.328273 accuracy: 93.0\n",
      "loss: 0.20017 accuracy: 93.0\n",
      "loss: 0.328866 accuracy: 90.0\n",
      "loss: 0.191295 accuracy: 92.0\n",
      "loss: 0.32181 accuracy: 91.0\n",
      "loss: 0.222487 accuracy: 91.0\n",
      "loss: 0.259021 accuracy: 93.0\n",
      "loss: 0.171118 accuracy: 94.0\n",
      "loss: 0.338961 accuracy: 91.0\n",
      "loss: 0.301406 accuracy: 88.0\n",
      "loss: 0.247399 accuracy: 92.0\n",
      "loss: 0.237855 accuracy: 93.0\n",
      "loss: 0.176817 accuracy: 94.0\n",
      "loss: 0.273111 accuracy: 90.0\n",
      "loss: 0.333547 accuracy: 88.0\n",
      "loss: 0.205941 accuracy: 93.0\n",
      "loss: 0.233234 accuracy: 92.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.268237 accuracy: 93.0\n",
      "loss: 0.125575 accuracy: 96.0\n",
      "loss: 0.20588 accuracy: 92.0\n",
      "loss: 0.151287 accuracy: 95.0\n",
      "loss: 0.266746 accuracy: 91.0\n",
      "loss: 0.241426 accuracy: 89.0\n",
      "loss: 0.30348 accuracy: 92.0\n",
      "loss: 0.11276 accuracy: 95.0\n",
      "loss: 0.141919 accuracy: 93.0\n",
      "loss: 0.180403 accuracy: 94.0\n",
      "loss: 0.230531 accuracy: 94.0\n",
      "loss: 0.209552 accuracy: 90.0\n",
      "loss: 0.072404 accuracy: 99.0\n",
      "loss: 0.157503 accuracy: 96.0\n",
      "loss: 0.121289 accuracy: 96.0\n",
      "loss: 0.188477 accuracy: 92.0\n",
      "loss: 0.155161 accuracy: 97.0\n",
      "loss: 0.105184 accuracy: 96.0\n",
      "loss: 0.146398 accuracy: 96.0\n",
      "loss: 0.224761 accuracy: 94.0\n",
      "loss: 0.103862 accuracy: 95.0\n",
      "loss: 0.266495 accuracy: 95.0\n",
      "loss: 0.160077 accuracy: 94.0\n",
      "loss: 0.0697373 accuracy: 97.0\n",
      "loss: 0.367384 accuracy: 90.0\n",
      "loss: 0.166495 accuracy: 94.0\n",
      "loss: 0.12427 accuracy: 96.0\n",
      "loss: 0.111302 accuracy: 96.0\n",
      "loss: 0.31066 accuracy: 90.0\n",
      "loss: 0.217159 accuracy: 94.0\n",
      "loss: 0.105715 accuracy: 96.0\n",
      "loss: 0.129815 accuracy: 95.0\n",
      "loss: 0.237879 accuracy: 93.0\n",
      "loss: 0.22215 accuracy: 96.0\n",
      "loss: 0.230235 accuracy: 91.0\n",
      "loss: 0.153614 accuracy: 95.0\n",
      "loss: 0.165999 accuracy: 92.0\n",
      "loss: 0.116661 accuracy: 95.0\n",
      "loss: 0.29408 accuracy: 93.0\n",
      "loss: 0.190784 accuracy: 93.0\n",
      "loss: 0.271356 accuracy: 92.0\n",
      "loss: 0.235277 accuracy: 92.0\n",
      "loss: 0.187216 accuracy: 94.0\n",
      "loss: 0.181943 accuracy: 97.0\n",
      "loss: 0.179843 accuracy: 96.0\n",
      "loss: 0.241051 accuracy: 95.0\n",
      "loss: 0.0755531 accuracy: 98.0\n",
      "loss: 0.27877 accuracy: 93.0\n",
      "loss: 0.213299 accuracy: 94.0\n",
      "loss: 0.175674 accuracy: 94.0\n",
      "loss: 0.169604 accuracy: 94.0\n",
      "loss: 0.211127 accuracy: 91.0\n",
      "loss: 0.236413 accuracy: 92.0\n",
      "loss: 0.152917 accuracy: 95.0\n",
      "loss: 0.219538 accuracy: 93.0\n",
      "loss: 0.203449 accuracy: 94.0\n",
      "loss: 0.185174 accuracy: 94.0\n",
      "loss: 0.338641 accuracy: 89.0\n",
      "loss: 0.309096 accuracy: 90.0\n",
      "loss: 0.165873 accuracy: 91.0\n",
      "loss: 0.261125 accuracy: 92.0\n",
      "loss: 0.243184 accuracy: 93.0\n",
      "loss: 0.281498 accuracy: 93.0\n",
      "loss: 0.280472 accuracy: 92.0\n",
      "loss: 0.132824 accuracy: 95.0\n",
      "loss: 0.212088 accuracy: 93.0\n",
      "loss: 0.157288 accuracy: 96.0\n",
      "loss: 0.190734 accuracy: 96.0\n",
      "loss: 0.277123 accuracy: 91.0\n",
      "loss: 0.114718 accuracy: 96.0\n",
      "loss: 0.174505 accuracy: 95.0\n",
      "loss: 0.115272 accuracy: 97.0\n",
      "loss: 0.176001 accuracy: 94.0\n",
      "loss: 0.198924 accuracy: 94.0\n",
      "loss: 0.180896 accuracy: 92.0\n",
      "loss: 0.210483 accuracy: 94.0\n",
      "loss: 0.206427 accuracy: 91.0\n",
      "loss: 0.200049 accuracy: 96.0\n",
      "loss: 0.0879712 accuracy: 97.0\n",
      "loss: 0.211131 accuracy: 94.0\n",
      "loss: 0.0987776 accuracy: 97.0\n",
      "loss: 0.26865 accuracy: 91.0\n",
      "loss: 0.239653 accuracy: 95.0\n",
      "loss: 0.252004 accuracy: 92.0\n",
      "loss: 0.216835 accuracy: 92.0\n",
      "loss: 0.17656 accuracy: 96.0\n",
      "loss: 0.186682 accuracy: 94.0\n",
      "loss: 0.277648 accuracy: 92.0\n",
      "loss: 0.208722 accuracy: 94.0\n",
      "loss: 0.185845 accuracy: 94.0\n",
      "loss: 0.391325 accuracy: 92.0\n",
      "loss: 0.307124 accuracy: 90.0\n",
      "loss: 0.207443 accuracy: 94.0\n",
      "loss: 0.315713 accuracy: 92.0\n",
      "loss: 0.252038 accuracy: 92.0\n",
      "loss: 0.316499 accuracy: 89.0\n",
      "loss: 0.245555 accuracy: 93.0\n",
      "loss: 0.139048 accuracy: 97.0\n",
      "loss: 0.128964 accuracy: 96.0\n",
      "loss: 0.253347 accuracy: 93.0\n",
      "loss: 0.255679 accuracy: 95.0\n",
      "loss: 0.107995 accuracy: 98.0\n",
      "loss: 0.172643 accuracy: 95.0\n",
      "loss: 0.15673 accuracy: 94.0\n",
      "loss: 0.151104 accuracy: 93.0\n",
      "loss: 0.153283 accuracy: 96.0\n",
      "loss: 0.115959 accuracy: 97.0\n",
      "loss: 0.20757 accuracy: 93.0\n",
      "loss: 0.21477 accuracy: 94.0\n",
      "loss: 0.156793 accuracy: 97.0\n",
      "loss: 0.236557 accuracy: 94.0\n",
      "loss: 0.179659 accuracy: 92.0\n",
      "loss: 0.257505 accuracy: 90.0\n",
      "loss: 0.160131 accuracy: 96.0\n",
      "loss: 0.300278 accuracy: 92.0\n",
      "loss: 0.148152 accuracy: 96.0\n",
      "loss: 0.2106 accuracy: 92.0\n",
      "loss: 0.0836629 accuracy: 99.0\n",
      "loss: 0.0943441 accuracy: 99.0\n",
      "loss: 0.26535 accuracy: 94.0\n",
      "loss: 0.244978 accuracy: 94.0\n",
      "loss: 0.244691 accuracy: 95.0\n",
      "loss: 0.242245 accuracy: 92.0\n",
      "loss: 0.176699 accuracy: 95.0\n",
      "loss: 0.307692 accuracy: 91.0\n",
      "loss: 0.198153 accuracy: 94.0\n",
      "loss: 0.13804 accuracy: 95.0\n",
      "loss: 0.15798 accuracy: 94.0\n",
      "loss: 0.113207 accuracy: 97.0\n",
      "loss: 0.175514 accuracy: 97.0\n",
      "loss: 0.271083 accuracy: 92.0\n",
      "loss: 0.443774 accuracy: 88.0\n",
      "loss: 0.249953 accuracy: 96.0\n",
      "loss: 0.150207 accuracy: 95.0\n",
      "loss: 0.125141 accuracy: 95.0\n",
      "loss: 0.237084 accuracy: 93.0\n",
      "loss: 0.294809 accuracy: 92.0\n",
      "loss: 0.0616781 accuracy: 98.0\n",
      "loss: 0.279544 accuracy: 94.0\n",
      "loss: 0.332659 accuracy: 90.0\n",
      "loss: 0.349122 accuracy: 89.0\n",
      "loss: 0.304871 accuracy: 91.0\n",
      "loss: 0.158136 accuracy: 94.0\n",
      "loss: 0.185867 accuracy: 92.0\n",
      "loss: 0.130442 accuracy: 94.0\n",
      "loss: 0.156662 accuracy: 95.0\n",
      "loss: 0.246996 accuracy: 90.0\n",
      "loss: 0.304072 accuracy: 94.0\n",
      "loss: 0.187809 accuracy: 95.0\n",
      "loss: 0.236894 accuracy: 93.0\n",
      "loss: 0.107808 accuracy: 97.0\n",
      "loss: 0.402101 accuracy: 89.0\n",
      "loss: 0.13789 accuracy: 95.0\n",
      "loss: 0.337343 accuracy: 91.0\n",
      "loss: 0.206611 accuracy: 95.0\n",
      "loss: 0.219984 accuracy: 93.0\n",
      "loss: 0.185342 accuracy: 94.0\n",
      "loss: 0.0632427 accuracy: 98.0\n",
      "loss: 0.412051 accuracy: 93.0\n",
      "loss: 0.16601 accuracy: 95.0\n",
      "loss: 0.119765 accuracy: 96.0\n",
      "loss: 0.193351 accuracy: 93.0\n",
      "loss: 0.22199 accuracy: 92.0\n",
      "loss: 0.218647 accuracy: 92.0\n",
      "loss: 0.17725 accuracy: 97.0\n",
      "loss: 0.123232 accuracy: 96.0\n",
      "loss: 0.270552 accuracy: 95.0\n",
      "loss: 0.281321 accuracy: 92.0\n",
      "loss: 0.241718 accuracy: 94.0\n",
      "loss: 0.145443 accuracy: 97.0\n",
      "loss: 0.120923 accuracy: 96.0\n",
      "loss: 0.193198 accuracy: 94.0\n",
      "loss: 0.264754 accuracy: 92.0\n",
      "loss: 0.291493 accuracy: 93.0\n",
      "loss: 0.20073 accuracy: 94.0\n",
      "loss: 0.0932071 accuracy: 98.0\n",
      "loss: 0.113383 accuracy: 95.0\n",
      "loss: 0.190475 accuracy: 91.0\n",
      "loss: 0.200607 accuracy: 96.0\n",
      "loss: 0.211729 accuracy: 93.0\n",
      "loss: 0.123507 accuracy: 97.0\n",
      "loss: 0.326033 accuracy: 90.0\n",
      "loss: 0.244222 accuracy: 94.0\n",
      "loss: 0.123812 accuracy: 96.0\n",
      "loss: 0.367817 accuracy: 93.0\n",
      "loss: 0.141272 accuracy: 95.0\n",
      "loss: 0.166421 accuracy: 98.0\n",
      "loss: 0.282595 accuracy: 91.0\n",
      "loss: 0.167556 accuracy: 95.0\n",
      "loss: 0.199618 accuracy: 94.0\n",
      "loss: 0.206311 accuracy: 91.0\n",
      "loss: 0.126916 accuracy: 98.0\n",
      "loss: 0.131332 accuracy: 97.0\n",
      "loss: 0.185774 accuracy: 93.0\n",
      "loss: 0.33322 accuracy: 95.0\n",
      "loss: 0.299022 accuracy: 90.0\n",
      "loss: 0.121591 accuracy: 95.0\n",
      "loss: 0.181966 accuracy: 94.0\n",
      "loss: 0.328192 accuracy: 87.0\n",
      "loss: 0.215296 accuracy: 92.0\n",
      "loss: 0.319479 accuracy: 91.0\n",
      "loss: 0.204032 accuracy: 93.0\n",
      "loss: 0.148851 accuracy: 97.0\n",
      "loss: 0.102174 accuracy: 97.0\n",
      "loss: 0.202679 accuracy: 93.0\n",
      "loss: 0.199761 accuracy: 94.0\n",
      "loss: 0.122157 accuracy: 98.0\n",
      "loss: 0.16 accuracy: 96.0\n",
      "loss: 0.167286 accuracy: 93.0\n",
      "loss: 0.163952 accuracy: 93.0\n",
      "loss: 0.159444 accuracy: 97.0\n",
      "loss: 0.0969195 accuracy: 96.0\n",
      "loss: 0.211437 accuracy: 95.0\n",
      "loss: 0.302398 accuracy: 94.0\n",
      "loss: 0.263941 accuracy: 94.0\n",
      "loss: 0.224467 accuracy: 92.0\n",
      "loss: 0.220824 accuracy: 92.0\n",
      "loss: 0.157971 accuracy: 98.0\n",
      "loss: 0.346576 accuracy: 91.0\n",
      "loss: 0.10687 accuracy: 98.0\n",
      "loss: 0.224851 accuracy: 93.0\n",
      "loss: 0.15289 accuracy: 96.0\n",
      "loss: 0.192312 accuracy: 96.0\n",
      "loss: 0.0992157 accuracy: 98.0\n",
      "loss: 0.276407 accuracy: 93.0\n",
      "loss: 0.232245 accuracy: 93.0\n",
      "loss: 0.176698 accuracy: 95.0\n",
      "loss: 0.146163 accuracy: 94.0\n",
      "loss: 0.196628 accuracy: 94.0\n",
      "loss: 0.122733 accuracy: 97.0\n",
      "loss: 0.133933 accuracy: 96.0\n",
      "loss: 0.265588 accuracy: 90.0\n",
      "loss: 0.293738 accuracy: 92.0\n",
      "loss: 0.322003 accuracy: 93.0\n",
      "loss: 0.0988518 accuracy: 97.0\n",
      "loss: 0.144263 accuracy: 96.0\n",
      "loss: 0.249194 accuracy: 94.0\n",
      "loss: 0.0878739 accuracy: 98.0\n",
      "loss: 0.180227 accuracy: 96.0\n",
      "loss: 0.208506 accuracy: 93.0\n",
      "loss: 0.243158 accuracy: 93.0\n",
      "loss: 0.302964 accuracy: 93.0\n",
      "loss: 0.112308 accuracy: 97.0\n",
      "loss: 0.210655 accuracy: 93.0\n",
      "loss: 0.197565 accuracy: 93.0\n",
      "loss: 0.112862 accuracy: 95.0\n",
      "loss: 0.202176 accuracy: 96.0\n",
      "loss: 0.151608 accuracy: 98.0\n",
      "loss: 0.189767 accuracy: 94.0\n",
      "loss: 0.18407 accuracy: 95.0\n",
      "loss: 0.183802 accuracy: 94.0\n",
      "loss: 0.244167 accuracy: 94.0\n",
      "loss: 0.185957 accuracy: 93.0\n",
      "loss: 0.105459 accuracy: 97.0\n",
      "loss: 0.306876 accuracy: 91.0\n",
      "loss: 0.235507 accuracy: 94.0\n",
      "loss: 0.109759 accuracy: 99.0\n",
      "loss: 0.198075 accuracy: 94.0\n",
      "loss: 0.0978142 accuracy: 99.0\n",
      "loss: 0.148721 accuracy: 97.0\n",
      "loss: 0.260799 accuracy: 91.0\n",
      "loss: 0.203171 accuracy: 96.0\n",
      "loss: 0.291123 accuracy: 92.0\n",
      "loss: 0.24569 accuracy: 91.0\n",
      "loss: 0.236693 accuracy: 92.0\n",
      "loss: 0.137316 accuracy: 95.0\n",
      "loss: 0.17125 accuracy: 95.0\n",
      "loss: 0.150905 accuracy: 95.0\n",
      "loss: 0.0722768 accuracy: 98.0\n",
      "loss: 0.106444 accuracy: 95.0\n",
      "loss: 0.211168 accuracy: 92.0\n",
      "loss: 0.145614 accuracy: 93.0\n",
      "loss: 0.457514 accuracy: 89.0\n",
      "loss: 0.402033 accuracy: 92.0\n",
      "loss: 0.253555 accuracy: 89.0\n",
      "loss: 0.262397 accuracy: 90.0\n",
      "loss: 0.230715 accuracy: 94.0\n",
      "loss: 0.139991 accuracy: 95.0\n",
      "loss: 0.202551 accuracy: 94.0\n",
      "loss: 0.241887 accuracy: 94.0\n",
      "loss: 0.233513 accuracy: 91.0\n",
      "loss: 0.186794 accuracy: 94.0\n",
      "loss: 0.237788 accuracy: 92.0\n",
      "loss: 0.182924 accuracy: 92.0\n",
      "loss: 0.180373 accuracy: 94.0\n",
      "loss: 0.265459 accuracy: 94.0\n",
      "loss: 0.153931 accuracy: 94.0\n",
      "loss: 0.289943 accuracy: 93.0\n",
      "loss: 0.0967493 accuracy: 96.0\n",
      "loss: 0.140683 accuracy: 93.0\n",
      "loss: 0.233645 accuracy: 90.0\n",
      "loss: 0.17135 accuracy: 93.0\n",
      "loss: 0.182274 accuracy: 98.0\n",
      "loss: 0.196397 accuracy: 96.0\n",
      "loss: 0.221426 accuracy: 95.0\n",
      "loss: 0.22363 accuracy: 95.0\n",
      "loss: 0.180276 accuracy: 94.0\n",
      "loss: 0.0911469 accuracy: 97.0\n",
      "loss: 0.0615673 accuracy: 98.0\n",
      "loss: 0.238336 accuracy: 94.0\n",
      "loss: 0.245764 accuracy: 93.0\n",
      "loss: 0.375013 accuracy: 89.0\n",
      "loss: 0.380992 accuracy: 89.0\n",
      "loss: 0.372725 accuracy: 91.0\n",
      "loss: 0.13462 accuracy: 97.0\n",
      "loss: 0.302467 accuracy: 92.0\n",
      "loss: 0.167128 accuracy: 95.0\n",
      "loss: 0.29742 accuracy: 90.0\n",
      "loss: 0.175551 accuracy: 93.0\n",
      "loss: 0.0807046 accuracy: 98.0\n",
      "loss: 0.16864 accuracy: 93.0\n",
      "loss: 0.249151 accuracy: 92.0\n",
      "loss: 0.144952 accuracy: 94.0\n",
      "loss: 0.107528 accuracy: 98.0\n",
      "loss: 0.138965 accuracy: 95.0\n",
      "loss: 0.138163 accuracy: 96.0\n",
      "loss: 0.108351 accuracy: 97.0\n",
      "loss: 0.105755 accuracy: 97.0\n",
      "loss: 0.152178 accuracy: 95.0\n",
      "loss: 0.36544 accuracy: 91.0\n",
      "loss: 0.125233 accuracy: 95.0\n",
      "loss: 0.168581 accuracy: 94.0\n",
      "loss: 0.353535 accuracy: 92.0\n",
      "loss: 0.197032 accuracy: 90.0\n",
      "loss: 0.170259 accuracy: 95.0\n",
      "loss: 0.173153 accuracy: 96.0\n",
      "loss: 0.0954122 accuracy: 97.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.227071 accuracy: 93.0\n",
      "loss: 0.193894 accuracy: 93.0\n",
      "loss: 0.230257 accuracy: 94.0\n",
      "loss: 0.181865 accuracy: 93.0\n",
      "loss: 0.208908 accuracy: 96.0\n",
      "loss: 0.222406 accuracy: 96.0\n",
      "loss: 0.123653 accuracy: 96.0\n",
      "loss: 0.29226 accuracy: 91.0\n",
      "loss: 0.19157 accuracy: 95.0\n",
      "loss: 0.155042 accuracy: 94.0\n",
      "loss: 0.121431 accuracy: 96.0\n",
      "loss: 0.212196 accuracy: 92.0\n",
      "loss: 0.0977907 accuracy: 96.0\n",
      "loss: 0.14259 accuracy: 96.0\n",
      "loss: 0.14007 accuracy: 96.0\n",
      "loss: 0.0909549 accuracy: 97.0\n",
      "loss: 0.220627 accuracy: 91.0\n",
      "loss: 0.234313 accuracy: 93.0\n",
      "loss: 0.280373 accuracy: 93.0\n",
      "loss: 0.0680204 accuracy: 97.0\n",
      "loss: 0.0950293 accuracy: 97.0\n",
      "loss: 0.0842573 accuracy: 99.0\n",
      "loss: 0.3423 accuracy: 91.0\n",
      "loss: 0.120491 accuracy: 96.0\n",
      "loss: 0.154549 accuracy: 96.0\n",
      "loss: 0.0644235 accuracy: 98.0\n",
      "loss: 0.184977 accuracy: 94.0\n",
      "loss: 0.0855772 accuracy: 98.0\n",
      "loss: 0.122057 accuracy: 97.0\n",
      "loss: 0.194397 accuracy: 93.0\n",
      "loss: 0.136343 accuracy: 94.0\n",
      "loss: 0.0760156 accuracy: 97.0\n",
      "loss: 0.244678 accuracy: 94.0\n",
      "loss: 0.252271 accuracy: 90.0\n",
      "loss: 0.163526 accuracy: 95.0\n",
      "loss: 0.204146 accuracy: 92.0\n",
      "loss: 0.142828 accuracy: 96.0\n",
      "loss: 0.194827 accuracy: 92.0\n",
      "loss: 0.170903 accuracy: 94.0\n",
      "loss: 0.178348 accuracy: 95.0\n",
      "loss: 0.227322 accuracy: 96.0\n",
      "loss: 0.376487 accuracy: 90.0\n",
      "loss: 0.313123 accuracy: 95.0\n",
      "loss: 0.136588 accuracy: 96.0\n",
      "loss: 0.0922211 accuracy: 98.0\n",
      "loss: 0.285882 accuracy: 93.0\n",
      "loss: 0.296075 accuracy: 93.0\n",
      "loss: 0.100556 accuracy: 98.0\n",
      "loss: 0.0700937 accuracy: 98.0\n",
      "loss: 0.0697684 accuracy: 98.0\n",
      "loss: 0.132338 accuracy: 96.0\n",
      "loss: 0.121395 accuracy: 97.0\n",
      "loss: 0.121704 accuracy: 96.0\n",
      "loss: 0.217132 accuracy: 95.0\n",
      "loss: 0.208898 accuracy: 94.0\n",
      "loss: 0.172959 accuracy: 94.0\n",
      "loss: 0.109868 accuracy: 98.0\n",
      "loss: 0.248881 accuracy: 93.0\n",
      "loss: 0.359788 accuracy: 91.0\n",
      "loss: 0.118536 accuracy: 96.0\n",
      "loss: 0.264194 accuracy: 95.0\n",
      "loss: 0.136392 accuracy: 95.0\n",
      "loss: 0.233413 accuracy: 94.0\n",
      "loss: 0.266277 accuracy: 92.0\n",
      "loss: 0.299125 accuracy: 91.0\n",
      "loss: 0.175119 accuracy: 93.0\n",
      "loss: 0.091199 accuracy: 98.0\n",
      "loss: 0.196312 accuracy: 94.0\n",
      "loss: 0.0827175 accuracy: 96.0\n",
      "loss: 0.080849 accuracy: 98.0\n",
      "loss: 0.206128 accuracy: 92.0\n",
      "loss: 0.186254 accuracy: 95.0\n",
      "loss: 0.16154 accuracy: 94.0\n",
      "loss: 0.0884799 accuracy: 97.0\n",
      "loss: 0.160114 accuracy: 97.0\n",
      "loss: 0.0604213 accuracy: 99.0\n",
      "loss: 0.150056 accuracy: 97.0\n",
      "loss: 0.0931699 accuracy: 96.0\n",
      "loss: 0.233474 accuracy: 94.0\n",
      "loss: 0.135789 accuracy: 95.0\n",
      "loss: 0.174846 accuracy: 95.0\n",
      "loss: 0.264174 accuracy: 92.0\n",
      "loss: 0.285873 accuracy: 93.0\n",
      "loss: 0.21719 accuracy: 93.0\n",
      "loss: 0.170156 accuracy: 94.0\n",
      "loss: 0.103558 accuracy: 96.0\n",
      "loss: 0.129225 accuracy: 94.0\n",
      "loss: 0.132725 accuracy: 93.0\n",
      "loss: 0.199897 accuracy: 93.0\n",
      "loss: 0.194438 accuracy: 96.0\n",
      "loss: 0.272577 accuracy: 94.0\n",
      "loss: 0.1621 accuracy: 97.0\n",
      "loss: 0.17376 accuracy: 95.0\n",
      "loss: 0.211296 accuracy: 93.0\n",
      "loss: 0.141096 accuracy: 95.0\n",
      "loss: 0.248597 accuracy: 93.0\n",
      "loss: 0.0863673 accuracy: 97.0\n",
      "loss: 0.143761 accuracy: 97.0\n",
      "loss: 0.148996 accuracy: 94.0\n",
      "loss: 0.115505 accuracy: 95.0\n",
      "loss: 0.116692 accuracy: 96.0\n",
      "loss: 0.271883 accuracy: 94.0\n",
      "loss: 0.127225 accuracy: 96.0\n",
      "loss: 0.118155 accuracy: 97.0\n",
      "loss: 0.132303 accuracy: 95.0\n",
      "loss: 0.105067 accuracy: 98.0\n",
      "loss: 0.166367 accuracy: 94.0\n",
      "loss: 0.11628 accuracy: 97.0\n",
      "loss: 0.122576 accuracy: 95.0\n",
      "loss: 0.247568 accuracy: 94.0\n",
      "loss: 0.146355 accuracy: 97.0\n",
      "loss: 0.211051 accuracy: 95.0\n",
      "loss: 0.306363 accuracy: 94.0\n",
      "loss: 0.15182 accuracy: 95.0\n",
      "loss: 0.273032 accuracy: 90.0\n",
      "loss: 0.280288 accuracy: 92.0\n",
      "loss: 0.222845 accuracy: 93.0\n",
      "loss: 0.18054 accuracy: 94.0\n",
      "loss: 0.180307 accuracy: 92.0\n",
      "loss: 0.210417 accuracy: 93.0\n",
      "loss: 0.219716 accuracy: 91.0\n",
      "loss: 0.366686 accuracy: 92.0\n",
      "loss: 0.268617 accuracy: 92.0\n",
      "loss: 0.19743 accuracy: 93.0\n",
      "loss: 0.286155 accuracy: 91.0\n",
      "loss: 0.0852482 accuracy: 95.0\n",
      "loss: 0.186965 accuracy: 93.0\n",
      "loss: 0.123195 accuracy: 95.0\n",
      "loss: 0.149131 accuracy: 97.0\n",
      "loss: 0.172648 accuracy: 94.0\n",
      "loss: 0.0532585 accuracy: 99.0\n",
      "loss: 0.233696 accuracy: 95.0\n",
      "loss: 0.111325 accuracy: 97.0\n",
      "loss: 0.262133 accuracy: 92.0\n",
      "loss: 0.111336 accuracy: 95.0\n",
      "loss: 0.113115 accuracy: 98.0\n",
      "loss: 0.0927724 accuracy: 95.0\n",
      "loss: 0.333426 accuracy: 91.0\n",
      "loss: 0.21532 accuracy: 94.0\n",
      "loss: 0.120204 accuracy: 96.0\n",
      "loss: 0.109576 accuracy: 96.0\n",
      "loss: 0.190147 accuracy: 95.0\n",
      "loss: 0.206711 accuracy: 94.0\n",
      "loss: 0.372609 accuracy: 92.0\n",
      "loss: 0.138944 accuracy: 95.0\n",
      "loss: 0.376472 accuracy: 93.0\n",
      "loss: 0.235111 accuracy: 94.0\n",
      "loss: 0.231773 accuracy: 91.0\n",
      "loss: 0.205806 accuracy: 93.0\n",
      "loss: 0.20439 accuracy: 92.0\n",
      "loss: 0.218836 accuracy: 93.0\n",
      "loss: 0.197475 accuracy: 95.0\n",
      "loss: 0.165096 accuracy: 92.0\n",
      "loss: 0.179293 accuracy: 96.0\n",
      "loss: 0.336289 accuracy: 92.0\n",
      "loss: 0.166063 accuracy: 95.0\n",
      "loss: 0.257939 accuracy: 92.0\n",
      "loss: 0.136992 accuracy: 96.0\n",
      "loss: 0.143024 accuracy: 95.0\n",
      "loss: 0.234139 accuracy: 92.0\n",
      "loss: 0.218137 accuracy: 94.0\n",
      "loss: 0.122299 accuracy: 96.0\n",
      "loss: 0.0472237 accuracy: 99.0\n",
      "loss: 0.0456147 accuracy: 99.0\n",
      "loss: 0.209657 accuracy: 95.0\n",
      "loss: 0.125048 accuracy: 95.0\n",
      "loss: 0.103778 accuracy: 96.0\n",
      "loss: 0.262712 accuracy: 91.0\n",
      "loss: 0.233129 accuracy: 92.0\n",
      "loss: 0.309666 accuracy: 92.0\n",
      "loss: 0.105255 accuracy: 98.0\n",
      "loss: 0.306326 accuracy: 92.0\n",
      "loss: 0.206363 accuracy: 94.0\n",
      "epoch 5\n",
      "loss: 0.0838371 accuracy: 97.0\n",
      "loss: 0.293005 accuracy: 95.0\n",
      "loss: 0.120657 accuracy: 98.0\n",
      "loss: 0.158925 accuracy: 96.0\n",
      "loss: 0.0558978 accuracy: 99.0\n",
      "loss: 0.0699117 accuracy: 97.0\n",
      "loss: 0.179115 accuracy: 95.0\n",
      "loss: 0.298676 accuracy: 91.0\n",
      "loss: 0.111101 accuracy: 97.0\n",
      "loss: 0.284281 accuracy: 91.0\n",
      "loss: 0.127521 accuracy: 96.0\n",
      "loss: 0.102938 accuracy: 97.0\n",
      "loss: 0.147124 accuracy: 95.0\n",
      "loss: 0.192628 accuracy: 93.0\n",
      "loss: 0.210573 accuracy: 93.0\n",
      "loss: 0.106426 accuracy: 96.0\n",
      "loss: 0.35185 accuracy: 91.0\n",
      "loss: 0.197219 accuracy: 93.0\n",
      "loss: 0.158721 accuracy: 93.0\n",
      "loss: 0.159621 accuracy: 95.0\n",
      "loss: 0.148067 accuracy: 97.0\n",
      "loss: 0.211087 accuracy: 94.0\n",
      "loss: 0.110127 accuracy: 97.0\n",
      "loss: 0.231587 accuracy: 94.0\n",
      "loss: 0.168776 accuracy: 94.0\n",
      "loss: 0.192579 accuracy: 94.0\n",
      "loss: 0.111845 accuracy: 96.0\n",
      "loss: 0.125527 accuracy: 96.0\n",
      "loss: 0.158657 accuracy: 94.0\n",
      "loss: 0.122704 accuracy: 97.0\n",
      "loss: 0.148091 accuracy: 97.0\n",
      "loss: 0.274947 accuracy: 94.0\n",
      "loss: 0.117089 accuracy: 96.0\n",
      "loss: 0.191776 accuracy: 94.0\n",
      "loss: 0.186302 accuracy: 94.0\n",
      "loss: 0.0726275 accuracy: 99.0\n",
      "loss: 0.0718576 accuracy: 98.0\n",
      "loss: 0.153481 accuracy: 96.0\n",
      "loss: 0.182514 accuracy: 93.0\n",
      "loss: 0.0997953 accuracy: 97.0\n",
      "loss: 0.219789 accuracy: 91.0\n",
      "loss: 0.0640283 accuracy: 98.0\n",
      "loss: 0.165397 accuracy: 93.0\n",
      "loss: 0.293231 accuracy: 92.0\n",
      "loss: 0.0975134 accuracy: 97.0\n",
      "loss: 0.261626 accuracy: 96.0\n",
      "loss: 0.0949191 accuracy: 97.0\n",
      "loss: 0.102866 accuracy: 94.0\n",
      "loss: 0.191081 accuracy: 95.0\n",
      "loss: 0.172807 accuracy: 95.0\n",
      "loss: 0.112237 accuracy: 97.0\n",
      "loss: 0.215367 accuracy: 92.0\n",
      "loss: 0.105733 accuracy: 96.0\n",
      "loss: 0.100064 accuracy: 98.0\n",
      "loss: 0.065302 accuracy: 99.0\n",
      "loss: 0.116718 accuracy: 95.0\n",
      "loss: 0.251131 accuracy: 89.0\n",
      "loss: 0.431699 accuracy: 90.0\n",
      "loss: 0.179266 accuracy: 94.0\n",
      "loss: 0.236839 accuracy: 93.0\n",
      "loss: 0.205257 accuracy: 96.0\n",
      "loss: 0.17511 accuracy: 95.0\n",
      "loss: 0.182563 accuracy: 94.0\n",
      "loss: 0.253759 accuracy: 91.0\n",
      "loss: 0.138286 accuracy: 95.0\n",
      "loss: 0.158342 accuracy: 97.0\n",
      "loss: 0.109942 accuracy: 97.0\n",
      "loss: 0.0833363 accuracy: 98.0\n",
      "loss: 0.138322 accuracy: 96.0\n",
      "loss: 0.225374 accuracy: 94.0\n",
      "loss: 0.113384 accuracy: 97.0\n",
      "loss: 0.164418 accuracy: 95.0\n",
      "loss: 0.100004 accuracy: 97.0\n",
      "loss: 0.157976 accuracy: 95.0\n",
      "loss: 0.0709154 accuracy: 99.0\n",
      "loss: 0.185315 accuracy: 95.0\n",
      "loss: 0.235905 accuracy: 94.0\n",
      "loss: 0.129104 accuracy: 97.0\n",
      "loss: 0.225193 accuracy: 93.0\n",
      "loss: 0.0765032 accuracy: 97.0\n",
      "loss: 0.103074 accuracy: 96.0\n",
      "loss: 0.137587 accuracy: 96.0\n",
      "loss: 0.166428 accuracy: 97.0\n",
      "loss: 0.120153 accuracy: 96.0\n",
      "loss: 0.190716 accuracy: 92.0\n",
      "loss: 0.140321 accuracy: 95.0\n",
      "loss: 0.187014 accuracy: 93.0\n",
      "loss: 0.147396 accuracy: 94.0\n",
      "loss: 0.268085 accuracy: 90.0\n",
      "loss: 0.145121 accuracy: 93.0\n",
      "loss: 0.294194 accuracy: 91.0\n",
      "loss: 0.131132 accuracy: 97.0\n",
      "loss: 0.105317 accuracy: 98.0\n",
      "loss: 0.0465903 accuracy: 98.0\n",
      "loss: 0.159659 accuracy: 95.0\n",
      "loss: 0.206243 accuracy: 94.0\n",
      "loss: 0.14535 accuracy: 96.0\n",
      "loss: 0.278275 accuracy: 92.0\n",
      "loss: 0.174554 accuracy: 94.0\n",
      "loss: 0.189761 accuracy: 94.0\n",
      "loss: 0.150924 accuracy: 96.0\n",
      "loss: 0.0951046 accuracy: 98.0\n",
      "loss: 0.0843453 accuracy: 96.0\n",
      "loss: 0.157011 accuracy: 96.0\n",
      "loss: 0.1369 accuracy: 96.0\n",
      "loss: 0.0722917 accuracy: 98.0\n",
      "loss: 0.116765 accuracy: 97.0\n",
      "loss: 0.19883 accuracy: 94.0\n",
      "loss: 0.301958 accuracy: 90.0\n",
      "loss: 0.129927 accuracy: 97.0\n",
      "loss: 0.280419 accuracy: 93.0\n",
      "loss: 0.157772 accuracy: 95.0\n",
      "loss: 0.144187 accuracy: 96.0\n",
      "loss: 0.115105 accuracy: 97.0\n",
      "loss: 0.0991813 accuracy: 97.0\n",
      "loss: 0.126913 accuracy: 95.0\n",
      "loss: 0.291668 accuracy: 91.0\n",
      "loss: 0.0564562 accuracy: 98.0\n",
      "loss: 0.144608 accuracy: 96.0\n",
      "loss: 0.182505 accuracy: 94.0\n",
      "loss: 0.0679613 accuracy: 99.0\n",
      "loss: 0.107191 accuracy: 95.0\n",
      "loss: 0.166469 accuracy: 96.0\n",
      "loss: 0.107983 accuracy: 95.0\n",
      "loss: 0.12484 accuracy: 96.0\n",
      "loss: 0.101388 accuracy: 96.0\n",
      "loss: 0.216499 accuracy: 95.0\n",
      "loss: 0.0983308 accuracy: 96.0\n",
      "loss: 0.0928723 accuracy: 98.0\n",
      "loss: 0.123232 accuracy: 95.0\n",
      "loss: 0.157919 accuracy: 94.0\n",
      "loss: 0.13149 accuracy: 95.0\n",
      "loss: 0.191876 accuracy: 95.0\n",
      "loss: 0.232641 accuracy: 93.0\n",
      "loss: 0.0817619 accuracy: 98.0\n",
      "loss: 0.128546 accuracy: 97.0\n",
      "loss: 0.301827 accuracy: 94.0\n",
      "loss: 0.231769 accuracy: 93.0\n",
      "loss: 0.244632 accuracy: 94.0\n",
      "loss: 0.135898 accuracy: 96.0\n",
      "loss: 0.207968 accuracy: 95.0\n",
      "loss: 0.209049 accuracy: 93.0\n",
      "loss: 0.27759 accuracy: 92.0\n",
      "loss: 0.276001 accuracy: 91.0\n",
      "loss: 0.528916 accuracy: 85.0\n",
      "loss: 0.234268 accuracy: 93.0\n",
      "loss: 0.178613 accuracy: 95.0\n",
      "loss: 0.179293 accuracy: 93.0\n",
      "loss: 0.139398 accuracy: 97.0\n",
      "loss: 0.115281 accuracy: 98.0\n",
      "loss: 0.123234 accuracy: 98.0\n",
      "loss: 0.200959 accuracy: 94.0\n",
      "loss: 0.096587 accuracy: 95.0\n",
      "loss: 0.116644 accuracy: 98.0\n",
      "loss: 0.130209 accuracy: 96.0\n",
      "loss: 0.0977802 accuracy: 96.0\n",
      "loss: 0.196236 accuracy: 94.0\n",
      "loss: 0.328283 accuracy: 91.0\n",
      "loss: 0.171439 accuracy: 97.0\n",
      "loss: 0.153504 accuracy: 96.0\n",
      "loss: 0.243077 accuracy: 91.0\n",
      "loss: 0.221409 accuracy: 94.0\n",
      "loss: 0.192479 accuracy: 94.0\n",
      "loss: 0.120507 accuracy: 98.0\n",
      "loss: 0.152911 accuracy: 94.0\n",
      "loss: 0.0859424 accuracy: 98.0\n",
      "loss: 0.199837 accuracy: 94.0\n",
      "loss: 0.112214 accuracy: 97.0\n",
      "loss: 0.122177 accuracy: 96.0\n",
      "loss: 0.240299 accuracy: 95.0\n",
      "loss: 0.0935398 accuracy: 96.0\n",
      "loss: 0.0722901 accuracy: 98.0\n",
      "loss: 0.19427 accuracy: 95.0\n",
      "loss: 0.131373 accuracy: 95.0\n",
      "loss: 0.0631697 accuracy: 99.0\n",
      "loss: 0.146101 accuracy: 93.0\n",
      "loss: 0.122593 accuracy: 95.0\n",
      "loss: 0.234732 accuracy: 95.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(mnist.train.num_examples // batch_size))\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    sess.run(init)\n",
    "    #saver.restore(sess, interim_checkpoint_path)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"epoch\", epoch)\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = summary_op.eval(feed_dict={x: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            t, l, a = sess.run([training_op, loss, accuracy], feed_dict={x: X_batch, y: y_batch})\n",
    "            \n",
    "            if batch_index % 10000: print(\"loss:\", l, \"accuracy:\", a)\n",
    "    save_path = saver.save(sess, interim_checkpoint_path)\n",
    "    test_acc = accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "    print(\">>>>>>>>>> test dataset accuracy:\", test_acc)\n",
    "\n",
    "    save_path = saver.save(sess, \"./checkpoints/mnist_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
