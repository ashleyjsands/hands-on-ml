{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "#  Create a test graph\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_inputs = 28 * 28\n",
    "n_hidden1 = 1000\n",
    "n_hidden2 = 500\n",
    "n_hidden3 = 100\n",
    "n_hidden4 = 50\n",
    "n_output = 10\n",
    "\n",
    "def neuron_layer(X, n_neurons, name):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        # truncated normal distributions limit the size of the weights, speeding up the training time.\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"weights\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"biases\")\n",
    "        z = tf.matmul(X, W) + b\n",
    "        return tf.nn.relu(z)\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    x = tf.placeholder(tf.float32, shape=(None, number_of_inputs), name=\"input\")\n",
    "    y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "    with tf.name_scope(\"dnn\"):\n",
    "        hidden1_output = neuron_layer(x, n_hidden1, \"hidden1\")\n",
    "        hidden2_output = neuron_layer(hidden1_output, n_hidden2, \"hidden2\")\n",
    "        hidden3_output = neuron_layer(hidden2_output, n_hidden3, \"hidden3\")\n",
    "        hidden4_output = neuron_layer(hidden3_output, n_hidden4, \"hidden4\")\n",
    "        logits = neuron_layer(hidden4_output, n_output, \"output\")\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "        loss = tf.reduce_mean(cross_entropy, name=\"loss\")\n",
    "\n",
    "    with tf.name_scope(\"training\"):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    k = 1\n",
    "    correctness = tf.nn.in_top_k(logits, y, k)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correctness, tf.float32)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "interim_checkpoint_path = \"./checkpoints/mnist_model.ckpt\"\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "log_dir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "summary_op = tf.summary.merge([loss_summary, accuracy_summary])\n",
    "file_writer = tf.summary.FileWriter(log_dir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.36651 accuracy: 15.0\n",
      "loss: 2.29901 accuracy: 16.0\n",
      "loss: 2.15483 accuracy: 25.0\n",
      "loss: 2.11218 accuracy: 31.0\n",
      "loss: 1.99116 accuracy: 34.0\n",
      "loss: 2.00267 accuracy: 35.0\n",
      "loss: 1.94445 accuracy: 39.0\n",
      "loss: 1.87665 accuracy: 39.0\n",
      "loss: 2.05443 accuracy: 28.0\n",
      "loss: 1.81381 accuracy: 41.0\n",
      "loss: 2.19886 accuracy: 33.0\n",
      "loss: 2.63245 accuracy: 24.0\n",
      "loss: 3.2966 accuracy: 11.0\n",
      "loss: 2.10924 accuracy: 21.0\n",
      "loss: 2.10728 accuracy: 34.0\n",
      "loss: 2.16004 accuracy: 17.0\n",
      "loss: 1.89746 accuracy: 42.0\n",
      "loss: 1.50495 accuracy: 59.0\n",
      "loss: 1.53296 accuracy: 57.0\n",
      "loss: 1.53048 accuracy: 56.0\n",
      "loss: 1.33637 accuracy: 63.0\n",
      "loss: 1.11283 accuracy: 66.0\n",
      "loss: 1.39557 accuracy: 54.0\n",
      "loss: 1.41595 accuracy: 55.0\n",
      "loss: 1.07627 accuracy: 66.0\n",
      "loss: 1.0198 accuracy: 69.0\n",
      "loss: 0.994305 accuracy: 72.0\n",
      "loss: 1.03293 accuracy: 68.0\n",
      "loss: 0.962346 accuracy: 70.0\n",
      "loss: 0.676946 accuracy: 83.0\n",
      "loss: 0.957636 accuracy: 75.0\n",
      "loss: 0.676229 accuracy: 80.0\n",
      "loss: 0.866485 accuracy: 75.0\n",
      "loss: 1.01577 accuracy: 67.0\n",
      "loss: 1.16414 accuracy: 58.0\n",
      "loss: 1.42815 accuracy: 55.0\n",
      "loss: 1.67688 accuracy: 48.0\n",
      "loss: 1.03186 accuracy: 64.0\n",
      "loss: 0.677439 accuracy: 83.0\n",
      "loss: 0.821805 accuracy: 74.0\n",
      "loss: 0.821718 accuracy: 77.0\n",
      "loss: 0.74502 accuracy: 79.0\n",
      "loss: 0.544136 accuracy: 87.0\n",
      "loss: 0.56447 accuracy: 82.0\n",
      "loss: 0.614644 accuracy: 83.0\n",
      "loss: 0.44496 accuracy: 86.0\n",
      "loss: 0.409829 accuracy: 90.0\n",
      "loss: 0.422829 accuracy: 89.0\n",
      "loss: 0.291737 accuracy: 91.0\n",
      "loss: 0.402697 accuracy: 87.0\n",
      "loss: 0.452328 accuracy: 89.0\n",
      "loss: 0.553352 accuracy: 83.0\n",
      "loss: 0.525326 accuracy: 83.0\n",
      "loss: 0.397712 accuracy: 88.0\n",
      "loss: 0.42695 accuracy: 89.0\n",
      "loss: 0.780588 accuracy: 78.0\n",
      "loss: 0.346118 accuracy: 88.0\n",
      "loss: 0.486548 accuracy: 84.0\n",
      "loss: 0.663504 accuracy: 83.0\n",
      "loss: 0.414032 accuracy: 88.0\n",
      "loss: 0.56583 accuracy: 81.0\n",
      "loss: 0.443378 accuracy: 83.0\n",
      "loss: 0.5405 accuracy: 82.0\n",
      "loss: 0.764012 accuracy: 75.0\n",
      "loss: 0.624347 accuracy: 73.0\n",
      "loss: 0.475756 accuracy: 86.0\n",
      "loss: 0.366034 accuracy: 89.0\n",
      "loss: 0.336428 accuracy: 91.0\n",
      "loss: 0.550779 accuracy: 84.0\n",
      "loss: 0.330362 accuracy: 89.0\n",
      "loss: 0.366205 accuracy: 90.0\n",
      "loss: 0.440323 accuracy: 88.0\n",
      "loss: 0.371044 accuracy: 92.0\n",
      "loss: 0.492003 accuracy: 85.0\n",
      "loss: 0.603135 accuracy: 86.0\n",
      "loss: 0.350016 accuracy: 91.0\n",
      "loss: 0.463377 accuracy: 90.0\n",
      "loss: 0.499077 accuracy: 84.0\n",
      "loss: 0.525795 accuracy: 88.0\n",
      "loss: 0.290447 accuracy: 94.0\n",
      "loss: 0.449013 accuracy: 87.0\n",
      "loss: 0.195448 accuracy: 96.0\n",
      "loss: 0.461883 accuracy: 85.0\n",
      "loss: 0.376556 accuracy: 88.0\n",
      "loss: 0.500962 accuracy: 83.0\n",
      "loss: 0.426131 accuracy: 86.0\n",
      "loss: 0.281395 accuracy: 92.0\n",
      "loss: 0.149402 accuracy: 95.0\n",
      "loss: 0.276266 accuracy: 95.0\n",
      "loss: 0.355618 accuracy: 87.0\n",
      "loss: 0.264415 accuracy: 93.0\n",
      "loss: 0.414982 accuracy: 88.0\n",
      "loss: 0.553587 accuracy: 84.0\n",
      "loss: 0.390304 accuracy: 89.0\n",
      "loss: 0.314364 accuracy: 91.0\n",
      "loss: 0.312664 accuracy: 93.0\n",
      "loss: 0.378357 accuracy: 90.0\n",
      "loss: 0.294069 accuracy: 93.0\n",
      "loss: 0.253503 accuracy: 93.0\n",
      "loss: 0.39979 accuracy: 86.0\n",
      "loss: 0.440342 accuracy: 83.0\n",
      "loss: 0.482481 accuracy: 83.0\n",
      "loss: 0.40762 accuracy: 83.0\n",
      "loss: 0.278744 accuracy: 92.0\n",
      "loss: 0.460377 accuracy: 88.0\n",
      "loss: 0.421408 accuracy: 85.0\n",
      "loss: 0.31776 accuracy: 90.0\n",
      "loss: 0.285406 accuracy: 91.0\n",
      "loss: 0.299027 accuracy: 88.0\n",
      "loss: 0.373428 accuracy: 88.0\n",
      "loss: 0.295932 accuracy: 91.0\n",
      "loss: 0.499257 accuracy: 86.0\n",
      "loss: 0.280793 accuracy: 94.0\n",
      "loss: 0.379651 accuracy: 90.0\n",
      "loss: 0.30532 accuracy: 90.0\n",
      "loss: 0.375601 accuracy: 91.0\n",
      "loss: 0.279657 accuracy: 90.0\n",
      "loss: 0.211014 accuracy: 93.0\n",
      "loss: 0.304152 accuracy: 94.0\n",
      "loss: 0.315842 accuracy: 92.0\n",
      "loss: 0.425982 accuracy: 86.0\n",
      "loss: 0.411043 accuracy: 87.0\n",
      "loss: 0.39251 accuracy: 86.0\n",
      "loss: 0.2836 accuracy: 88.0\n",
      "loss: 0.524193 accuracy: 87.0\n",
      "loss: 0.440652 accuracy: 88.0\n",
      "loss: 0.455585 accuracy: 88.0\n",
      "loss: 0.327333 accuracy: 92.0\n",
      "loss: 0.255174 accuracy: 91.0\n",
      "loss: 0.681785 accuracy: 82.0\n",
      "loss: 0.339603 accuracy: 91.0\n",
      "loss: 0.19724 accuracy: 95.0\n",
      "loss: 0.272488 accuracy: 96.0\n",
      "loss: 0.309332 accuracy: 91.0\n",
      "loss: 0.602369 accuracy: 83.0\n",
      "loss: 0.25039 accuracy: 91.0\n",
      "loss: 0.305738 accuracy: 92.0\n",
      "loss: 0.298364 accuracy: 91.0\n",
      "loss: 0.223084 accuracy: 92.0\n",
      "loss: 0.246963 accuracy: 91.0\n",
      "loss: 0.472715 accuracy: 90.0\n",
      "loss: 0.306495 accuracy: 90.0\n",
      "loss: 0.441491 accuracy: 89.0\n",
      "loss: 0.322153 accuracy: 90.0\n",
      "loss: 0.210696 accuracy: 93.0\n",
      "loss: 0.258519 accuracy: 93.0\n",
      "loss: 0.222668 accuracy: 95.0\n",
      "loss: 0.207105 accuracy: 94.0\n",
      "loss: 0.295518 accuracy: 92.0\n",
      "loss: 0.506743 accuracy: 84.0\n",
      "loss: 0.2548 accuracy: 91.0\n",
      "loss: 0.339169 accuracy: 91.0\n",
      "loss: 0.216159 accuracy: 96.0\n",
      "loss: 0.303317 accuracy: 93.0\n",
      "loss: 0.12129 accuracy: 97.0\n",
      "loss: 0.308872 accuracy: 88.0\n",
      "loss: 0.380657 accuracy: 86.0\n",
      "loss: 0.297534 accuracy: 88.0\n",
      "loss: 0.232747 accuracy: 91.0\n",
      "loss: 0.372962 accuracy: 89.0\n",
      "loss: 0.394985 accuracy: 93.0\n",
      "loss: 0.203861 accuracy: 94.0\n",
      "loss: 0.313129 accuracy: 88.0\n",
      "loss: 0.256466 accuracy: 92.0\n",
      "loss: 0.303178 accuracy: 88.0\n",
      "loss: 0.31053 accuracy: 91.0\n",
      "loss: 0.282775 accuracy: 92.0\n",
      "loss: 0.278901 accuracy: 95.0\n",
      "loss: 0.254948 accuracy: 92.0\n",
      "loss: 0.124594 accuracy: 97.0\n",
      "loss: 0.299935 accuracy: 90.0\n",
      "loss: 0.212707 accuracy: 92.0\n",
      "loss: 0.264779 accuracy: 91.0\n",
      "loss: 0.356559 accuracy: 91.0\n",
      "loss: 0.268408 accuracy: 94.0\n",
      "loss: 0.242753 accuracy: 95.0\n",
      "loss: 0.38555 accuracy: 88.0\n",
      "loss: 0.279298 accuracy: 89.0\n",
      "loss: 0.30733 accuracy: 93.0\n",
      "loss: 0.277987 accuracy: 90.0\n",
      "loss: 0.315435 accuracy: 93.0\n",
      "loss: 0.170547 accuracy: 95.0\n",
      "loss: 0.235824 accuracy: 94.0\n",
      "loss: 0.270911 accuracy: 92.0\n",
      "loss: 0.355044 accuracy: 87.0\n",
      "loss: 0.311258 accuracy: 90.0\n",
      "loss: 0.245164 accuracy: 96.0\n",
      "loss: 0.154639 accuracy: 94.0\n",
      "loss: 0.122336 accuracy: 98.0\n",
      "loss: 0.0999661 accuracy: 97.0\n",
      "loss: 0.233705 accuracy: 92.0\n",
      "loss: 0.243436 accuracy: 91.0\n",
      "loss: 0.325153 accuracy: 91.0\n",
      "loss: 0.13535 accuracy: 95.0\n",
      "loss: 0.126713 accuracy: 96.0\n",
      "loss: 0.168028 accuracy: 95.0\n",
      "loss: 0.265118 accuracy: 93.0\n",
      "loss: 0.172445 accuracy: 95.0\n",
      "loss: 0.289672 accuracy: 94.0\n",
      "loss: 0.186073 accuracy: 90.0\n",
      "loss: 0.297532 accuracy: 93.0\n",
      "loss: 0.24014 accuracy: 94.0\n",
      "loss: 0.193769 accuracy: 93.0\n",
      "loss: 0.252558 accuracy: 90.0\n",
      "loss: 0.217584 accuracy: 93.0\n",
      "loss: 0.283214 accuracy: 91.0\n",
      "loss: 0.322301 accuracy: 88.0\n",
      "loss: 0.348491 accuracy: 90.0\n",
      "loss: 0.310744 accuracy: 88.0\n",
      "loss: 0.329177 accuracy: 91.0\n",
      "loss: 0.161817 accuracy: 95.0\n",
      "loss: 0.250902 accuracy: 90.0\n",
      "loss: 0.25532 accuracy: 92.0\n",
      "loss: 0.179484 accuracy: 94.0\n",
      "loss: 0.193022 accuracy: 93.0\n",
      "loss: 0.164614 accuracy: 95.0\n",
      "loss: 0.167247 accuracy: 93.0\n",
      "loss: 0.300799 accuracy: 92.0\n",
      "loss: 0.473692 accuracy: 90.0\n",
      "loss: 0.154967 accuracy: 94.0\n",
      "loss: 0.233879 accuracy: 94.0\n",
      "loss: 0.162468 accuracy: 95.0\n",
      "loss: 0.119282 accuracy: 98.0\n",
      "loss: 0.277021 accuracy: 89.0\n",
      "loss: 0.190564 accuracy: 94.0\n",
      "loss: 0.145059 accuracy: 93.0\n",
      "loss: 0.177938 accuracy: 92.0\n",
      "loss: 0.355149 accuracy: 89.0\n",
      "loss: 0.228455 accuracy: 93.0\n",
      "loss: 0.202878 accuracy: 92.0\n",
      "loss: 0.326702 accuracy: 90.0\n",
      "loss: 0.15536 accuracy: 96.0\n",
      "loss: 0.243515 accuracy: 93.0\n",
      "loss: 0.27501 accuracy: 93.0\n",
      "loss: 0.264279 accuracy: 93.0\n",
      "loss: 0.265984 accuracy: 91.0\n",
      "loss: 0.334301 accuracy: 87.0\n",
      "loss: 0.240938 accuracy: 94.0\n",
      "loss: 0.173876 accuracy: 96.0\n",
      "loss: 0.117985 accuracy: 98.0\n",
      "loss: 0.231702 accuracy: 93.0\n",
      "loss: 0.270876 accuracy: 91.0\n",
      "loss: 0.260828 accuracy: 92.0\n",
      "loss: 0.191846 accuracy: 95.0\n",
      "loss: 0.17964 accuracy: 93.0\n",
      "loss: 0.212121 accuracy: 93.0\n",
      "loss: 0.48191 accuracy: 86.0\n",
      "loss: 0.209846 accuracy: 94.0\n",
      "loss: 0.268408 accuracy: 92.0\n",
      "loss: 0.149669 accuracy: 95.0\n",
      "loss: 0.327674 accuracy: 90.0\n",
      "loss: 0.276253 accuracy: 93.0\n",
      "loss: 0.13081 accuracy: 97.0\n",
      "loss: 0.186648 accuracy: 95.0\n",
      "loss: 0.279609 accuracy: 92.0\n",
      "loss: 0.186937 accuracy: 93.0\n",
      "loss: 0.297962 accuracy: 89.0\n",
      "loss: 0.227593 accuracy: 96.0\n",
      "loss: 0.114262 accuracy: 97.0\n",
      "loss: 0.285974 accuracy: 91.0\n",
      "loss: 0.316897 accuracy: 92.0\n",
      "loss: 0.221168 accuracy: 93.0\n",
      "loss: 0.225838 accuracy: 95.0\n",
      "loss: 0.291403 accuracy: 91.0\n",
      "loss: 0.283162 accuracy: 92.0\n",
      "loss: 0.246734 accuracy: 91.0\n",
      "loss: 0.236104 accuracy: 95.0\n",
      "loss: 0.222617 accuracy: 93.0\n",
      "loss: 0.179322 accuracy: 93.0\n",
      "loss: 0.192982 accuracy: 94.0\n",
      "loss: 0.108615 accuracy: 98.0\n",
      "loss: 0.106299 accuracy: 96.0\n",
      "loss: 0.189139 accuracy: 94.0\n",
      "loss: 0.158372 accuracy: 94.0\n",
      "loss: 0.245056 accuracy: 94.0\n",
      "loss: 0.346846 accuracy: 92.0\n",
      "loss: 0.161215 accuracy: 95.0\n",
      "loss: 0.371826 accuracy: 89.0\n",
      "loss: 0.109645 accuracy: 97.0\n",
      "loss: 0.197989 accuracy: 94.0\n",
      "loss: 0.202857 accuracy: 94.0\n",
      "loss: 0.218525 accuracy: 94.0\n",
      "loss: 0.130986 accuracy: 97.0\n",
      "loss: 0.218894 accuracy: 95.0\n",
      "loss: 0.235512 accuracy: 92.0\n",
      "loss: 0.273444 accuracy: 91.0\n",
      "loss: 0.262016 accuracy: 92.0\n",
      "loss: 0.159555 accuracy: 96.0\n",
      "loss: 0.0796456 accuracy: 99.0\n",
      "loss: 0.165833 accuracy: 97.0\n",
      "loss: 0.234144 accuracy: 94.0\n",
      "loss: 0.245473 accuracy: 95.0\n",
      "loss: 0.164211 accuracy: 93.0\n",
      "loss: 0.194683 accuracy: 95.0\n",
      "loss: 0.269557 accuracy: 92.0\n",
      "loss: 0.206081 accuracy: 92.0\n",
      "loss: 0.224985 accuracy: 92.0\n",
      "loss: 0.230757 accuracy: 92.0\n",
      "loss: 0.16774 accuracy: 96.0\n",
      "loss: 0.299906 accuracy: 89.0\n",
      "loss: 0.167486 accuracy: 94.0\n",
      "loss: 0.154562 accuracy: 95.0\n",
      "loss: 0.209605 accuracy: 95.0\n",
      "loss: 0.150649 accuracy: 94.0\n",
      "loss: 0.151284 accuracy: 97.0\n",
      "loss: 0.279619 accuracy: 90.0\n",
      "loss: 0.343055 accuracy: 88.0\n",
      "loss: 0.0566859 accuracy: 99.0\n",
      "loss: 0.160077 accuracy: 96.0\n",
      "loss: 0.205587 accuracy: 96.0\n",
      "loss: 0.207494 accuracy: 94.0\n",
      "loss: 0.195043 accuracy: 92.0\n",
      "loss: 0.276439 accuracy: 93.0\n",
      "loss: 0.344423 accuracy: 91.0\n",
      "loss: 0.285591 accuracy: 93.0\n",
      "loss: 0.253287 accuracy: 88.0\n",
      "loss: 0.250709 accuracy: 92.0\n",
      "loss: 0.23523 accuracy: 94.0\n",
      "loss: 0.181618 accuracy: 95.0\n",
      "loss: 0.272554 accuracy: 93.0\n",
      "loss: 0.317924 accuracy: 89.0\n",
      "loss: 0.435314 accuracy: 89.0\n",
      "loss: 0.187623 accuracy: 96.0\n",
      "loss: 0.0980458 accuracy: 98.0\n",
      "loss: 0.0713467 accuracy: 99.0\n",
      "loss: 0.177379 accuracy: 93.0\n",
      "loss: 0.104682 accuracy: 97.0\n",
      "loss: 0.292041 accuracy: 94.0\n",
      "loss: 0.108803 accuracy: 97.0\n",
      "loss: 0.189787 accuracy: 96.0\n",
      "loss: 0.156448 accuracy: 95.0\n",
      "loss: 0.12827 accuracy: 97.0\n",
      "loss: 0.291934 accuracy: 91.0\n",
      "loss: 0.184895 accuracy: 94.0\n",
      "loss: 0.158158 accuracy: 98.0\n",
      "loss: 0.178906 accuracy: 94.0\n",
      "loss: 0.347624 accuracy: 92.0\n",
      "loss: 0.143966 accuracy: 94.0\n",
      "loss: 0.217782 accuracy: 96.0\n",
      "loss: 0.105422 accuracy: 98.0\n",
      "loss: 0.149767 accuracy: 95.0\n",
      "loss: 0.185022 accuracy: 93.0\n",
      "loss: 0.191988 accuracy: 94.0\n",
      "loss: 0.205893 accuracy: 92.0\n",
      "loss: 0.194648 accuracy: 93.0\n",
      "loss: 0.24127 accuracy: 89.0\n",
      "loss: 0.334212 accuracy: 91.0\n",
      "loss: 0.128315 accuracy: 96.0\n",
      "loss: 0.145165 accuracy: 95.0\n",
      "loss: 0.149613 accuracy: 97.0\n",
      "loss: 0.164522 accuracy: 96.0\n",
      "loss: 0.235985 accuracy: 95.0\n",
      "loss: 0.165552 accuracy: 94.0\n",
      "loss: 0.204172 accuracy: 94.0\n",
      "loss: 0.253735 accuracy: 91.0\n",
      "loss: 0.283417 accuracy: 91.0\n",
      "loss: 0.249596 accuracy: 94.0\n",
      "loss: 0.136631 accuracy: 94.0\n",
      "loss: 0.108745 accuracy: 97.0\n",
      "loss: 0.208336 accuracy: 94.0\n",
      "loss: 0.178027 accuracy: 95.0\n",
      "loss: 0.101374 accuracy: 98.0\n",
      "loss: 0.236277 accuracy: 93.0\n",
      "loss: 0.260161 accuracy: 90.0\n",
      "loss: 0.275161 accuracy: 90.0\n",
      "loss: 0.097325 accuracy: 98.0\n",
      "loss: 0.14116 accuracy: 96.0\n",
      "loss: 0.196451 accuracy: 96.0\n",
      "loss: 0.196224 accuracy: 95.0\n",
      "loss: 0.247809 accuracy: 94.0\n",
      "loss: 0.18328 accuracy: 95.0\n",
      "loss: 0.209107 accuracy: 90.0\n",
      "loss: 0.136993 accuracy: 94.0\n",
      "loss: 0.128903 accuracy: 94.0\n",
      "loss: 0.268539 accuracy: 95.0\n",
      "loss: 0.273904 accuracy: 93.0\n",
      "loss: 0.224261 accuracy: 91.0\n",
      "loss: 0.181923 accuracy: 94.0\n",
      "loss: 0.137159 accuracy: 96.0\n",
      "loss: 0.107207 accuracy: 97.0\n",
      "loss: 0.119095 accuracy: 94.0\n",
      "loss: 0.198769 accuracy: 94.0\n",
      "loss: 0.137904 accuracy: 95.0\n",
      "loss: 0.232526 accuracy: 89.0\n",
      "loss: 0.204059 accuracy: 95.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.143068 accuracy: 94.0\n",
      "loss: 0.174443 accuracy: 95.0\n",
      "loss: 0.105212 accuracy: 95.0\n",
      "loss: 0.0861856 accuracy: 98.0\n",
      "loss: 0.133619 accuracy: 96.0\n",
      "loss: 0.238014 accuracy: 95.0\n",
      "loss: 0.163118 accuracy: 95.0\n",
      "loss: 0.132588 accuracy: 94.0\n",
      "loss: 0.163699 accuracy: 96.0\n",
      "loss: 0.227814 accuracy: 94.0\n",
      "loss: 0.314801 accuracy: 90.0\n",
      "loss: 0.209582 accuracy: 94.0\n",
      "loss: 0.105339 accuracy: 96.0\n",
      "loss: 0.182652 accuracy: 95.0\n",
      "loss: 0.102623 accuracy: 96.0\n",
      "loss: 0.18092 accuracy: 96.0\n",
      "loss: 0.12752 accuracy: 97.0\n",
      "loss: 0.156601 accuracy: 96.0\n",
      "loss: 0.102581 accuracy: 98.0\n",
      "loss: 0.262397 accuracy: 94.0\n",
      "loss: 0.108029 accuracy: 97.0\n",
      "loss: 0.170005 accuracy: 94.0\n",
      "loss: 0.187631 accuracy: 92.0\n",
      "loss: 0.0648149 accuracy: 98.0\n",
      "loss: 0.199785 accuracy: 92.0\n",
      "loss: 0.148929 accuracy: 95.0\n",
      "loss: 0.242221 accuracy: 93.0\n",
      "loss: 0.142532 accuracy: 95.0\n",
      "loss: 0.257073 accuracy: 93.0\n",
      "loss: 0.0982527 accuracy: 98.0\n",
      "loss: 0.277202 accuracy: 93.0\n",
      "loss: 0.182802 accuracy: 97.0\n",
      "loss: 0.147772 accuracy: 94.0\n",
      "loss: 0.0835336 accuracy: 97.0\n",
      "loss: 0.211731 accuracy: 92.0\n",
      "loss: 0.0997071 accuracy: 98.0\n",
      "loss: 0.144956 accuracy: 94.0\n",
      "loss: 0.139591 accuracy: 96.0\n",
      "loss: 0.139593 accuracy: 95.0\n",
      "loss: 0.127146 accuracy: 95.0\n",
      "loss: 0.157317 accuracy: 96.0\n",
      "loss: 0.101475 accuracy: 96.0\n",
      "loss: 0.14732 accuracy: 96.0\n",
      "loss: 0.107608 accuracy: 96.0\n",
      "loss: 0.191197 accuracy: 96.0\n",
      "loss: 0.190424 accuracy: 94.0\n",
      "loss: 0.145613 accuracy: 94.0\n",
      "loss: 0.0422225 accuracy: 98.0\n",
      "loss: 0.214349 accuracy: 94.0\n",
      "loss: 0.257243 accuracy: 93.0\n",
      "loss: 0.269098 accuracy: 94.0\n",
      "loss: 0.235074 accuracy: 93.0\n",
      "loss: 0.279546 accuracy: 94.0\n",
      "loss: 0.208588 accuracy: 92.0\n",
      "loss: 0.263372 accuracy: 93.0\n",
      "loss: 0.183583 accuracy: 94.0\n",
      "loss: 0.0525833 accuracy: 100.0\n",
      "loss: 0.278097 accuracy: 91.0\n",
      "loss: 0.214717 accuracy: 92.0\n",
      "loss: 0.186457 accuracy: 94.0\n",
      "loss: 0.165375 accuracy: 94.0\n",
      "loss: 0.133965 accuracy: 94.0\n",
      "loss: 0.111379 accuracy: 98.0\n",
      "loss: 0.131242 accuracy: 96.0\n",
      "loss: 0.229592 accuracy: 91.0\n",
      "loss: 0.122589 accuracy: 96.0\n",
      "loss: 0.106681 accuracy: 98.0\n",
      "loss: 0.0821655 accuracy: 97.0\n",
      "loss: 0.153891 accuracy: 93.0\n",
      "loss: 0.261613 accuracy: 92.0\n",
      "loss: 0.182783 accuracy: 96.0\n",
      "loss: 0.114865 accuracy: 98.0\n",
      "loss: 0.208126 accuracy: 92.0\n",
      "loss: 0.161972 accuracy: 97.0\n",
      "loss: 0.182213 accuracy: 95.0\n",
      "loss: 0.238434 accuracy: 94.0\n",
      "loss: 0.118766 accuracy: 96.0\n",
      "loss: 0.12438 accuracy: 97.0\n",
      "loss: 0.108181 accuracy: 97.0\n",
      "loss: 0.170016 accuracy: 96.0\n",
      "loss: 0.152897 accuracy: 93.0\n",
      "loss: 0.17505 accuracy: 96.0\n",
      "loss: 0.181756 accuracy: 94.0\n",
      "loss: 0.0707006 accuracy: 100.0\n",
      "loss: 0.262365 accuracy: 90.0\n",
      "loss: 0.135046 accuracy: 94.0\n",
      "loss: 0.108651 accuracy: 97.0\n",
      "loss: 0.0892123 accuracy: 98.0\n",
      "loss: 0.134114 accuracy: 96.0\n",
      "loss: 0.285663 accuracy: 94.0\n",
      "loss: 0.203149 accuracy: 96.0\n",
      "loss: 0.183891 accuracy: 92.0\n",
      "loss: 0.154516 accuracy: 95.0\n",
      "loss: 0.240408 accuracy: 94.0\n",
      "loss: 0.155529 accuracy: 95.0\n",
      "loss: 0.161933 accuracy: 96.0\n",
      "loss: 0.124298 accuracy: 95.0\n",
      "loss: 0.0874696 accuracy: 98.0\n",
      "loss: 0.361715 accuracy: 90.0\n",
      "loss: 0.095938 accuracy: 97.0\n",
      "loss: 0.0977481 accuracy: 97.0\n",
      "loss: 0.0846089 accuracy: 97.0\n",
      "loss: 0.0967109 accuracy: 96.0\n",
      "loss: 0.196456 accuracy: 93.0\n",
      "loss: 0.108345 accuracy: 96.0\n",
      "loss: 0.141363 accuracy: 96.0\n",
      "loss: 0.0929971 accuracy: 99.0\n",
      "loss: 0.127974 accuracy: 97.0\n",
      "loss: 0.242216 accuracy: 94.0\n",
      "loss: 0.153405 accuracy: 96.0\n",
      "loss: 0.17126 accuracy: 96.0\n",
      "loss: 0.190114 accuracy: 96.0\n",
      "loss: 0.135741 accuracy: 98.0\n",
      "loss: 0.164664 accuracy: 96.0\n",
      "loss: 0.171662 accuracy: 94.0\n",
      "loss: 0.181922 accuracy: 94.0\n",
      "loss: 0.132465 accuracy: 97.0\n",
      "loss: 0.149475 accuracy: 94.0\n",
      "loss: 0.230139 accuracy: 93.0\n",
      "loss: 0.0904042 accuracy: 98.0\n",
      "loss: 0.0819828 accuracy: 97.0\n",
      "loss: 0.198504 accuracy: 94.0\n",
      "loss: 0.0851187 accuracy: 97.0\n",
      "loss: 0.0845137 accuracy: 98.0\n",
      "loss: 0.141793 accuracy: 94.0\n",
      "loss: 0.282486 accuracy: 91.0\n",
      "loss: 0.208587 accuracy: 96.0\n",
      "loss: 0.0862603 accuracy: 96.0\n",
      "loss: 0.142259 accuracy: 95.0\n",
      "loss: 0.202277 accuracy: 90.0\n",
      "loss: 0.229977 accuracy: 93.0\n",
      "loss: 0.204541 accuracy: 95.0\n",
      "loss: 0.078238 accuracy: 97.0\n",
      "loss: 0.0326649 accuracy: 100.0\n",
      "loss: 0.16989 accuracy: 94.0\n",
      "loss: 0.204314 accuracy: 94.0\n",
      "loss: 0.158361 accuracy: 95.0\n",
      "loss: 0.147106 accuracy: 94.0\n",
      "loss: 0.294562 accuracy: 94.0\n",
      "loss: 0.271683 accuracy: 93.0\n",
      "loss: 0.232355 accuracy: 93.0\n",
      "loss: 0.110907 accuracy: 98.0\n",
      "loss: 0.22159 accuracy: 92.0\n",
      "loss: 0.304014 accuracy: 93.0\n",
      "loss: 0.141283 accuracy: 98.0\n",
      "loss: 0.151588 accuracy: 95.0\n",
      "loss: 0.114503 accuracy: 96.0\n",
      "loss: 0.184992 accuracy: 93.0\n",
      "loss: 0.0841526 accuracy: 96.0\n",
      "loss: 0.10477 accuracy: 98.0\n",
      "loss: 0.174013 accuracy: 94.0\n",
      "loss: 0.217845 accuracy: 94.0\n",
      "loss: 0.144502 accuracy: 96.0\n",
      "loss: 0.132965 accuracy: 98.0\n",
      "loss: 0.157598 accuracy: 94.0\n",
      "loss: 0.138409 accuracy: 96.0\n",
      "loss: 0.0791627 accuracy: 97.0\n",
      "loss: 0.073312 accuracy: 97.0\n",
      "loss: 0.109999 accuracy: 97.0\n",
      "loss: 0.258852 accuracy: 92.0\n",
      "loss: 0.112785 accuracy: 94.0\n",
      "loss: 0.118707 accuracy: 96.0\n",
      "loss: 0.177673 accuracy: 94.0\n",
      "loss: 0.0850724 accuracy: 98.0\n",
      ">>>>>>>>>> test dataset accuracy: 96.23\n",
      "loss: 0.153074 accuracy: 94.0\n",
      "loss: 0.115181 accuracy: 97.0\n",
      "loss: 0.130698 accuracy: 98.0\n",
      "loss: 0.108754 accuracy: 97.0\n",
      "loss: 0.0753427 accuracy: 98.0\n",
      "loss: 0.161901 accuracy: 94.0\n",
      "loss: 0.181194 accuracy: 96.0\n",
      "loss: 0.0943392 accuracy: 97.0\n",
      "loss: 0.177521 accuracy: 94.0\n",
      "loss: 0.127369 accuracy: 96.0\n",
      "loss: 0.252994 accuracy: 92.0\n",
      "loss: 0.144968 accuracy: 96.0\n",
      "loss: 0.142449 accuracy: 97.0\n",
      "loss: 0.150858 accuracy: 95.0\n",
      "loss: 0.195226 accuracy: 93.0\n",
      "loss: 0.0951858 accuracy: 97.0\n",
      "loss: 0.145043 accuracy: 97.0\n",
      "loss: 0.158864 accuracy: 97.0\n",
      "loss: 0.145285 accuracy: 94.0\n",
      "loss: 0.0780378 accuracy: 97.0\n",
      "loss: 0.0646025 accuracy: 98.0\n",
      "loss: 0.167411 accuracy: 95.0\n",
      "loss: 0.0632499 accuracy: 99.0\n",
      "loss: 0.11326 accuracy: 97.0\n",
      "loss: 0.223874 accuracy: 92.0\n",
      "loss: 0.196369 accuracy: 94.0\n",
      "loss: 0.0743558 accuracy: 97.0\n",
      "loss: 0.141713 accuracy: 96.0\n",
      "loss: 0.0589599 accuracy: 99.0\n",
      "loss: 0.19194 accuracy: 97.0\n",
      "loss: 0.0555155 accuracy: 98.0\n",
      "loss: 0.130317 accuracy: 96.0\n",
      "loss: 0.147643 accuracy: 95.0\n",
      "loss: 0.168305 accuracy: 96.0\n",
      "loss: 0.0545117 accuracy: 98.0\n",
      "loss: 0.0668055 accuracy: 99.0\n",
      "loss: 0.184295 accuracy: 95.0\n",
      "loss: 0.140751 accuracy: 95.0\n",
      "loss: 0.20996 accuracy: 97.0\n",
      "loss: 0.0552292 accuracy: 98.0\n",
      "loss: 0.186141 accuracy: 98.0\n",
      "loss: 0.15144 accuracy: 95.0\n",
      "loss: 0.0413073 accuracy: 99.0\n",
      "loss: 0.123171 accuracy: 97.0\n",
      "loss: 0.0762597 accuracy: 98.0\n",
      "loss: 0.0570883 accuracy: 98.0\n",
      "loss: 0.242858 accuracy: 93.0\n",
      "loss: 0.0845713 accuracy: 97.0\n",
      "loss: 0.102219 accuracy: 98.0\n",
      "loss: 0.252578 accuracy: 92.0\n",
      "loss: 0.119509 accuracy: 94.0\n",
      "loss: 0.188982 accuracy: 95.0\n",
      "loss: 0.144268 accuracy: 96.0\n",
      "loss: 0.0887756 accuracy: 98.0\n",
      "loss: 0.0859316 accuracy: 97.0\n",
      "loss: 0.138496 accuracy: 96.0\n",
      "loss: 0.0859224 accuracy: 98.0\n",
      "loss: 0.0676959 accuracy: 99.0\n",
      "loss: 0.114491 accuracy: 94.0\n",
      "loss: 0.0727313 accuracy: 98.0\n",
      "loss: 0.112214 accuracy: 98.0\n",
      "loss: 0.0684484 accuracy: 99.0\n",
      "loss: 0.13074 accuracy: 97.0\n",
      "loss: 0.0484209 accuracy: 100.0\n",
      "loss: 0.116431 accuracy: 96.0\n",
      "loss: 0.0998019 accuracy: 97.0\n",
      "loss: 0.0982359 accuracy: 94.0\n",
      "loss: 0.0541848 accuracy: 98.0\n",
      "loss: 0.102769 accuracy: 98.0\n",
      "loss: 0.240384 accuracy: 95.0\n",
      "loss: 0.0791273 accuracy: 98.0\n",
      "loss: 0.0884174 accuracy: 96.0\n",
      "loss: 0.0482484 accuracy: 99.0\n",
      "loss: 0.105927 accuracy: 98.0\n",
      "loss: 0.234728 accuracy: 92.0\n",
      "loss: 0.158171 accuracy: 94.0\n",
      "loss: 0.17821 accuracy: 94.0\n",
      "loss: 0.0790391 accuracy: 98.0\n",
      "loss: 0.0488752 accuracy: 99.0\n",
      "loss: 0.167675 accuracy: 96.0\n",
      "loss: 0.0652676 accuracy: 99.0\n",
      "loss: 0.0999469 accuracy: 97.0\n",
      "loss: 0.13846 accuracy: 96.0\n",
      "loss: 0.248215 accuracy: 95.0\n",
      "loss: 0.12137 accuracy: 96.0\n",
      "loss: 0.113063 accuracy: 98.0\n",
      "loss: 0.0842915 accuracy: 97.0\n",
      "loss: 0.134855 accuracy: 96.0\n",
      "loss: 0.0819983 accuracy: 97.0\n",
      "loss: 0.0589373 accuracy: 99.0\n",
      "loss: 0.0715977 accuracy: 97.0\n",
      "loss: 0.0677835 accuracy: 97.0\n",
      "loss: 0.171032 accuracy: 97.0\n",
      "loss: 0.153302 accuracy: 95.0\n",
      "loss: 0.180773 accuracy: 93.0\n",
      "loss: 0.0720648 accuracy: 99.0\n",
      "loss: 0.139137 accuracy: 94.0\n",
      "loss: 0.196952 accuracy: 94.0\n",
      "loss: 0.124983 accuracy: 96.0\n",
      "loss: 0.18296 accuracy: 95.0\n",
      "loss: 0.0834004 accuracy: 97.0\n",
      "loss: 0.147018 accuracy: 97.0\n",
      "loss: 0.198885 accuracy: 97.0\n",
      "loss: 0.117884 accuracy: 95.0\n",
      "loss: 0.0519652 accuracy: 99.0\n",
      "loss: 0.211345 accuracy: 94.0\n",
      "loss: 0.0429598 accuracy: 100.0\n",
      "loss: 0.10865 accuracy: 97.0\n",
      "loss: 0.137735 accuracy: 97.0\n",
      "loss: 0.124277 accuracy: 98.0\n",
      "loss: 0.135651 accuracy: 97.0\n",
      "loss: 0.129353 accuracy: 94.0\n",
      "loss: 0.110784 accuracy: 98.0\n",
      "loss: 0.204544 accuracy: 93.0\n",
      "loss: 0.129585 accuracy: 96.0\n",
      "loss: 0.0578107 accuracy: 99.0\n",
      "loss: 0.0557181 accuracy: 99.0\n",
      "loss: 0.044487 accuracy: 99.0\n",
      "loss: 0.238765 accuracy: 92.0\n",
      "loss: 0.197037 accuracy: 94.0\n",
      "loss: 0.126486 accuracy: 96.0\n",
      "loss: 0.206704 accuracy: 95.0\n",
      "loss: 0.230333 accuracy: 96.0\n",
      "loss: 0.108055 accuracy: 98.0\n",
      "loss: 0.0666988 accuracy: 98.0\n",
      "loss: 0.188581 accuracy: 94.0\n",
      "loss: 0.152988 accuracy: 97.0\n",
      "loss: 0.125596 accuracy: 96.0\n",
      "loss: 0.147003 accuracy: 94.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0983948 accuracy: 98.0\n",
      "loss: 0.101465 accuracy: 99.0\n",
      "loss: 0.0955366 accuracy: 95.0\n",
      "loss: 0.0979097 accuracy: 97.0\n",
      "loss: 0.0818639 accuracy: 96.0\n",
      "loss: 0.0663029 accuracy: 98.0\n",
      "loss: 0.0523059 accuracy: 98.0\n",
      "loss: 0.0517511 accuracy: 98.0\n",
      "loss: 0.116945 accuracy: 97.0\n",
      "loss: 0.135647 accuracy: 96.0\n",
      "loss: 0.117605 accuracy: 95.0\n",
      "loss: 0.0464652 accuracy: 99.0\n",
      "loss: 0.206183 accuracy: 95.0\n",
      "loss: 0.178332 accuracy: 93.0\n",
      "loss: 0.096166 accuracy: 95.0\n",
      "loss: 0.121548 accuracy: 96.0\n",
      "loss: 0.0372559 accuracy: 100.0\n",
      "loss: 0.138542 accuracy: 96.0\n",
      "loss: 0.112176 accuracy: 97.0\n",
      "loss: 0.140771 accuracy: 97.0\n",
      "loss: 0.101898 accuracy: 97.0\n",
      "loss: 0.195724 accuracy: 95.0\n",
      "loss: 0.130778 accuracy: 96.0\n",
      "loss: 0.0979172 accuracy: 98.0\n",
      "loss: 0.154416 accuracy: 96.0\n",
      "loss: 0.0852567 accuracy: 98.0\n",
      "loss: 0.092098 accuracy: 98.0\n",
      "loss: 0.0882537 accuracy: 99.0\n",
      "loss: 0.0843941 accuracy: 98.0\n",
      "loss: 0.087831 accuracy: 98.0\n",
      "loss: 0.189462 accuracy: 96.0\n",
      "loss: 0.0489697 accuracy: 99.0\n",
      "loss: 0.0778981 accuracy: 99.0\n",
      "loss: 0.0523934 accuracy: 98.0\n",
      "loss: 0.0758697 accuracy: 98.0\n",
      "loss: 0.253005 accuracy: 97.0\n",
      "loss: 0.110248 accuracy: 96.0\n",
      "loss: 0.310902 accuracy: 92.0\n",
      "loss: 0.0976575 accuracy: 98.0\n",
      "loss: 0.184433 accuracy: 96.0\n",
      "loss: 0.0752376 accuracy: 97.0\n",
      "loss: 0.0968361 accuracy: 96.0\n",
      "loss: 0.163654 accuracy: 97.0\n",
      "loss: 0.0983308 accuracy: 97.0\n",
      "loss: 0.0512461 accuracy: 98.0\n",
      "loss: 0.0814824 accuracy: 98.0\n",
      "loss: 0.0667509 accuracy: 98.0\n",
      "loss: 0.21398 accuracy: 91.0\n",
      "loss: 0.107991 accuracy: 97.0\n",
      "loss: 0.115264 accuracy: 96.0\n",
      "loss: 0.10264 accuracy: 97.0\n",
      "loss: 0.0497428 accuracy: 98.0\n",
      "loss: 0.138156 accuracy: 96.0\n",
      "loss: 0.124197 accuracy: 96.0\n",
      "loss: 0.139381 accuracy: 97.0\n",
      "loss: 0.0943233 accuracy: 98.0\n",
      "loss: 0.0904519 accuracy: 97.0\n",
      "loss: 0.322145 accuracy: 92.0\n",
      "loss: 0.107668 accuracy: 96.0\n",
      "loss: 0.10103 accuracy: 98.0\n",
      "loss: 0.066715 accuracy: 98.0\n",
      "loss: 0.0946415 accuracy: 97.0\n",
      "loss: 0.0986851 accuracy: 97.0\n",
      "loss: 0.0303755 accuracy: 100.0\n",
      "loss: 0.0595591 accuracy: 98.0\n",
      "loss: 0.124543 accuracy: 96.0\n",
      "loss: 0.133856 accuracy: 96.0\n",
      "loss: 0.0884272 accuracy: 98.0\n",
      "loss: 0.187123 accuracy: 95.0\n",
      "loss: 0.138321 accuracy: 96.0\n",
      "loss: 0.0748817 accuracy: 97.0\n",
      "loss: 0.0616857 accuracy: 98.0\n",
      "loss: 0.100436 accuracy: 97.0\n",
      "loss: 0.0614317 accuracy: 97.0\n",
      "loss: 0.185589 accuracy: 93.0\n",
      "loss: 0.106281 accuracy: 96.0\n",
      "loss: 0.0426564 accuracy: 99.0\n",
      "loss: 0.14629 accuracy: 96.0\n",
      "loss: 0.0439819 accuracy: 100.0\n",
      "loss: 0.0754028 accuracy: 97.0\n",
      "loss: 0.0647323 accuracy: 97.0\n",
      "loss: 0.126221 accuracy: 93.0\n",
      "loss: 0.0635308 accuracy: 98.0\n",
      "loss: 0.0766673 accuracy: 97.0\n",
      "loss: 0.254112 accuracy: 93.0\n",
      "loss: 0.117898 accuracy: 97.0\n",
      "loss: 0.071311 accuracy: 98.0\n",
      "loss: 0.195689 accuracy: 94.0\n",
      "loss: 0.0790818 accuracy: 97.0\n",
      "loss: 0.117098 accuracy: 96.0\n",
      "loss: 0.154893 accuracy: 93.0\n",
      "loss: 0.0444672 accuracy: 99.0\n",
      "loss: 0.222053 accuracy: 93.0\n",
      "loss: 0.141052 accuracy: 97.0\n",
      "loss: 0.115647 accuracy: 96.0\n",
      "loss: 0.067836 accuracy: 99.0\n",
      "loss: 0.0669534 accuracy: 97.0\n",
      "loss: 0.12554 accuracy: 93.0\n",
      "loss: 0.11464 accuracy: 95.0\n",
      "loss: 0.10466 accuracy: 98.0\n",
      "loss: 0.0425337 accuracy: 99.0\n",
      "loss: 0.204276 accuracy: 95.0\n",
      "loss: 0.15001 accuracy: 95.0\n",
      "loss: 0.0952908 accuracy: 97.0\n",
      "loss: 0.0595992 accuracy: 99.0\n",
      "loss: 0.0637401 accuracy: 98.0\n",
      "loss: 0.113389 accuracy: 97.0\n",
      "loss: 0.0346885 accuracy: 100.0\n",
      "loss: 0.0636543 accuracy: 98.0\n",
      "loss: 0.102444 accuracy: 97.0\n",
      "loss: 0.0342813 accuracy: 99.0\n",
      "loss: 0.155228 accuracy: 96.0\n",
      "loss: 0.0691342 accuracy: 97.0\n",
      "loss: 0.1846 accuracy: 94.0\n",
      "loss: 0.0589303 accuracy: 98.0\n",
      "loss: 0.106769 accuracy: 94.0\n",
      "loss: 0.133209 accuracy: 95.0\n",
      "loss: 0.0749325 accuracy: 99.0\n",
      "loss: 0.192231 accuracy: 93.0\n",
      "loss: 0.0448745 accuracy: 98.0\n",
      "loss: 0.0736512 accuracy: 96.0\n",
      "loss: 0.0499167 accuracy: 99.0\n",
      "loss: 0.083011 accuracy: 97.0\n",
      "loss: 0.0787558 accuracy: 98.0\n",
      "loss: 0.0729048 accuracy: 98.0\n",
      "loss: 0.174823 accuracy: 97.0\n",
      "loss: 0.0515413 accuracy: 99.0\n",
      "loss: 0.179969 accuracy: 96.0\n",
      "loss: 0.105375 accuracy: 96.0\n",
      "loss: 0.100322 accuracy: 96.0\n",
      "loss: 0.0578034 accuracy: 98.0\n",
      "loss: 0.0463264 accuracy: 100.0\n",
      "loss: 0.112913 accuracy: 96.0\n",
      "loss: 0.276757 accuracy: 96.0\n",
      "loss: 0.151205 accuracy: 96.0\n",
      "loss: 0.125786 accuracy: 96.0\n",
      "loss: 0.117564 accuracy: 95.0\n",
      "loss: 0.177081 accuracy: 96.0\n",
      "loss: 0.0936877 accuracy: 96.0\n",
      "loss: 0.106064 accuracy: 95.0\n",
      "loss: 0.0881005 accuracy: 99.0\n",
      "loss: 0.109566 accuracy: 95.0\n",
      "loss: 0.0911297 accuracy: 98.0\n",
      "loss: 0.0338236 accuracy: 98.0\n",
      "loss: 0.129653 accuracy: 96.0\n",
      "loss: 0.0657791 accuracy: 98.0\n",
      "loss: 0.0267947 accuracy: 100.0\n",
      "loss: 0.0448084 accuracy: 99.0\n",
      "loss: 0.100366 accuracy: 97.0\n",
      "loss: 0.125907 accuracy: 97.0\n",
      "loss: 0.0848941 accuracy: 97.0\n",
      "loss: 0.11108 accuracy: 98.0\n",
      "loss: 0.104126 accuracy: 97.0\n",
      "loss: 0.0610293 accuracy: 99.0\n",
      "loss: 0.0562726 accuracy: 97.0\n",
      "loss: 0.113619 accuracy: 97.0\n",
      "loss: 0.121745 accuracy: 96.0\n",
      "loss: 0.100969 accuracy: 98.0\n",
      "loss: 0.130547 accuracy: 97.0\n",
      "loss: 0.205445 accuracy: 95.0\n",
      "loss: 0.148898 accuracy: 94.0\n",
      "loss: 0.0301329 accuracy: 100.0\n",
      "loss: 0.175963 accuracy: 95.0\n",
      "loss: 0.0796472 accuracy: 97.0\n",
      "loss: 0.0515697 accuracy: 98.0\n",
      "loss: 0.140368 accuracy: 96.0\n",
      "loss: 0.0843781 accuracy: 98.0\n",
      "loss: 0.074946 accuracy: 97.0\n",
      "loss: 0.0860264 accuracy: 99.0\n",
      "loss: 0.067682 accuracy: 98.0\n",
      "loss: 0.0522911 accuracy: 97.0\n",
      "loss: 0.128359 accuracy: 97.0\n",
      "loss: 0.084799 accuracy: 98.0\n",
      "loss: 0.0477959 accuracy: 99.0\n",
      "loss: 0.153617 accuracy: 95.0\n",
      "loss: 0.198202 accuracy: 93.0\n",
      "loss: 0.16727 accuracy: 98.0\n",
      "loss: 0.147159 accuracy: 97.0\n",
      "loss: 0.0936637 accuracy: 97.0\n",
      "loss: 0.129881 accuracy: 94.0\n",
      "loss: 0.0579232 accuracy: 97.0\n",
      "loss: 0.148644 accuracy: 97.0\n",
      "loss: 0.0668501 accuracy: 97.0\n",
      "loss: 0.115327 accuracy: 96.0\n",
      "loss: 0.0822039 accuracy: 99.0\n",
      "loss: 0.0553876 accuracy: 99.0\n",
      "loss: 0.127187 accuracy: 95.0\n",
      "loss: 0.0818648 accuracy: 98.0\n",
      "loss: 0.125507 accuracy: 95.0\n",
      "loss: 0.0799543 accuracy: 98.0\n",
      "loss: 0.139508 accuracy: 94.0\n",
      "loss: 0.100578 accuracy: 98.0\n",
      "loss: 0.114634 accuracy: 97.0\n",
      "loss: 0.0624159 accuracy: 97.0\n",
      "loss: 0.0841402 accuracy: 97.0\n",
      "loss: 0.0841986 accuracy: 97.0\n",
      "loss: 0.119192 accuracy: 95.0\n",
      "loss: 0.130701 accuracy: 97.0\n",
      "loss: 0.0465715 accuracy: 98.0\n",
      "loss: 0.142555 accuracy: 96.0\n",
      "loss: 0.122393 accuracy: 97.0\n",
      "loss: 0.139663 accuracy: 96.0\n",
      "loss: 0.0408652 accuracy: 98.0\n",
      "loss: 0.11115 accuracy: 95.0\n",
      "loss: 0.144657 accuracy: 97.0\n",
      "loss: 0.133954 accuracy: 96.0\n",
      "loss: 0.225739 accuracy: 92.0\n",
      "loss: 0.197903 accuracy: 95.0\n",
      "loss: 0.125268 accuracy: 97.0\n",
      "loss: 0.0458683 accuracy: 99.0\n",
      "loss: 0.0696297 accuracy: 98.0\n",
      "loss: 0.0791676 accuracy: 98.0\n",
      "loss: 0.098882 accuracy: 98.0\n",
      "loss: 0.100957 accuracy: 97.0\n",
      "loss: 0.0570313 accuracy: 99.0\n",
      "loss: 0.0794769 accuracy: 98.0\n",
      "loss: 0.0943527 accuracy: 99.0\n",
      "loss: 0.131311 accuracy: 97.0\n",
      "loss: 0.0999733 accuracy: 96.0\n",
      "loss: 0.0572067 accuracy: 98.0\n",
      "loss: 0.0917027 accuracy: 97.0\n",
      "loss: 0.231979 accuracy: 94.0\n",
      "loss: 0.0689062 accuracy: 99.0\n",
      "loss: 0.147945 accuracy: 94.0\n",
      "loss: 0.0784694 accuracy: 96.0\n",
      "loss: 0.0654135 accuracy: 98.0\n",
      "loss: 0.129483 accuracy: 97.0\n",
      "loss: 0.0404341 accuracy: 100.0\n",
      "loss: 0.204918 accuracy: 95.0\n",
      "loss: 0.181584 accuracy: 93.0\n",
      "loss: 0.0698335 accuracy: 97.0\n",
      "loss: 0.12391 accuracy: 97.0\n",
      "loss: 0.0747525 accuracy: 98.0\n",
      "loss: 0.137843 accuracy: 96.0\n",
      "loss: 0.279866 accuracy: 93.0\n",
      "loss: 0.0945415 accuracy: 96.0\n",
      "loss: 0.044676 accuracy: 99.0\n",
      "loss: 0.0679008 accuracy: 97.0\n",
      "loss: 0.0771731 accuracy: 97.0\n",
      "loss: 0.103533 accuracy: 97.0\n",
      "loss: 0.0934999 accuracy: 96.0\n",
      "loss: 0.119288 accuracy: 97.0\n",
      "loss: 0.0613463 accuracy: 98.0\n",
      "loss: 0.0851758 accuracy: 95.0\n",
      "loss: 0.119049 accuracy: 97.0\n",
      "loss: 0.140254 accuracy: 96.0\n",
      "loss: 0.10394 accuracy: 97.0\n",
      "loss: 0.0870967 accuracy: 95.0\n",
      "loss: 0.0611691 accuracy: 99.0\n",
      "loss: 0.0898818 accuracy: 96.0\n",
      "loss: 0.142686 accuracy: 95.0\n",
      "loss: 0.1258 accuracy: 96.0\n",
      "loss: 0.148711 accuracy: 96.0\n",
      "loss: 0.0738589 accuracy: 98.0\n",
      "loss: 0.060937 accuracy: 99.0\n",
      "loss: 0.114187 accuracy: 97.0\n",
      "loss: 0.151988 accuracy: 95.0\n",
      "loss: 0.0931325 accuracy: 99.0\n",
      "loss: 0.102767 accuracy: 96.0\n",
      "loss: 0.093962 accuracy: 97.0\n",
      "loss: 0.0510014 accuracy: 98.0\n",
      "loss: 0.0227196 accuracy: 99.0\n",
      "loss: 0.13941 accuracy: 93.0\n",
      "loss: 0.196451 accuracy: 94.0\n",
      "loss: 0.117314 accuracy: 97.0\n",
      "loss: 0.0711192 accuracy: 98.0\n",
      "loss: 0.0920449 accuracy: 97.0\n",
      "loss: 0.0462386 accuracy: 100.0\n",
      "loss: 0.125942 accuracy: 94.0\n",
      "loss: 0.0795939 accuracy: 97.0\n",
      "loss: 0.072157 accuracy: 99.0\n",
      "loss: 0.092402 accuracy: 98.0\n",
      "loss: 0.0357084 accuracy: 100.0\n",
      "loss: 0.0474548 accuracy: 99.0\n",
      "loss: 0.0705329 accuracy: 99.0\n",
      "loss: 0.0170568 accuracy: 100.0\n",
      "loss: 0.0680961 accuracy: 99.0\n",
      "loss: 0.17487 accuracy: 96.0\n",
      "loss: 0.0911641 accuracy: 96.0\n",
      "loss: 0.0774247 accuracy: 96.0\n",
      "loss: 0.073502 accuracy: 97.0\n",
      "loss: 0.196883 accuracy: 98.0\n",
      "loss: 0.0503632 accuracy: 99.0\n",
      "loss: 0.165699 accuracy: 93.0\n",
      "loss: 0.11096 accuracy: 97.0\n",
      "loss: 0.107905 accuracy: 96.0\n",
      "loss: 0.0627359 accuracy: 97.0\n",
      "loss: 0.0981479 accuracy: 97.0\n",
      "loss: 0.0288111 accuracy: 99.0\n",
      "loss: 0.122797 accuracy: 97.0\n",
      "loss: 0.0723253 accuracy: 98.0\n",
      "loss: 0.153467 accuracy: 95.0\n",
      "loss: 0.0979972 accuracy: 96.0\n",
      "loss: 0.117216 accuracy: 97.0\n",
      "loss: 0.285261 accuracy: 92.0\n",
      "loss: 0.0976102 accuracy: 95.0\n",
      "loss: 0.0577044 accuracy: 97.0\n",
      "loss: 0.125134 accuracy: 94.0\n",
      "loss: 0.03477 accuracy: 99.0\n",
      "loss: 0.0983457 accuracy: 98.0\n",
      "loss: 0.0331926 accuracy: 100.0\n",
      "loss: 0.0346442 accuracy: 98.0\n",
      "loss: 0.134778 accuracy: 98.0\n",
      "loss: 0.123813 accuracy: 96.0\n",
      "loss: 0.0663927 accuracy: 99.0\n",
      "loss: 0.043561 accuracy: 99.0\n",
      "loss: 0.0505918 accuracy: 99.0\n",
      "loss: 0.0486679 accuracy: 99.0\n",
      "loss: 0.104286 accuracy: 97.0\n",
      "loss: 0.0676207 accuracy: 97.0\n",
      "loss: 0.0827908 accuracy: 96.0\n",
      "loss: 0.0936254 accuracy: 95.0\n",
      "loss: 0.0566821 accuracy: 99.0\n",
      "loss: 0.044528 accuracy: 98.0\n",
      "loss: 0.103263 accuracy: 95.0\n",
      "loss: 0.135376 accuracy: 97.0\n",
      "loss: 0.056927 accuracy: 99.0\n",
      "loss: 0.0720293 accuracy: 99.0\n",
      "loss: 0.0663372 accuracy: 98.0\n",
      "loss: 0.0299428 accuracy: 99.0\n",
      "loss: 0.0944788 accuracy: 97.0\n",
      "loss: 0.0659333 accuracy: 97.0\n",
      "loss: 0.13415 accuracy: 96.0\n",
      "loss: 0.0791426 accuracy: 98.0\n",
      "loss: 0.141176 accuracy: 97.0\n",
      "loss: 0.0427697 accuracy: 97.0\n",
      "loss: 0.101363 accuracy: 97.0\n",
      "loss: 0.0576042 accuracy: 97.0\n",
      "loss: 0.111911 accuracy: 97.0\n",
      "loss: 0.0306202 accuracy: 99.0\n",
      "loss: 0.0692857 accuracy: 97.0\n",
      "loss: 0.161946 accuracy: 96.0\n",
      "loss: 0.103032 accuracy: 96.0\n",
      "loss: 0.182204 accuracy: 96.0\n",
      "loss: 0.0830413 accuracy: 98.0\n",
      "loss: 0.0898314 accuracy: 98.0\n",
      "loss: 0.257026 accuracy: 94.0\n",
      "loss: 0.124651 accuracy: 98.0\n",
      "loss: 0.0268197 accuracy: 100.0\n",
      "loss: 0.170675 accuracy: 95.0\n",
      "loss: 0.0636695 accuracy: 98.0\n",
      "loss: 0.0293149 accuracy: 100.0\n",
      "loss: 0.0584837 accuracy: 97.0\n",
      "loss: 0.105559 accuracy: 97.0\n",
      "loss: 0.108628 accuracy: 97.0\n",
      "loss: 0.118562 accuracy: 97.0\n",
      "loss: 0.0352208 accuracy: 99.0\n",
      "loss: 0.215087 accuracy: 95.0\n",
      "loss: 0.109236 accuracy: 96.0\n",
      "loss: 0.132177 accuracy: 96.0\n",
      "loss: 0.179923 accuracy: 97.0\n",
      "loss: 0.0402531 accuracy: 99.0\n",
      "loss: 0.0474315 accuracy: 99.0\n",
      "loss: 0.0362427 accuracy: 99.0\n",
      "loss: 0.0708449 accuracy: 98.0\n",
      "loss: 0.0883234 accuracy: 96.0\n",
      "loss: 0.135618 accuracy: 94.0\n",
      "loss: 0.0293921 accuracy: 100.0\n",
      "loss: 0.0337377 accuracy: 99.0\n",
      "loss: 0.047326 accuracy: 98.0\n",
      "loss: 0.114634 accuracy: 96.0\n",
      "loss: 0.189793 accuracy: 96.0\n",
      "loss: 0.0242764 accuracy: 99.0\n",
      "loss: 0.0571045 accuracy: 99.0\n",
      "loss: 0.125077 accuracy: 96.0\n",
      "loss: 0.163223 accuracy: 95.0\n",
      "loss: 0.062311 accuracy: 99.0\n",
      "loss: 0.0473285 accuracy: 99.0\n",
      "loss: 0.0839427 accuracy: 98.0\n",
      "loss: 0.0812846 accuracy: 98.0\n",
      "loss: 0.120595 accuracy: 98.0\n",
      "loss: 0.106967 accuracy: 96.0\n",
      "loss: 0.133066 accuracy: 98.0\n",
      "loss: 0.0545527 accuracy: 98.0\n",
      "loss: 0.0299203 accuracy: 100.0\n",
      "loss: 0.0879229 accuracy: 97.0\n",
      "loss: 0.0951598 accuracy: 98.0\n",
      "loss: 0.109762 accuracy: 98.0\n",
      "loss: 0.074748 accuracy: 97.0\n",
      "loss: 0.122945 accuracy: 94.0\n",
      "loss: 0.146153 accuracy: 94.0\n",
      "loss: 0.0696091 accuracy: 97.0\n",
      "loss: 0.070495 accuracy: 97.0\n",
      "loss: 0.120107 accuracy: 97.0\n",
      "loss: 0.0990043 accuracy: 95.0\n",
      "loss: 0.0414525 accuracy: 99.0\n",
      "loss: 0.073418 accuracy: 98.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0615506 accuracy: 97.0\n",
      "loss: 0.0426345 accuracy: 98.0\n",
      "loss: 0.0567875 accuracy: 96.0\n",
      "loss: 0.0672125 accuracy: 97.0\n",
      "loss: 0.0976917 accuracy: 97.0\n",
      "loss: 0.0854013 accuracy: 96.0\n",
      "loss: 0.103681 accuracy: 96.0\n",
      "loss: 0.0812463 accuracy: 95.0\n",
      "loss: 0.0911084 accuracy: 96.0\n",
      "loss: 0.192348 accuracy: 93.0\n",
      "loss: 0.122805 accuracy: 96.0\n",
      "loss: 0.211828 accuracy: 97.0\n",
      "loss: 0.0910921 accuracy: 96.0\n",
      "loss: 0.0199493 accuracy: 100.0\n",
      "loss: 0.0796417 accuracy: 98.0\n",
      "loss: 0.150319 accuracy: 96.0\n",
      "loss: 0.0800245 accuracy: 98.0\n",
      "loss: 0.160095 accuracy: 96.0\n",
      "loss: 0.0490314 accuracy: 99.0\n",
      "loss: 0.108447 accuracy: 94.0\n",
      "loss: 0.0147867 accuracy: 100.0\n",
      "loss: 0.0845139 accuracy: 97.0\n",
      "loss: 0.254245 accuracy: 94.0\n",
      "loss: 0.0636924 accuracy: 99.0\n",
      "loss: 0.0561411 accuracy: 99.0\n",
      "loss: 0.0234214 accuracy: 100.0\n",
      "loss: 0.0854868 accuracy: 98.0\n",
      "loss: 0.0817208 accuracy: 96.0\n",
      "loss: 0.0702447 accuracy: 98.0\n",
      "loss: 0.118431 accuracy: 96.0\n",
      "loss: 0.0972277 accuracy: 97.0\n",
      "loss: 0.173837 accuracy: 96.0\n",
      "loss: 0.0322145 accuracy: 100.0\n",
      ">>>>>>>>>> test dataset accuracy: 96.16\n",
      "loss: 0.169709 accuracy: 94.0\n",
      "loss: 0.142787 accuracy: 96.0\n",
      "loss: 0.0548564 accuracy: 98.0\n",
      "loss: 0.0695491 accuracy: 97.0\n",
      "loss: 0.139021 accuracy: 96.0\n",
      "loss: 0.0425727 accuracy: 98.0\n",
      "loss: 0.0368144 accuracy: 99.0\n",
      "loss: 0.019958 accuracy: 100.0\n",
      "loss: 0.0949779 accuracy: 98.0\n",
      "loss: 0.0619392 accuracy: 97.0\n",
      "loss: 0.0691935 accuracy: 97.0\n",
      "loss: 0.104029 accuracy: 99.0\n",
      "loss: 0.141995 accuracy: 97.0\n",
      "loss: 0.0262168 accuracy: 99.0\n",
      "loss: 0.098846 accuracy: 95.0\n",
      "loss: 0.119886 accuracy: 97.0\n",
      "loss: 0.036744 accuracy: 99.0\n",
      "loss: 0.0530154 accuracy: 97.0\n",
      "loss: 0.0608891 accuracy: 98.0\n",
      "loss: 0.0310403 accuracy: 99.0\n",
      "loss: 0.0441001 accuracy: 99.0\n",
      "loss: 0.0143967 accuracy: 100.0\n",
      "loss: 0.0893639 accuracy: 99.0\n",
      "loss: 0.0884134 accuracy: 97.0\n",
      "loss: 0.0392985 accuracy: 100.0\n",
      "loss: 0.0687517 accuracy: 97.0\n",
      "loss: 0.0697813 accuracy: 99.0\n",
      "loss: 0.0992471 accuracy: 98.0\n",
      "loss: 0.0192547 accuracy: 99.0\n",
      "loss: 0.0822985 accuracy: 96.0\n",
      "loss: 0.11893 accuracy: 96.0\n",
      "loss: 0.0658694 accuracy: 99.0\n",
      "loss: 0.0742253 accuracy: 98.0\n",
      "loss: 0.0159657 accuracy: 100.0\n",
      "loss: 0.0271014 accuracy: 100.0\n",
      "loss: 0.080317 accuracy: 98.0\n",
      "loss: 0.0668814 accuracy: 97.0\n",
      "loss: 0.0264867 accuracy: 99.0\n",
      "loss: 0.0787144 accuracy: 98.0\n",
      "loss: 0.0332689 accuracy: 99.0\n",
      "loss: 0.0816382 accuracy: 96.0\n",
      "loss: 0.0522086 accuracy: 98.0\n",
      "loss: 0.0953763 accuracy: 97.0\n",
      "loss: 0.028779 accuracy: 100.0\n",
      "loss: 0.0947377 accuracy: 96.0\n",
      "loss: 0.0674352 accuracy: 98.0\n",
      "loss: 0.0884314 accuracy: 95.0\n",
      "loss: 0.0939294 accuracy: 98.0\n",
      "loss: 0.0370166 accuracy: 100.0\n",
      "loss: 0.0472666 accuracy: 98.0\n",
      "loss: 0.0775043 accuracy: 97.0\n",
      "loss: 0.118972 accuracy: 95.0\n",
      "loss: 0.0430256 accuracy: 99.0\n",
      "loss: 0.0471224 accuracy: 98.0\n",
      "loss: 0.0464589 accuracy: 99.0\n",
      "loss: 0.108884 accuracy: 97.0\n",
      "loss: 0.0667346 accuracy: 99.0\n",
      "loss: 0.023917 accuracy: 100.0\n",
      "loss: 0.0957034 accuracy: 98.0\n",
      "loss: 0.0406862 accuracy: 100.0\n",
      "loss: 0.0785346 accuracy: 97.0\n",
      "loss: 0.0859331 accuracy: 97.0\n",
      "loss: 0.103786 accuracy: 97.0\n",
      "loss: 0.0468191 accuracy: 98.0\n",
      "loss: 0.0385283 accuracy: 98.0\n",
      "loss: 0.0547706 accuracy: 98.0\n",
      "loss: 0.0230676 accuracy: 100.0\n",
      "loss: 0.0369192 accuracy: 99.0\n",
      "loss: 0.029841 accuracy: 100.0\n",
      "loss: 0.0247668 accuracy: 99.0\n",
      "loss: 0.0321422 accuracy: 99.0\n",
      "loss: 0.0474881 accuracy: 99.0\n",
      "loss: 0.127734 accuracy: 95.0\n",
      "loss: 0.0681186 accuracy: 96.0\n",
      "loss: 0.0428615 accuracy: 99.0\n",
      "loss: 0.0315371 accuracy: 98.0\n",
      "loss: 0.0176864 accuracy: 100.0\n",
      "loss: 0.0721351 accuracy: 97.0\n",
      "loss: 0.157555 accuracy: 94.0\n",
      "loss: 0.12001 accuracy: 97.0\n",
      "loss: 0.067247 accuracy: 98.0\n",
      "loss: 0.0600188 accuracy: 96.0\n",
      "loss: 0.0764872 accuracy: 99.0\n",
      "loss: 0.0758969 accuracy: 98.0\n",
      "loss: 0.0182323 accuracy: 100.0\n",
      "loss: 0.120004 accuracy: 96.0\n",
      "loss: 0.0726568 accuracy: 99.0\n",
      "loss: 0.0508037 accuracy: 98.0\n",
      "loss: 0.0180068 accuracy: 100.0\n",
      "loss: 0.0794631 accuracy: 98.0\n",
      "loss: 0.032047 accuracy: 99.0\n",
      "loss: 0.0239917 accuracy: 99.0\n",
      "loss: 0.103445 accuracy: 97.0\n",
      "loss: 0.0262628 accuracy: 100.0\n",
      "loss: 0.0690337 accuracy: 98.0\n",
      "loss: 0.0121085 accuracy: 100.0\n",
      "loss: 0.0849661 accuracy: 99.0\n",
      "loss: 0.122721 accuracy: 97.0\n",
      "loss: 0.106664 accuracy: 97.0\n",
      "loss: 0.0385135 accuracy: 99.0\n",
      "loss: 0.0380183 accuracy: 99.0\n",
      "loss: 0.0160351 accuracy: 100.0\n",
      "loss: 0.0520073 accuracy: 98.0\n",
      "loss: 0.016174 accuracy: 100.0\n",
      "loss: 0.0413648 accuracy: 99.0\n",
      "loss: 0.044706 accuracy: 98.0\n",
      "loss: 0.10171 accuracy: 95.0\n",
      "loss: 0.0279207 accuracy: 100.0\n",
      "loss: 0.0680026 accuracy: 99.0\n",
      "loss: 0.0591967 accuracy: 96.0\n",
      "loss: 0.10305 accuracy: 97.0\n",
      "loss: 0.00940171 accuracy: 100.0\n",
      "loss: 0.0873252 accuracy: 97.0\n",
      "loss: 0.0695285 accuracy: 97.0\n",
      "loss: 0.089263 accuracy: 96.0\n",
      "loss: 0.132307 accuracy: 95.0\n",
      "loss: 0.110572 accuracy: 96.0\n",
      "loss: 0.0421453 accuracy: 99.0\n",
      "loss: 0.0151269 accuracy: 100.0\n",
      "loss: 0.0281034 accuracy: 99.0\n",
      "loss: 0.0176418 accuracy: 100.0\n",
      "loss: 0.0721547 accuracy: 98.0\n",
      "loss: 0.0240469 accuracy: 100.0\n",
      "loss: 0.0454389 accuracy: 98.0\n",
      "loss: 0.0577835 accuracy: 97.0\n",
      "loss: 0.0737465 accuracy: 96.0\n",
      "loss: 0.0799535 accuracy: 97.0\n",
      "loss: 0.0752791 accuracy: 98.0\n",
      "loss: 0.108776 accuracy: 96.0\n",
      "loss: 0.110516 accuracy: 98.0\n",
      "loss: 0.0252408 accuracy: 99.0\n",
      "loss: 0.0710573 accuracy: 99.0\n",
      "loss: 0.0296995 accuracy: 100.0\n",
      "loss: 0.0241732 accuracy: 100.0\n",
      "loss: 0.0390772 accuracy: 99.0\n",
      "loss: 0.0749672 accuracy: 95.0\n",
      "loss: 0.130768 accuracy: 96.0\n",
      "loss: 0.0338128 accuracy: 99.0\n",
      "loss: 0.0524622 accuracy: 98.0\n",
      "loss: 0.110577 accuracy: 96.0\n",
      "loss: 0.0279237 accuracy: 100.0\n",
      "loss: 0.126167 accuracy: 97.0\n",
      "loss: 0.0911061 accuracy: 97.0\n",
      "loss: 0.0311463 accuracy: 100.0\n",
      "loss: 0.0821355 accuracy: 97.0\n",
      "loss: 0.100605 accuracy: 96.0\n",
      "loss: 0.107531 accuracy: 97.0\n",
      "loss: 0.0846803 accuracy: 97.0\n",
      "loss: 0.0804863 accuracy: 98.0\n",
      "loss: 0.0735243 accuracy: 97.0\n",
      "loss: 0.0296542 accuracy: 100.0\n",
      "loss: 0.039024 accuracy: 100.0\n",
      "loss: 0.0547471 accuracy: 98.0\n",
      "loss: 0.0345872 accuracy: 98.0\n",
      "loss: 0.221877 accuracy: 94.0\n",
      "loss: 0.0458917 accuracy: 99.0\n",
      "loss: 0.122204 accuracy: 96.0\n",
      "loss: 0.0189245 accuracy: 100.0\n",
      "loss: 0.0593508 accuracy: 98.0\n",
      "loss: 0.0506267 accuracy: 98.0\n",
      "loss: 0.0860164 accuracy: 98.0\n",
      "loss: 0.0276077 accuracy: 99.0\n",
      "loss: 0.0220011 accuracy: 99.0\n",
      "loss: 0.0310221 accuracy: 99.0\n",
      "loss: 0.0850048 accuracy: 98.0\n",
      "loss: 0.0238653 accuracy: 100.0\n",
      "loss: 0.0806804 accuracy: 97.0\n",
      "loss: 0.0393455 accuracy: 99.0\n",
      "loss: 0.0536936 accuracy: 98.0\n",
      "loss: 0.0621634 accuracy: 97.0\n",
      "loss: 0.0206465 accuracy: 100.0\n",
      "loss: 0.150881 accuracy: 94.0\n",
      "loss: 0.170311 accuracy: 95.0\n",
      "loss: 0.06916 accuracy: 98.0\n",
      "loss: 0.0761964 accuracy: 97.0\n",
      "loss: 0.0553614 accuracy: 98.0\n",
      "loss: 0.0606706 accuracy: 98.0\n",
      "loss: 0.134666 accuracy: 96.0\n",
      "loss: 0.175954 accuracy: 96.0\n",
      "loss: 0.121307 accuracy: 97.0\n",
      "loss: 0.0598138 accuracy: 97.0\n",
      "loss: 0.0398958 accuracy: 99.0\n",
      "loss: 0.0350551 accuracy: 99.0\n",
      "loss: 0.0753722 accuracy: 97.0\n",
      "loss: 0.0731457 accuracy: 99.0\n",
      "loss: 0.0486685 accuracy: 98.0\n",
      "loss: 0.050436 accuracy: 99.0\n",
      "loss: 0.0583611 accuracy: 98.0\n",
      "loss: 0.0799802 accuracy: 98.0\n",
      "loss: 0.0238589 accuracy: 100.0\n",
      "loss: 0.0333113 accuracy: 100.0\n",
      "loss: 0.108569 accuracy: 96.0\n",
      "loss: 0.0271998 accuracy: 99.0\n",
      "loss: 0.0952123 accuracy: 97.0\n",
      "loss: 0.0699505 accuracy: 98.0\n",
      "loss: 0.0393872 accuracy: 99.0\n",
      "loss: 0.0270146 accuracy: 98.0\n",
      "loss: 0.0655963 accuracy: 98.0\n",
      "loss: 0.0401478 accuracy: 99.0\n",
      "loss: 0.0573401 accuracy: 98.0\n",
      "loss: 0.0276418 accuracy: 100.0\n",
      "loss: 0.161051 accuracy: 94.0\n",
      "loss: 0.0561709 accuracy: 98.0\n",
      "loss: 0.0398184 accuracy: 99.0\n",
      "loss: 0.0934499 accuracy: 97.0\n",
      "loss: 0.032222 accuracy: 100.0\n",
      "loss: 0.0381109 accuracy: 98.0\n",
      "loss: 0.0317795 accuracy: 100.0\n",
      "loss: 0.0517163 accuracy: 99.0\n",
      "loss: 0.129574 accuracy: 93.0\n",
      "loss: 0.147758 accuracy: 96.0\n",
      "loss: 0.0256607 accuracy: 99.0\n",
      "loss: 0.0502456 accuracy: 98.0\n",
      "loss: 0.0592586 accuracy: 99.0\n",
      "loss: 0.0544429 accuracy: 98.0\n",
      "loss: 0.0815104 accuracy: 98.0\n",
      "loss: 0.0340761 accuracy: 100.0\n",
      "loss: 0.103911 accuracy: 95.0\n",
      "loss: 0.02929 accuracy: 99.0\n",
      "loss: 0.0825717 accuracy: 98.0\n",
      "loss: 0.0357165 accuracy: 99.0\n",
      "loss: 0.114518 accuracy: 97.0\n",
      "loss: 0.015036 accuracy: 100.0\n",
      "loss: 0.0219806 accuracy: 99.0\n",
      "loss: 0.0950512 accuracy: 97.0\n",
      "loss: 0.180238 accuracy: 96.0\n",
      "loss: 0.101523 accuracy: 97.0\n",
      "loss: 0.0557506 accuracy: 98.0\n",
      "loss: 0.0362448 accuracy: 99.0\n",
      "loss: 0.0728501 accuracy: 98.0\n",
      "loss: 0.158267 accuracy: 94.0\n",
      "loss: 0.0526851 accuracy: 98.0\n",
      "loss: 0.119623 accuracy: 95.0\n",
      "loss: 0.0617677 accuracy: 98.0\n",
      "loss: 0.175307 accuracy: 95.0\n",
      "loss: 0.0744987 accuracy: 99.0\n",
      "loss: 0.0775724 accuracy: 97.0\n",
      "loss: 0.0631185 accuracy: 99.0\n",
      "loss: 0.122346 accuracy: 96.0\n",
      "loss: 0.0490293 accuracy: 98.0\n",
      "loss: 0.138658 accuracy: 97.0\n",
      "loss: 0.140984 accuracy: 96.0\n",
      "loss: 0.0670322 accuracy: 98.0\n",
      "loss: 0.0870869 accuracy: 97.0\n",
      "loss: 0.0425576 accuracy: 99.0\n",
      "loss: 0.126825 accuracy: 98.0\n",
      "loss: 0.057392 accuracy: 98.0\n",
      "loss: 0.0770793 accuracy: 99.0\n",
      "loss: 0.125362 accuracy: 99.0\n",
      "loss: 0.103051 accuracy: 97.0\n",
      "loss: 0.0292663 accuracy: 99.0\n",
      "loss: 0.0451619 accuracy: 98.0\n",
      "loss: 0.036745 accuracy: 98.0\n",
      "loss: 0.047542 accuracy: 98.0\n",
      "loss: 0.0197925 accuracy: 100.0\n",
      "loss: 0.0451756 accuracy: 99.0\n",
      "loss: 0.0688326 accuracy: 97.0\n",
      "loss: 0.0840216 accuracy: 97.0\n",
      "loss: 0.0450734 accuracy: 99.0\n",
      "loss: 0.0756964 accuracy: 99.0\n",
      "loss: 0.03049 accuracy: 99.0\n",
      "loss: 0.0682956 accuracy: 97.0\n",
      "loss: 0.0597333 accuracy: 99.0\n",
      "loss: 0.0499147 accuracy: 98.0\n",
      "loss: 0.123206 accuracy: 97.0\n",
      "loss: 0.049734 accuracy: 99.0\n",
      "loss: 0.055617 accuracy: 98.0\n",
      "loss: 0.0832543 accuracy: 98.0\n",
      "loss: 0.0267333 accuracy: 100.0\n",
      "loss: 0.0176061 accuracy: 100.0\n",
      "loss: 0.0181078 accuracy: 100.0\n",
      "loss: 0.0830984 accuracy: 98.0\n",
      "loss: 0.0918113 accuracy: 96.0\n",
      "loss: 0.0708825 accuracy: 99.0\n",
      "loss: 0.134339 accuracy: 98.0\n",
      "loss: 0.042709 accuracy: 99.0\n",
      "loss: 0.0668973 accuracy: 97.0\n",
      "loss: 0.134804 accuracy: 95.0\n",
      "loss: 0.0529426 accuracy: 99.0\n",
      "loss: 0.0434899 accuracy: 98.0\n",
      "loss: 0.0558179 accuracy: 97.0\n",
      "loss: 0.0790083 accuracy: 97.0\n",
      "loss: 0.0159121 accuracy: 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0321124 accuracy: 99.0\n",
      "loss: 0.0904256 accuracy: 98.0\n",
      "loss: 0.0204486 accuracy: 100.0\n",
      "loss: 0.0530792 accuracy: 98.0\n",
      "loss: 0.094785 accuracy: 97.0\n",
      "loss: 0.0412973 accuracy: 99.0\n",
      "loss: 0.0897626 accuracy: 98.0\n",
      "loss: 0.0255332 accuracy: 100.0\n",
      "loss: 0.0780249 accuracy: 96.0\n",
      "loss: 0.0755791 accuracy: 96.0\n",
      "loss: 0.0238643 accuracy: 100.0\n",
      "loss: 0.0841488 accuracy: 98.0\n",
      "loss: 0.025342 accuracy: 100.0\n",
      "loss: 0.123984 accuracy: 97.0\n",
      "loss: 0.0470971 accuracy: 99.0\n",
      "loss: 0.0941565 accuracy: 97.0\n",
      "loss: 0.0354718 accuracy: 98.0\n",
      "loss: 0.0496177 accuracy: 99.0\n",
      "loss: 0.0275361 accuracy: 99.0\n",
      "loss: 0.0573838 accuracy: 98.0\n",
      "loss: 0.0834087 accuracy: 99.0\n",
      "loss: 0.0790734 accuracy: 97.0\n",
      "loss: 0.0275195 accuracy: 99.0\n",
      "loss: 0.0440719 accuracy: 99.0\n",
      "loss: 0.122027 accuracy: 96.0\n",
      "loss: 0.0600223 accuracy: 99.0\n",
      "loss: 0.071375 accuracy: 98.0\n",
      "loss: 0.0421621 accuracy: 98.0\n",
      "loss: 0.0571945 accuracy: 98.0\n",
      "loss: 0.106216 accuracy: 96.0\n",
      "loss: 0.0763776 accuracy: 97.0\n",
      "loss: 0.0350131 accuracy: 99.0\n",
      "loss: 0.129766 accuracy: 94.0\n",
      "loss: 0.0695698 accuracy: 97.0\n",
      "loss: 0.0200088 accuracy: 100.0\n",
      "loss: 0.0496696 accuracy: 98.0\n",
      "loss: 0.0163763 accuracy: 100.0\n",
      "loss: 0.00617534 accuracy: 100.0\n",
      "loss: 0.0640431 accuracy: 98.0\n",
      "loss: 0.0635541 accuracy: 98.0\n",
      "loss: 0.150707 accuracy: 96.0\n",
      "loss: 0.0805365 accuracy: 97.0\n",
      "loss: 0.118574 accuracy: 98.0\n",
      "loss: 0.0970568 accuracy: 98.0\n",
      "loss: 0.049935 accuracy: 97.0\n",
      "loss: 0.035453 accuracy: 100.0\n",
      "loss: 0.0476975 accuracy: 98.0\n",
      "loss: 0.0711109 accuracy: 99.0\n",
      "loss: 0.0545807 accuracy: 98.0\n",
      "loss: 0.0638355 accuracy: 98.0\n",
      "loss: 0.0268122 accuracy: 98.0\n",
      "loss: 0.0498353 accuracy: 98.0\n",
      "loss: 0.109006 accuracy: 95.0\n",
      "loss: 0.12349 accuracy: 97.0\n",
      "loss: 0.0727957 accuracy: 98.0\n",
      "loss: 0.0387458 accuracy: 99.0\n",
      "loss: 0.1352 accuracy: 97.0\n",
      "loss: 0.0363826 accuracy: 99.0\n",
      "loss: 0.0700804 accuracy: 97.0\n",
      "loss: 0.0183476 accuracy: 100.0\n",
      "loss: 0.110845 accuracy: 94.0\n",
      "loss: 0.0339035 accuracy: 100.0\n",
      "loss: 0.0793242 accuracy: 98.0\n",
      "loss: 0.0225683 accuracy: 100.0\n",
      "loss: 0.127085 accuracy: 97.0\n",
      "loss: 0.0849805 accuracy: 98.0\n",
      "loss: 0.14192 accuracy: 95.0\n",
      "loss: 0.121084 accuracy: 99.0\n",
      "loss: 0.055966 accuracy: 99.0\n",
      "loss: 0.0306662 accuracy: 99.0\n",
      "loss: 0.108931 accuracy: 96.0\n",
      "loss: 0.0463956 accuracy: 99.0\n",
      "loss: 0.0361676 accuracy: 98.0\n",
      "loss: 0.0532407 accuracy: 98.0\n",
      "loss: 0.0472963 accuracy: 97.0\n",
      "loss: 0.123323 accuracy: 98.0\n",
      "loss: 0.0306996 accuracy: 99.0\n",
      "loss: 0.0392175 accuracy: 99.0\n",
      "loss: 0.0182048 accuracy: 100.0\n",
      "loss: 0.040409 accuracy: 99.0\n",
      "loss: 0.0881585 accuracy: 95.0\n",
      "loss: 0.028159 accuracy: 100.0\n",
      "loss: 0.0600834 accuracy: 98.0\n",
      "loss: 0.0273529 accuracy: 100.0\n",
      "loss: 0.0485742 accuracy: 97.0\n",
      "loss: 0.0579186 accuracy: 98.0\n",
      "loss: 0.0700497 accuracy: 99.0\n",
      "loss: 0.0633335 accuracy: 97.0\n",
      "loss: 0.0810469 accuracy: 97.0\n",
      "loss: 0.0399772 accuracy: 99.0\n",
      "loss: 0.0384563 accuracy: 99.0\n",
      "loss: 0.0759411 accuracy: 98.0\n",
      "loss: 0.0139441 accuracy: 100.0\n",
      "loss: 0.0151965 accuracy: 100.0\n",
      "loss: 0.00842152 accuracy: 100.0\n",
      "loss: 0.151018 accuracy: 97.0\n",
      "loss: 0.0751128 accuracy: 98.0\n",
      "loss: 0.065571 accuracy: 99.0\n",
      "loss: 0.0207612 accuracy: 100.0\n",
      "loss: 0.0778242 accuracy: 98.0\n",
      "loss: 0.031368 accuracy: 99.0\n",
      "loss: 0.0257445 accuracy: 99.0\n",
      "loss: 0.108299 accuracy: 97.0\n",
      "loss: 0.0213431 accuracy: 100.0\n",
      "loss: 0.0497767 accuracy: 98.0\n",
      "loss: 0.0269405 accuracy: 100.0\n",
      "loss: 0.118442 accuracy: 99.0\n",
      "loss: 0.0369594 accuracy: 99.0\n",
      "loss: 0.0975402 accuracy: 96.0\n",
      "loss: 0.0222159 accuracy: 99.0\n",
      "loss: 0.0742339 accuracy: 98.0\n",
      "loss: 0.075347 accuracy: 99.0\n",
      "loss: 0.165883 accuracy: 98.0\n",
      "loss: 0.104289 accuracy: 98.0\n",
      "loss: 0.0256034 accuracy: 100.0\n",
      "loss: 0.0857617 accuracy: 98.0\n",
      "loss: 0.07304 accuracy: 98.0\n",
      "loss: 0.108096 accuracy: 97.0\n",
      "loss: 0.0869093 accuracy: 95.0\n",
      "loss: 0.19616 accuracy: 96.0\n",
      "loss: 0.0252901 accuracy: 98.0\n",
      "loss: 0.0453495 accuracy: 99.0\n",
      "loss: 0.043856 accuracy: 98.0\n",
      "loss: 0.152689 accuracy: 97.0\n",
      "loss: 0.0682911 accuracy: 97.0\n",
      "loss: 0.0633184 accuracy: 98.0\n",
      "loss: 0.0373665 accuracy: 99.0\n",
      "loss: 0.0260064 accuracy: 99.0\n",
      "loss: 0.0510046 accuracy: 96.0\n",
      "loss: 0.0776201 accuracy: 98.0\n",
      "loss: 0.0931678 accuracy: 95.0\n",
      "loss: 0.103552 accuracy: 96.0\n",
      "loss: 0.145409 accuracy: 96.0\n",
      "loss: 0.0429955 accuracy: 99.0\n",
      "loss: 0.0815735 accuracy: 97.0\n",
      "loss: 0.0309245 accuracy: 100.0\n",
      "loss: 0.0464065 accuracy: 98.0\n",
      "loss: 0.143222 accuracy: 94.0\n",
      "loss: 0.0263477 accuracy: 100.0\n",
      "loss: 0.0178345 accuracy: 99.0\n",
      "loss: 0.0362324 accuracy: 99.0\n",
      "loss: 0.0932958 accuracy: 97.0\n",
      "loss: 0.0851965 accuracy: 98.0\n",
      "loss: 0.0117442 accuracy: 100.0\n",
      "loss: 0.0715272 accuracy: 98.0\n",
      "loss: 0.0772477 accuracy: 96.0\n",
      "loss: 0.03848 accuracy: 98.0\n",
      "loss: 0.0436253 accuracy: 98.0\n",
      "loss: 0.111605 accuracy: 96.0\n",
      "loss: 0.0897508 accuracy: 97.0\n",
      "loss: 0.0677231 accuracy: 96.0\n",
      "loss: 0.0671449 accuracy: 99.0\n",
      "loss: 0.0828194 accuracy: 98.0\n",
      "loss: 0.0804643 accuracy: 96.0\n",
      "loss: 0.0321766 accuracy: 99.0\n",
      "loss: 0.0223865 accuracy: 100.0\n",
      "loss: 0.0704042 accuracy: 98.0\n",
      "loss: 0.163286 accuracy: 96.0\n",
      "loss: 0.0631628 accuracy: 97.0\n",
      "loss: 0.0725873 accuracy: 98.0\n",
      "loss: 0.0426469 accuracy: 98.0\n",
      "loss: 0.0126584 accuracy: 100.0\n",
      "loss: 0.0690024 accuracy: 98.0\n",
      "loss: 0.0322287 accuracy: 99.0\n",
      "loss: 0.0821881 accuracy: 97.0\n",
      "loss: 0.0728993 accuracy: 99.0\n",
      "loss: 0.093543 accuracy: 96.0\n",
      "loss: 0.0627737 accuracy: 97.0\n",
      "loss: 0.10141 accuracy: 97.0\n",
      "loss: 0.0715121 accuracy: 98.0\n",
      "loss: 0.01863 accuracy: 100.0\n",
      "loss: 0.150755 accuracy: 98.0\n",
      "loss: 0.0653014 accuracy: 99.0\n",
      "loss: 0.135934 accuracy: 96.0\n",
      "loss: 0.0685667 accuracy: 99.0\n",
      "loss: 0.0832286 accuracy: 97.0\n",
      "loss: 0.0548756 accuracy: 98.0\n",
      "loss: 0.0275348 accuracy: 99.0\n",
      "loss: 0.0278405 accuracy: 98.0\n",
      "loss: 0.0843264 accuracy: 98.0\n",
      "loss: 0.0407128 accuracy: 99.0\n",
      "loss: 0.0226024 accuracy: 99.0\n",
      "loss: 0.0544471 accuracy: 98.0\n",
      "loss: 0.0972151 accuracy: 97.0\n",
      "loss: 0.0468375 accuracy: 98.0\n",
      "loss: 0.102679 accuracy: 96.0\n",
      "loss: 0.0599935 accuracy: 98.0\n",
      "loss: 0.0440094 accuracy: 98.0\n",
      "loss: 0.0171384 accuracy: 100.0\n",
      "loss: 0.0284427 accuracy: 99.0\n",
      "loss: 0.0300264 accuracy: 99.0\n",
      "loss: 0.0414168 accuracy: 99.0\n",
      "loss: 0.0498688 accuracy: 98.0\n",
      "loss: 0.0662046 accuracy: 97.0\n",
      "loss: 0.0194978 accuracy: 99.0\n",
      "loss: 0.0800517 accuracy: 97.0\n",
      "loss: 0.0491966 accuracy: 99.0\n",
      "loss: 0.0425095 accuracy: 99.0\n",
      "loss: 0.0654668 accuracy: 97.0\n",
      "loss: 0.0297101 accuracy: 100.0\n",
      "loss: 0.0283508 accuracy: 99.0\n",
      "loss: 0.0792652 accuracy: 98.0\n",
      "loss: 0.0577238 accuracy: 99.0\n",
      "loss: 0.0961153 accuracy: 97.0\n",
      "loss: 0.0192658 accuracy: 100.0\n",
      "loss: 0.0538693 accuracy: 99.0\n",
      "loss: 0.0461874 accuracy: 98.0\n",
      "loss: 0.0631681 accuracy: 98.0\n",
      "loss: 0.0573193 accuracy: 98.0\n",
      "loss: 0.0511855 accuracy: 98.0\n",
      "loss: 0.0487429 accuracy: 97.0\n",
      "loss: 0.0596973 accuracy: 98.0\n",
      "loss: 0.0969558 accuracy: 98.0\n",
      "loss: 0.0276425 accuracy: 99.0\n",
      "loss: 0.0388042 accuracy: 98.0\n",
      "loss: 0.0594272 accuracy: 99.0\n",
      "loss: 0.0308845 accuracy: 99.0\n",
      "loss: 0.0226903 accuracy: 100.0\n",
      "loss: 0.0201234 accuracy: 100.0\n",
      "loss: 0.0389249 accuracy: 98.0\n",
      "loss: 0.101676 accuracy: 96.0\n",
      "loss: 0.0550736 accuracy: 98.0\n",
      "loss: 0.0924028 accuracy: 97.0\n",
      "loss: 0.133205 accuracy: 96.0\n",
      "loss: 0.0683708 accuracy: 98.0\n",
      "loss: 0.0790676 accuracy: 98.0\n",
      "loss: 0.128214 accuracy: 97.0\n",
      "loss: 0.0555964 accuracy: 98.0\n",
      "loss: 0.0247954 accuracy: 100.0\n",
      "loss: 0.0944058 accuracy: 96.0\n",
      "loss: 0.0252298 accuracy: 100.0\n",
      "loss: 0.103568 accuracy: 95.0\n",
      "loss: 0.186413 accuracy: 95.0\n",
      "loss: 0.0605589 accuracy: 98.0\n",
      "loss: 0.021898 accuracy: 100.0\n",
      "loss: 0.0562726 accuracy: 98.0\n",
      "loss: 0.136839 accuracy: 98.0\n",
      "loss: 0.032583 accuracy: 99.0\n",
      "loss: 0.0970712 accuracy: 96.0\n",
      "loss: 0.154703 accuracy: 98.0\n",
      "loss: 0.0881148 accuracy: 99.0\n",
      "loss: 0.0619559 accuracy: 98.0\n",
      "loss: 0.0388647 accuracy: 99.0\n",
      "loss: 0.04167 accuracy: 99.0\n",
      "loss: 0.0229762 accuracy: 100.0\n",
      "loss: 0.0593731 accuracy: 98.0\n",
      "loss: 0.0668549 accuracy: 99.0\n",
      "loss: 0.107627 accuracy: 96.0\n",
      "loss: 0.0735721 accuracy: 98.0\n",
      "loss: 0.0362283 accuracy: 98.0\n",
      "loss: 0.0436776 accuracy: 99.0\n",
      "loss: 0.0344954 accuracy: 100.0\n",
      "loss: 0.0470555 accuracy: 98.0\n",
      "loss: 0.0703441 accuracy: 99.0\n",
      "loss: 0.0451392 accuracy: 98.0\n",
      "loss: 0.118165 accuracy: 97.0\n",
      "loss: 0.0689538 accuracy: 98.0\n",
      "loss: 0.0546015 accuracy: 99.0\n",
      "loss: 0.0109118 accuracy: 100.0\n",
      "loss: 0.092381 accuracy: 95.0\n",
      "loss: 0.0564156 accuracy: 98.0\n",
      "loss: 0.0553017 accuracy: 99.0\n",
      "loss: 0.0371206 accuracy: 99.0\n",
      "loss: 0.0263672 accuracy: 99.0\n",
      "loss: 0.0157345 accuracy: 100.0\n",
      "loss: 0.0327687 accuracy: 99.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>> test dataset accuracy: 97.47\n",
      "loss: 0.0860299 accuracy: 98.0\n",
      "loss: 0.0362442 accuracy: 99.0\n",
      "loss: 0.0187933 accuracy: 99.0\n",
      "loss: 0.01592 accuracy: 100.0\n",
      "loss: 0.015988 accuracy: 100.0\n",
      "loss: 0.0435335 accuracy: 98.0\n",
      "loss: 0.0251939 accuracy: 100.0\n",
      "loss: 0.0453758 accuracy: 99.0\n",
      "loss: 0.011277 accuracy: 100.0\n",
      "loss: 0.0118251 accuracy: 100.0\n",
      "loss: 0.0334619 accuracy: 99.0\n",
      "loss: 0.0254428 accuracy: 100.0\n",
      "loss: 0.00602948 accuracy: 100.0\n",
      "loss: 0.0161334 accuracy: 100.0\n",
      "loss: 0.144265 accuracy: 96.0\n",
      "loss: 0.0240662 accuracy: 99.0\n",
      "loss: 0.00730252 accuracy: 100.0\n",
      "loss: 0.0263831 accuracy: 100.0\n",
      "loss: 0.0395359 accuracy: 98.0\n",
      "loss: 0.117849 accuracy: 99.0\n",
      "loss: 0.0720768 accuracy: 98.0\n",
      "loss: 0.0440612 accuracy: 100.0\n",
      "loss: 0.0247857 accuracy: 100.0\n",
      "loss: 0.0363584 accuracy: 98.0\n",
      "loss: 0.0266149 accuracy: 99.0\n",
      "loss: 0.0221557 accuracy: 99.0\n",
      "loss: 0.0146138 accuracy: 100.0\n",
      "loss: 0.0626886 accuracy: 99.0\n",
      "loss: 0.0319398 accuracy: 99.0\n",
      "loss: 0.0562871 accuracy: 98.0\n",
      "loss: 0.0484697 accuracy: 98.0\n",
      "loss: 0.0562586 accuracy: 98.0\n",
      "loss: 0.0184871 accuracy: 99.0\n",
      "loss: 0.0201395 accuracy: 99.0\n",
      "loss: 0.0192962 accuracy: 100.0\n",
      "loss: 0.0973897 accuracy: 98.0\n",
      "loss: 0.0207348 accuracy: 100.0\n",
      "loss: 0.0334297 accuracy: 99.0\n",
      "loss: 0.0204749 accuracy: 100.0\n",
      "loss: 0.0540661 accuracy: 98.0\n",
      "loss: 0.0447328 accuracy: 99.0\n",
      "loss: 0.0461208 accuracy: 99.0\n",
      "loss: 0.0366117 accuracy: 99.0\n",
      "loss: 0.0253281 accuracy: 99.0\n",
      "loss: 0.0115631 accuracy: 100.0\n",
      "loss: 0.0266829 accuracy: 100.0\n",
      "loss: 0.0115367 accuracy: 100.0\n",
      "loss: 0.070998 accuracy: 98.0\n",
      "loss: 0.0484505 accuracy: 99.0\n",
      "loss: 0.0200539 accuracy: 99.0\n",
      "loss: 0.0315706 accuracy: 99.0\n",
      "loss: 0.0116789 accuracy: 100.0\n",
      "loss: 0.0171426 accuracy: 100.0\n",
      "loss: 0.0115723 accuracy: 100.0\n",
      "loss: 0.0151232 accuracy: 100.0\n",
      "loss: 0.0363838 accuracy: 98.0\n",
      "loss: 0.0238237 accuracy: 99.0\n",
      "loss: 0.0739663 accuracy: 98.0\n",
      "loss: 0.0455729 accuracy: 98.0\n",
      "loss: 0.0782295 accuracy: 96.0\n",
      "loss: 0.0055408 accuracy: 100.0\n",
      "loss: 0.00629557 accuracy: 100.0\n",
      "loss: 0.0303044 accuracy: 100.0\n",
      "loss: 0.0772225 accuracy: 99.0\n",
      "loss: 0.0250793 accuracy: 99.0\n",
      "loss: 0.0240744 accuracy: 99.0\n",
      "loss: 0.0185604 accuracy: 99.0\n",
      "loss: 0.031103 accuracy: 98.0\n",
      "loss: 0.063617 accuracy: 98.0\n",
      "loss: 0.0721734 accuracy: 97.0\n",
      "loss: 0.0252399 accuracy: 99.0\n",
      "loss: 0.0119684 accuracy: 100.0\n",
      "loss: 0.0419586 accuracy: 98.0\n",
      "loss: 0.0544273 accuracy: 98.0\n",
      "loss: 0.0801808 accuracy: 98.0\n",
      "loss: 0.023042 accuracy: 100.0\n",
      "loss: 0.0431114 accuracy: 99.0\n",
      "loss: 0.0249466 accuracy: 100.0\n",
      "loss: 0.0449659 accuracy: 98.0\n",
      "loss: 0.0513764 accuracy: 99.0\n",
      "loss: 0.0458983 accuracy: 98.0\n",
      "loss: 0.0197386 accuracy: 100.0\n",
      "loss: 0.0218922 accuracy: 100.0\n",
      "loss: 0.0099782 accuracy: 100.0\n",
      "loss: 0.0251306 accuracy: 99.0\n",
      "loss: 0.0181488 accuracy: 100.0\n",
      "loss: 0.00695629 accuracy: 100.0\n",
      "loss: 0.0208759 accuracy: 99.0\n",
      "loss: 0.0328455 accuracy: 99.0\n",
      "loss: 0.0350265 accuracy: 99.0\n",
      "loss: 0.0458211 accuracy: 97.0\n",
      "loss: 0.0659499 accuracy: 97.0\n",
      "loss: 0.0062469 accuracy: 100.0\n",
      "loss: 0.0846961 accuracy: 98.0\n",
      "loss: 0.0923473 accuracy: 98.0\n",
      "loss: 0.0225433 accuracy: 99.0\n",
      "loss: 0.0625386 accuracy: 98.0\n",
      "loss: 0.107583 accuracy: 98.0\n",
      "loss: 0.0650176 accuracy: 99.0\n",
      "loss: 0.0164281 accuracy: 100.0\n",
      "loss: 0.0718604 accuracy: 98.0\n",
      "loss: 0.0649751 accuracy: 98.0\n",
      "loss: 0.144202 accuracy: 95.0\n",
      "loss: 0.0552685 accuracy: 99.0\n",
      "loss: 0.0840172 accuracy: 97.0\n",
      "loss: 0.030616 accuracy: 100.0\n",
      "loss: 0.0092207 accuracy: 100.0\n",
      "loss: 0.0320338 accuracy: 100.0\n",
      "loss: 0.0130219 accuracy: 100.0\n",
      "loss: 0.0141127 accuracy: 100.0\n",
      "loss: 0.0133068 accuracy: 100.0\n",
      "loss: 0.048763 accuracy: 98.0\n",
      "loss: 0.079502 accuracy: 97.0\n",
      "loss: 0.0211289 accuracy: 100.0\n",
      "loss: 0.0647908 accuracy: 97.0\n",
      "loss: 0.00798355 accuracy: 100.0\n",
      "loss: 0.0190245 accuracy: 100.0\n",
      "loss: 0.0235866 accuracy: 99.0\n",
      "loss: 0.0831346 accuracy: 98.0\n",
      "loss: 0.0497141 accuracy: 99.0\n",
      "loss: 0.0400163 accuracy: 99.0\n",
      "loss: 0.0558686 accuracy: 98.0\n",
      "loss: 0.0164719 accuracy: 99.0\n",
      "loss: 0.0479898 accuracy: 99.0\n",
      "loss: 0.018424 accuracy: 100.0\n",
      "loss: 0.00766547 accuracy: 100.0\n",
      "loss: 0.0160022 accuracy: 100.0\n",
      "loss: 0.0602531 accuracy: 97.0\n",
      "loss: 0.0712685 accuracy: 97.0\n",
      "loss: 0.109637 accuracy: 99.0\n",
      "loss: 0.0343568 accuracy: 99.0\n",
      "loss: 0.0355459 accuracy: 99.0\n",
      "loss: 0.0287061 accuracy: 99.0\n",
      "loss: 0.0565073 accuracy: 98.0\n",
      "loss: 0.0185382 accuracy: 100.0\n",
      "loss: 0.0208673 accuracy: 99.0\n",
      "loss: 0.116545 accuracy: 99.0\n",
      "loss: 0.036418 accuracy: 99.0\n",
      "loss: 0.0188622 accuracy: 100.0\n",
      "loss: 0.0313605 accuracy: 99.0\n",
      "loss: 0.0299574 accuracy: 99.0\n",
      "loss: 0.02012 accuracy: 100.0\n",
      "loss: 0.100609 accuracy: 98.0\n",
      "loss: 0.0367038 accuracy: 99.0\n",
      "loss: 0.0562319 accuracy: 98.0\n",
      "loss: 0.0846527 accuracy: 98.0\n",
      "loss: 0.0678778 accuracy: 98.0\n",
      "loss: 0.0608355 accuracy: 97.0\n",
      "loss: 0.103037 accuracy: 95.0\n",
      "loss: 0.0103817 accuracy: 100.0\n",
      "loss: 0.0728764 accuracy: 98.0\n",
      "loss: 0.0129555 accuracy: 100.0\n",
      "loss: 0.0506629 accuracy: 97.0\n",
      "loss: 0.025678 accuracy: 99.0\n",
      "loss: 0.028461 accuracy: 99.0\n",
      "loss: 0.107664 accuracy: 96.0\n",
      "loss: 0.0811897 accuracy: 99.0\n",
      "loss: 0.021373 accuracy: 99.0\n",
      "loss: 0.035906 accuracy: 99.0\n",
      "loss: 0.0585774 accuracy: 98.0\n",
      "loss: 0.0239877 accuracy: 100.0\n",
      "loss: 0.0318666 accuracy: 99.0\n",
      "loss: 0.0171685 accuracy: 100.0\n",
      "loss: 0.0585528 accuracy: 98.0\n",
      "loss: 0.0813987 accuracy: 96.0\n",
      "loss: 0.128043 accuracy: 98.0\n",
      "loss: 0.0323636 accuracy: 99.0\n",
      "loss: 0.0449565 accuracy: 99.0\n",
      "loss: 0.0303614 accuracy: 100.0\n",
      "loss: 0.0142392 accuracy: 100.0\n",
      "loss: 0.0315726 accuracy: 99.0\n",
      "loss: 0.087075 accuracy: 97.0\n",
      "loss: 0.0688324 accuracy: 98.0\n",
      "loss: 0.0240482 accuracy: 100.0\n",
      "loss: 0.120557 accuracy: 96.0\n",
      "loss: 0.0128838 accuracy: 100.0\n",
      "loss: 0.0367901 accuracy: 99.0\n",
      "loss: 0.0145056 accuracy: 100.0\n",
      "loss: 0.0193285 accuracy: 100.0\n",
      "loss: 0.0420151 accuracy: 97.0\n",
      "loss: 0.0251364 accuracy: 100.0\n",
      "loss: 0.0655665 accuracy: 98.0\n",
      "loss: 0.0164308 accuracy: 100.0\n",
      "loss: 0.0203168 accuracy: 100.0\n",
      "loss: 0.0294394 accuracy: 99.0\n",
      "loss: 0.0219676 accuracy: 100.0\n",
      "loss: 0.019404 accuracy: 100.0\n",
      "loss: 0.0287446 accuracy: 99.0\n",
      "loss: 0.0400131 accuracy: 99.0\n",
      "loss: 0.0950741 accuracy: 98.0\n",
      "loss: 0.0107888 accuracy: 100.0\n",
      "loss: 0.0865802 accuracy: 97.0\n",
      "loss: 0.0392568 accuracy: 99.0\n",
      "loss: 0.0505866 accuracy: 99.0\n",
      "loss: 0.0704118 accuracy: 97.0\n",
      "loss: 0.0531143 accuracy: 99.0\n",
      "loss: 0.0118088 accuracy: 99.0\n",
      "loss: 0.0115441 accuracy: 100.0\n",
      "loss: 0.0125256 accuracy: 100.0\n",
      "loss: 0.0304633 accuracy: 99.0\n",
      "loss: 0.0403412 accuracy: 99.0\n",
      "loss: 0.0192158 accuracy: 100.0\n",
      "loss: 0.0602207 accuracy: 98.0\n",
      "loss: 0.0289341 accuracy: 99.0\n",
      "loss: 0.0425649 accuracy: 99.0\n",
      "loss: 0.023307 accuracy: 99.0\n",
      "loss: 0.0202945 accuracy: 100.0\n",
      "loss: 0.0727772 accuracy: 98.0\n",
      "loss: 0.0367306 accuracy: 98.0\n",
      "loss: 0.125104 accuracy: 98.0\n",
      "loss: 0.0801153 accuracy: 96.0\n",
      "loss: 0.0332347 accuracy: 100.0\n",
      "loss: 0.0307014 accuracy: 99.0\n",
      "loss: 0.0347076 accuracy: 98.0\n",
      "loss: 0.0352765 accuracy: 99.0\n",
      "loss: 0.0137907 accuracy: 100.0\n",
      "loss: 0.0210789 accuracy: 99.0\n",
      "loss: 0.0425161 accuracy: 98.0\n",
      "loss: 0.0803583 accuracy: 98.0\n",
      "loss: 0.0681447 accuracy: 97.0\n",
      "loss: 0.0206782 accuracy: 100.0\n",
      "loss: 0.0143596 accuracy: 100.0\n",
      "loss: 0.0374268 accuracy: 98.0\n",
      "loss: 0.0187564 accuracy: 100.0\n",
      "loss: 0.0283406 accuracy: 99.0\n",
      "loss: 0.0932899 accuracy: 98.0\n",
      "loss: 0.0301208 accuracy: 99.0\n",
      "loss: 0.0363016 accuracy: 99.0\n",
      "loss: 0.0360289 accuracy: 98.0\n",
      "loss: 0.0184075 accuracy: 100.0\n",
      "loss: 0.0734173 accuracy: 98.0\n",
      "loss: 0.0767293 accuracy: 97.0\n",
      "loss: 0.0222206 accuracy: 100.0\n",
      "loss: 0.0255 accuracy: 99.0\n",
      "loss: 0.0355751 accuracy: 99.0\n",
      "loss: 0.0760227 accuracy: 98.0\n",
      "loss: 0.0823611 accuracy: 97.0\n",
      "loss: 0.00934583 accuracy: 100.0\n",
      "loss: 0.0503199 accuracy: 98.0\n",
      "loss: 0.0263717 accuracy: 99.0\n",
      "loss: 0.0117985 accuracy: 100.0\n",
      "loss: 0.01676 accuracy: 100.0\n",
      "loss: 0.0845482 accuracy: 96.0\n",
      "loss: 0.0289714 accuracy: 100.0\n",
      "loss: 0.0425458 accuracy: 99.0\n",
      "loss: 0.0190131 accuracy: 100.0\n",
      "loss: 0.0158094 accuracy: 100.0\n",
      "loss: 0.0254852 accuracy: 99.0\n",
      "loss: 0.0200931 accuracy: 99.0\n",
      "loss: 0.00836681 accuracy: 100.0\n",
      "loss: 0.0222275 accuracy: 99.0\n",
      "loss: 0.0906708 accuracy: 98.0\n",
      "loss: 0.0710551 accuracy: 98.0\n",
      "loss: 0.00584185 accuracy: 100.0\n",
      "loss: 0.0582786 accuracy: 98.0\n",
      "loss: 0.0335693 accuracy: 98.0\n",
      "loss: 0.03042 accuracy: 98.0\n",
      "loss: 0.0271798 accuracy: 99.0\n",
      "loss: 0.025408 accuracy: 99.0\n",
      "loss: 0.044536 accuracy: 99.0\n",
      "loss: 0.0162601 accuracy: 99.0\n",
      "loss: 0.054201 accuracy: 98.0\n",
      "loss: 0.0160323 accuracy: 99.0\n",
      "loss: 0.0705259 accuracy: 98.0\n",
      "loss: 0.0114495 accuracy: 100.0\n",
      "loss: 0.0244481 accuracy: 99.0\n",
      "loss: 0.00946468 accuracy: 100.0\n",
      "loss: 0.0317098 accuracy: 99.0\n",
      "loss: 0.021938 accuracy: 99.0\n",
      "loss: 0.0501554 accuracy: 99.0\n",
      "loss: 0.0866057 accuracy: 97.0\n",
      "loss: 0.0193733 accuracy: 100.0\n",
      "loss: 0.0644611 accuracy: 99.0\n",
      "loss: 0.0733662 accuracy: 98.0\n",
      "loss: 0.0196695 accuracy: 100.0\n",
      "loss: 0.0307455 accuracy: 98.0\n",
      "loss: 0.0300972 accuracy: 99.0\n",
      "loss: 0.022025 accuracy: 100.0\n",
      "loss: 0.0300534 accuracy: 99.0\n",
      "loss: 0.0368554 accuracy: 99.0\n",
      "loss: 0.0449226 accuracy: 98.0\n",
      "loss: 0.0295188 accuracy: 99.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0208855 accuracy: 100.0\n",
      "loss: 0.0462626 accuracy: 98.0\n",
      "loss: 0.0301515 accuracy: 99.0\n",
      "loss: 0.0183915 accuracy: 100.0\n",
      "loss: 0.0512321 accuracy: 97.0\n",
      "loss: 0.00799266 accuracy: 100.0\n",
      "loss: 0.079028 accuracy: 97.0\n",
      "loss: 0.0258933 accuracy: 99.0\n",
      "loss: 0.0159208 accuracy: 100.0\n",
      "loss: 0.0407469 accuracy: 99.0\n",
      "loss: 0.0610343 accuracy: 98.0\n",
      "loss: 0.0370348 accuracy: 98.0\n",
      "loss: 0.0602312 accuracy: 99.0\n",
      "loss: 0.0577037 accuracy: 98.0\n",
      "loss: 0.0381317 accuracy: 99.0\n",
      "loss: 0.058486 accuracy: 97.0\n",
      "loss: 0.0191375 accuracy: 99.0\n",
      "loss: 0.00912199 accuracy: 100.0\n",
      "loss: 0.0164211 accuracy: 100.0\n",
      "loss: 0.0835584 accuracy: 98.0\n",
      "loss: 0.0354808 accuracy: 99.0\n",
      "loss: 0.0316825 accuracy: 99.0\n",
      "loss: 0.0335028 accuracy: 98.0\n",
      "loss: 0.0229452 accuracy: 99.0\n",
      "loss: 0.0913334 accuracy: 97.0\n",
      "loss: 0.0497236 accuracy: 99.0\n",
      "loss: 0.02925 accuracy: 99.0\n",
      "loss: 0.0285159 accuracy: 99.0\n",
      "loss: 0.0146678 accuracy: 100.0\n",
      "loss: 0.0313444 accuracy: 99.0\n",
      "loss: 0.0125249 accuracy: 100.0\n",
      "loss: 0.0841941 accuracy: 99.0\n",
      "loss: 0.0573205 accuracy: 99.0\n",
      "loss: 0.0171742 accuracy: 99.0\n",
      "loss: 0.023063 accuracy: 100.0\n",
      "loss: 0.132873 accuracy: 98.0\n",
      "loss: 0.0403101 accuracy: 98.0\n",
      "loss: 0.0251981 accuracy: 99.0\n",
      "loss: 0.0287498 accuracy: 99.0\n",
      "loss: 0.0330682 accuracy: 100.0\n",
      "loss: 0.0256398 accuracy: 99.0\n",
      "loss: 0.0125314 accuracy: 100.0\n",
      "loss: 0.0198119 accuracy: 99.0\n",
      "loss: 0.0675766 accuracy: 98.0\n",
      "loss: 0.117334 accuracy: 96.0\n",
      "loss: 0.0274517 accuracy: 99.0\n",
      "loss: 0.0182663 accuracy: 100.0\n",
      "loss: 0.0748564 accuracy: 99.0\n",
      "loss: 0.0492907 accuracy: 98.0\n",
      "loss: 0.0171826 accuracy: 100.0\n",
      "loss: 0.0183981 accuracy: 100.0\n",
      "loss: 0.0535984 accuracy: 99.0\n",
      "loss: 0.121775 accuracy: 96.0\n",
      "loss: 0.130115 accuracy: 97.0\n",
      "loss: 0.0441415 accuracy: 97.0\n",
      "loss: 0.0658454 accuracy: 98.0\n",
      "loss: 0.0646934 accuracy: 96.0\n",
      "loss: 0.0258915 accuracy: 99.0\n",
      "loss: 0.0912311 accuracy: 96.0\n",
      "loss: 0.0521928 accuracy: 99.0\n",
      "loss: 0.158824 accuracy: 96.0\n",
      "loss: 0.053895 accuracy: 98.0\n",
      "loss: 0.00682465 accuracy: 100.0\n",
      "loss: 0.0991363 accuracy: 97.0\n",
      "loss: 0.0783766 accuracy: 96.0\n",
      "loss: 0.031314 accuracy: 99.0\n",
      "loss: 0.0218558 accuracy: 99.0\n",
      "loss: 0.0148065 accuracy: 100.0\n",
      "loss: 0.0481433 accuracy: 99.0\n",
      "loss: 0.0347647 accuracy: 99.0\n",
      "loss: 0.108946 accuracy: 95.0\n",
      "loss: 0.0841984 accuracy: 97.0\n",
      "loss: 0.0134921 accuracy: 100.0\n",
      "loss: 0.0340441 accuracy: 100.0\n",
      "loss: 0.03789 accuracy: 98.0\n",
      "loss: 0.0285514 accuracy: 100.0\n",
      "loss: 0.0873582 accuracy: 95.0\n",
      "loss: 0.0230414 accuracy: 100.0\n",
      "loss: 0.0416174 accuracy: 98.0\n",
      "loss: 0.0158198 accuracy: 100.0\n",
      "loss: 0.0254528 accuracy: 99.0\n",
      "loss: 0.0291509 accuracy: 100.0\n",
      "loss: 0.0538422 accuracy: 98.0\n",
      "loss: 0.0346277 accuracy: 99.0\n",
      "loss: 0.029042 accuracy: 98.0\n",
      "loss: 0.061598 accuracy: 96.0\n",
      "loss: 0.0558881 accuracy: 98.0\n",
      "loss: 0.0728463 accuracy: 99.0\n",
      "loss: 0.0433116 accuracy: 99.0\n",
      "loss: 0.0249943 accuracy: 100.0\n",
      "loss: 0.00675566 accuracy: 100.0\n",
      "loss: 0.0481243 accuracy: 97.0\n",
      "loss: 0.0283476 accuracy: 99.0\n",
      "loss: 0.0417947 accuracy: 99.0\n",
      "loss: 0.0644185 accuracy: 99.0\n",
      "loss: 0.0206414 accuracy: 99.0\n",
      "loss: 0.0462988 accuracy: 98.0\n",
      "loss: 0.0419373 accuracy: 98.0\n",
      "loss: 0.00635654 accuracy: 100.0\n",
      "loss: 0.0262511 accuracy: 99.0\n",
      "loss: 0.024653 accuracy: 100.0\n",
      "loss: 0.105351 accuracy: 97.0\n",
      "loss: 0.0424468 accuracy: 98.0\n",
      "loss: 0.00815539 accuracy: 100.0\n",
      "loss: 0.00699912 accuracy: 100.0\n",
      "loss: 0.0107813 accuracy: 100.0\n",
      "loss: 0.0141801 accuracy: 100.0\n",
      "loss: 0.015231 accuracy: 100.0\n",
      "loss: 0.0191182 accuracy: 100.0\n",
      "loss: 0.0926423 accuracy: 98.0\n",
      "loss: 0.0418329 accuracy: 99.0\n",
      "loss: 0.0739833 accuracy: 98.0\n",
      "loss: 0.0880562 accuracy: 97.0\n",
      "loss: 0.0160061 accuracy: 99.0\n",
      "loss: 0.0330717 accuracy: 99.0\n",
      "loss: 0.0344659 accuracy: 99.0\n",
      "loss: 0.109603 accuracy: 97.0\n",
      "loss: 0.0173168 accuracy: 100.0\n",
      "loss: 0.108086 accuracy: 96.0\n",
      "loss: 0.0651277 accuracy: 97.0\n",
      "loss: 0.0161975 accuracy: 100.0\n",
      "loss: 0.0189404 accuracy: 99.0\n",
      "loss: 0.0559962 accuracy: 98.0\n",
      "loss: 0.0763615 accuracy: 97.0\n",
      "loss: 0.00965637 accuracy: 100.0\n",
      "loss: 0.040707 accuracy: 97.0\n",
      "loss: 0.025808 accuracy: 99.0\n",
      "loss: 0.0548277 accuracy: 99.0\n",
      "loss: 0.0958626 accuracy: 97.0\n",
      "loss: 0.0664199 accuracy: 99.0\n",
      "loss: 0.0931384 accuracy: 98.0\n",
      "loss: 0.0359675 accuracy: 99.0\n",
      "loss: 0.0458767 accuracy: 99.0\n",
      "loss: 0.0553751 accuracy: 98.0\n",
      "loss: 0.0171334 accuracy: 100.0\n",
      "loss: 0.0303584 accuracy: 99.0\n",
      "loss: 0.050321 accuracy: 97.0\n",
      "loss: 0.00949821 accuracy: 100.0\n",
      "loss: 0.0819667 accuracy: 97.0\n",
      "loss: 0.0374747 accuracy: 99.0\n",
      "loss: 0.0521536 accuracy: 98.0\n",
      "loss: 0.141259 accuracy: 96.0\n",
      "loss: 0.0098709 accuracy: 100.0\n",
      "loss: 0.0336136 accuracy: 98.0\n",
      "loss: 0.0330971 accuracy: 100.0\n",
      "loss: 0.120146 accuracy: 98.0\n",
      "loss: 0.0129686 accuracy: 100.0\n",
      "loss: 0.0194194 accuracy: 100.0\n",
      "loss: 0.0371138 accuracy: 99.0\n",
      "loss: 0.00415068 accuracy: 100.0\n",
      "loss: 0.0649274 accuracy: 98.0\n",
      "loss: 0.0433677 accuracy: 99.0\n",
      "loss: 0.0427719 accuracy: 98.0\n",
      "loss: 0.116384 accuracy: 98.0\n",
      "loss: 0.0126075 accuracy: 100.0\n",
      "loss: 0.0506033 accuracy: 99.0\n",
      "loss: 0.00627609 accuracy: 100.0\n",
      "loss: 0.0352897 accuracy: 99.0\n",
      "loss: 0.0161283 accuracy: 100.0\n",
      "loss: 0.0972208 accuracy: 97.0\n",
      "loss: 0.0299264 accuracy: 99.0\n",
      "loss: 0.0126354 accuracy: 100.0\n",
      "loss: 0.0553114 accuracy: 95.0\n",
      "loss: 0.047598 accuracy: 98.0\n",
      "loss: 0.0618088 accuracy: 96.0\n",
      "loss: 0.0599043 accuracy: 98.0\n",
      "loss: 0.00868492 accuracy: 100.0\n",
      "loss: 0.0195352 accuracy: 100.0\n",
      "loss: 0.0755976 accuracy: 97.0\n",
      "loss: 0.0142537 accuracy: 100.0\n",
      "loss: 0.0641756 accuracy: 98.0\n",
      "loss: 0.0407418 accuracy: 97.0\n",
      "loss: 0.0226836 accuracy: 99.0\n",
      "loss: 0.0548008 accuracy: 98.0\n",
      "loss: 0.137128 accuracy: 97.0\n",
      "loss: 0.0707367 accuracy: 98.0\n",
      "loss: 0.0228632 accuracy: 100.0\n",
      "loss: 0.0713437 accuracy: 97.0\n",
      "loss: 0.0212535 accuracy: 99.0\n",
      "loss: 0.0181844 accuracy: 100.0\n",
      "loss: 0.0178469 accuracy: 100.0\n",
      "loss: 0.0303112 accuracy: 99.0\n",
      "loss: 0.0409891 accuracy: 98.0\n",
      "loss: 0.0471195 accuracy: 98.0\n",
      "loss: 0.0276523 accuracy: 99.0\n",
      "loss: 0.00726571 accuracy: 100.0\n",
      "loss: 0.0348795 accuracy: 99.0\n",
      "loss: 0.00760141 accuracy: 100.0\n",
      "loss: 0.00984218 accuracy: 100.0\n",
      "loss: 0.0193971 accuracy: 100.0\n",
      "loss: 0.0300779 accuracy: 99.0\n",
      "loss: 0.0322588 accuracy: 99.0\n",
      "loss: 0.0256812 accuracy: 98.0\n",
      "loss: 0.0517824 accuracy: 97.0\n",
      "loss: 0.0507543 accuracy: 99.0\n",
      "loss: 0.0401048 accuracy: 98.0\n",
      "loss: 0.0406938 accuracy: 98.0\n",
      "loss: 0.0273262 accuracy: 99.0\n",
      "loss: 0.0443842 accuracy: 98.0\n",
      "loss: 0.0401267 accuracy: 99.0\n",
      "loss: 0.0392816 accuracy: 98.0\n",
      "loss: 0.00965056 accuracy: 100.0\n",
      "loss: 0.0337964 accuracy: 98.0\n",
      "loss: 0.0123752 accuracy: 100.0\n",
      "loss: 0.0186679 accuracy: 100.0\n",
      "loss: 0.0683415 accuracy: 99.0\n",
      "loss: 0.0313338 accuracy: 99.0\n",
      "loss: 0.0442732 accuracy: 98.0\n",
      "loss: 0.0359477 accuracy: 99.0\n",
      "loss: 0.127831 accuracy: 95.0\n",
      "loss: 0.0572848 accuracy: 99.0\n",
      "loss: 0.0274722 accuracy: 99.0\n",
      "loss: 0.0216656 accuracy: 100.0\n",
      "loss: 0.020221 accuracy: 99.0\n",
      "loss: 0.0287647 accuracy: 99.0\n",
      "loss: 0.0167314 accuracy: 100.0\n",
      "loss: 0.0702461 accuracy: 99.0\n",
      "loss: 0.0530501 accuracy: 97.0\n",
      "loss: 0.0593401 accuracy: 99.0\n",
      "loss: 0.0233881 accuracy: 99.0\n",
      "loss: 0.024975 accuracy: 99.0\n",
      "loss: 0.102164 accuracy: 97.0\n",
      "loss: 0.039341 accuracy: 97.0\n",
      "loss: 0.0711719 accuracy: 98.0\n",
      "loss: 0.0285297 accuracy: 99.0\n",
      "loss: 0.0739783 accuracy: 99.0\n",
      "loss: 0.0796318 accuracy: 98.0\n",
      "loss: 0.156439 accuracy: 95.0\n",
      "loss: 0.057178 accuracy: 98.0\n",
      "loss: 0.0644995 accuracy: 98.0\n",
      "loss: 0.0224214 accuracy: 99.0\n",
      "loss: 0.0575732 accuracy: 97.0\n",
      "loss: 0.0263424 accuracy: 100.0\n",
      "loss: 0.0519183 accuracy: 99.0\n",
      "loss: 0.0145369 accuracy: 100.0\n",
      "loss: 0.0524681 accuracy: 98.0\n",
      "loss: 0.0642011 accuracy: 96.0\n",
      "loss: 0.055155 accuracy: 99.0\n",
      "loss: 0.114996 accuracy: 95.0\n",
      "loss: 0.0429956 accuracy: 99.0\n",
      "loss: 0.0304385 accuracy: 98.0\n",
      "loss: 0.061378 accuracy: 99.0\n",
      "loss: 0.0211161 accuracy: 100.0\n",
      "loss: 0.0134598 accuracy: 100.0\n",
      "loss: 0.0574939 accuracy: 97.0\n",
      "loss: 0.042187 accuracy: 99.0\n",
      "loss: 0.0141149 accuracy: 100.0\n",
      "loss: 0.0499671 accuracy: 98.0\n",
      "loss: 0.0267337 accuracy: 99.0\n",
      "loss: 0.0674398 accuracy: 97.0\n",
      "loss: 0.055641 accuracy: 97.0\n",
      "loss: 0.0970556 accuracy: 99.0\n",
      "loss: 0.0101958 accuracy: 100.0\n",
      "loss: 0.0680381 accuracy: 96.0\n",
      "loss: 0.0443786 accuracy: 98.0\n",
      "loss: 0.015402 accuracy: 100.0\n",
      "loss: 0.0709502 accuracy: 99.0\n",
      "loss: 0.0258301 accuracy: 100.0\n",
      "loss: 0.0237492 accuracy: 100.0\n",
      "loss: 0.0258897 accuracy: 99.0\n",
      "loss: 0.058109 accuracy: 98.0\n",
      "loss: 0.145409 accuracy: 97.0\n",
      "loss: 0.0356547 accuracy: 98.0\n",
      "loss: 0.0187662 accuracy: 100.0\n",
      "loss: 0.0610534 accuracy: 99.0\n",
      "loss: 0.0905565 accuracy: 97.0\n",
      "loss: 0.0515898 accuracy: 98.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>> test dataset accuracy: 97.6\n",
      "loss: 0.0207987 accuracy: 99.0\n",
      "loss: 0.0181425 accuracy: 100.0\n",
      "loss: 0.0176418 accuracy: 99.0\n",
      "loss: 0.037982 accuracy: 99.0\n",
      "loss: 0.0937528 accuracy: 96.0\n",
      "loss: 0.0204545 accuracy: 100.0\n",
      "loss: 0.0467677 accuracy: 99.0\n",
      "loss: 0.00558318 accuracy: 100.0\n",
      "loss: 0.0136868 accuracy: 100.0\n",
      "loss: 0.0129056 accuracy: 100.0\n",
      "loss: 0.0181282 accuracy: 100.0\n",
      "loss: 0.0113286 accuracy: 100.0\n",
      "loss: 0.0316531 accuracy: 99.0\n",
      "loss: 0.033317 accuracy: 98.0\n",
      "loss: 0.0446761 accuracy: 98.0\n",
      "loss: 0.100612 accuracy: 98.0\n",
      "loss: 0.0646782 accuracy: 98.0\n",
      "loss: 0.0266673 accuracy: 99.0\n",
      "loss: 0.0129385 accuracy: 100.0\n",
      "loss: 0.00535673 accuracy: 100.0\n",
      "loss: 0.0928505 accuracy: 99.0\n",
      "loss: 0.07861 accuracy: 98.0\n",
      "loss: 0.0331 accuracy: 99.0\n",
      "loss: 0.0133942 accuracy: 100.0\n",
      "loss: 0.0523016 accuracy: 99.0\n",
      "loss: 0.0050375 accuracy: 100.0\n",
      "loss: 0.00958876 accuracy: 100.0\n",
      "loss: 0.0233976 accuracy: 100.0\n",
      "loss: 0.0677529 accuracy: 98.0\n",
      "loss: 0.0607205 accuracy: 98.0\n",
      "loss: 0.0111545 accuracy: 100.0\n",
      "loss: 0.0105931 accuracy: 100.0\n",
      "loss: 0.0139621 accuracy: 100.0\n",
      "loss: 0.00781831 accuracy: 100.0\n",
      "loss: 0.00458681 accuracy: 100.0\n",
      "loss: 0.00523763 accuracy: 100.0\n",
      "loss: 0.162071 accuracy: 98.0\n",
      "loss: 0.018685 accuracy: 100.0\n",
      "loss: 0.0228399 accuracy: 99.0\n",
      "loss: 0.029602 accuracy: 99.0\n",
      "loss: 0.0100989 accuracy: 100.0\n",
      "loss: 0.0116995 accuracy: 100.0\n",
      "loss: 0.0199359 accuracy: 99.0\n",
      "loss: 0.0147941 accuracy: 100.0\n",
      "loss: 0.125792 accuracy: 96.0\n",
      "loss: 0.0391802 accuracy: 98.0\n",
      "loss: 0.0706111 accuracy: 98.0\n",
      "loss: 0.0262584 accuracy: 99.0\n",
      "loss: 0.0646318 accuracy: 98.0\n",
      "loss: 0.0174894 accuracy: 99.0\n",
      "loss: 0.0275943 accuracy: 99.0\n",
      "loss: 0.0741803 accuracy: 98.0\n",
      "loss: 0.024466 accuracy: 99.0\n",
      "loss: 0.029338 accuracy: 99.0\n",
      "loss: 0.0344423 accuracy: 99.0\n",
      "loss: 0.0148174 accuracy: 100.0\n",
      "loss: 0.0305901 accuracy: 99.0\n",
      "loss: 0.0246392 accuracy: 99.0\n",
      "loss: 0.0115449 accuracy: 100.0\n",
      "loss: 0.0130936 accuracy: 100.0\n",
      "loss: 0.118765 accuracy: 98.0\n",
      "loss: 0.00517508 accuracy: 100.0\n",
      "loss: 0.0213453 accuracy: 99.0\n",
      "loss: 0.0291645 accuracy: 100.0\n",
      "loss: 0.0277007 accuracy: 100.0\n",
      "loss: 0.0122245 accuracy: 100.0\n",
      "loss: 0.0341496 accuracy: 98.0\n",
      "loss: 0.0161197 accuracy: 100.0\n",
      "loss: 0.0132644 accuracy: 100.0\n",
      "loss: 0.0300359 accuracy: 99.0\n",
      "loss: 0.0241744 accuracy: 99.0\n",
      "loss: 0.0252002 accuracy: 98.0\n",
      "loss: 0.0145628 accuracy: 99.0\n",
      "loss: 0.00878632 accuracy: 100.0\n",
      "loss: 0.0177235 accuracy: 99.0\n",
      "loss: 0.0215023 accuracy: 100.0\n",
      "loss: 0.0051166 accuracy: 100.0\n",
      "loss: 0.0386447 accuracy: 99.0\n",
      "loss: 0.0244431 accuracy: 99.0\n",
      "loss: 0.109661 accuracy: 98.0\n",
      "loss: 0.0278737 accuracy: 99.0\n",
      "loss: 0.0526938 accuracy: 98.0\n",
      "loss: 0.0269726 accuracy: 99.0\n",
      "loss: 0.0328559 accuracy: 99.0\n",
      "loss: 0.0105345 accuracy: 100.0\n",
      "loss: 0.00915351 accuracy: 100.0\n",
      "loss: 0.0473936 accuracy: 98.0\n",
      "loss: 0.0184028 accuracy: 100.0\n",
      "loss: 0.00986143 accuracy: 100.0\n",
      "loss: 0.0424985 accuracy: 99.0\n",
      "loss: 0.0462176 accuracy: 99.0\n",
      "loss: 0.00224932 accuracy: 100.0\n",
      "loss: 0.00612827 accuracy: 100.0\n",
      "loss: 0.0480486 accuracy: 99.0\n",
      "loss: 0.0266839 accuracy: 99.0\n",
      "loss: 0.0495046 accuracy: 99.0\n",
      "loss: 0.0207585 accuracy: 100.0\n",
      "loss: 0.0292408 accuracy: 98.0\n",
      "loss: 0.0246596 accuracy: 100.0\n",
      "loss: 0.0142441 accuracy: 100.0\n",
      "loss: 0.00458867 accuracy: 100.0\n",
      "loss: 0.0108254 accuracy: 100.0\n",
      "loss: 0.0283243 accuracy: 99.0\n",
      "loss: 0.0107548 accuracy: 100.0\n",
      "loss: 0.00835063 accuracy: 100.0\n",
      "loss: 0.00320631 accuracy: 100.0\n",
      "loss: 0.00780265 accuracy: 100.0\n",
      "loss: 0.0225072 accuracy: 100.0\n",
      "loss: 0.0107696 accuracy: 100.0\n",
      "loss: 0.0149347 accuracy: 100.0\n",
      "loss: 0.0243242 accuracy: 98.0\n",
      "loss: 0.00608968 accuracy: 100.0\n",
      "loss: 0.133787 accuracy: 97.0\n",
      "loss: 0.0329108 accuracy: 98.0\n",
      "loss: 0.0450609 accuracy: 99.0\n",
      "loss: 0.00707199 accuracy: 100.0\n",
      "loss: 0.0236478 accuracy: 99.0\n",
      "loss: 0.0485902 accuracy: 99.0\n",
      "loss: 0.0633434 accuracy: 98.0\n",
      "loss: 0.0388833 accuracy: 98.0\n",
      "loss: 0.00403318 accuracy: 100.0\n",
      "loss: 0.0119943 accuracy: 100.0\n",
      "loss: 0.0182197 accuracy: 100.0\n",
      "loss: 0.0431417 accuracy: 98.0\n",
      "loss: 0.012468 accuracy: 100.0\n",
      "loss: 0.0335467 accuracy: 99.0\n",
      "loss: 0.0058902 accuracy: 100.0\n",
      "loss: 0.0678637 accuracy: 97.0\n",
      "loss: 0.0932273 accuracy: 95.0\n",
      "loss: 0.0104806 accuracy: 100.0\n",
      "loss: 0.010116 accuracy: 100.0\n",
      "loss: 0.0192722 accuracy: 100.0\n",
      "loss: 0.00695411 accuracy: 100.0\n",
      "loss: 0.0164316 accuracy: 100.0\n",
      "loss: 0.00408244 accuracy: 100.0\n",
      "loss: 0.00927001 accuracy: 100.0\n",
      "loss: 0.0444036 accuracy: 99.0\n",
      "loss: 0.0251292 accuracy: 99.0\n",
      "loss: 0.0162767 accuracy: 99.0\n",
      "loss: 0.0359455 accuracy: 99.0\n",
      "loss: 0.0134957 accuracy: 99.0\n",
      "loss: 0.0344809 accuracy: 99.0\n",
      "loss: 0.0269658 accuracy: 99.0\n",
      "loss: 0.0104513 accuracy: 100.0\n",
      "loss: 0.00207159 accuracy: 100.0\n",
      "loss: 0.00619268 accuracy: 100.0\n",
      "loss: 0.00463848 accuracy: 100.0\n",
      "loss: 0.00739712 accuracy: 100.0\n",
      "loss: 0.0299292 accuracy: 99.0\n",
      "loss: 0.0179 accuracy: 100.0\n",
      "loss: 0.00680816 accuracy: 100.0\n",
      "loss: 0.0123084 accuracy: 100.0\n",
      "loss: 0.0217876 accuracy: 100.0\n",
      "loss: 0.0116411 accuracy: 100.0\n",
      "loss: 0.0294975 accuracy: 98.0\n",
      "loss: 0.0410629 accuracy: 99.0\n",
      "loss: 0.00900803 accuracy: 100.0\n",
      "loss: 0.0514497 accuracy: 99.0\n",
      "loss: 0.0273982 accuracy: 99.0\n",
      "loss: 0.0227159 accuracy: 100.0\n",
      "loss: 0.0122951 accuracy: 100.0\n",
      "loss: 0.0364812 accuracy: 99.0\n",
      "loss: 0.0267982 accuracy: 99.0\n",
      "loss: 0.0175264 accuracy: 99.0\n",
      "loss: 0.0162561 accuracy: 99.0\n",
      "loss: 0.0275229 accuracy: 99.0\n",
      "loss: 0.0249326 accuracy: 99.0\n",
      "loss: 0.0093618 accuracy: 100.0\n",
      "loss: 0.00417042 accuracy: 100.0\n",
      "loss: 0.0943184 accuracy: 96.0\n",
      "loss: 0.0321713 accuracy: 99.0\n",
      "loss: 0.0193034 accuracy: 99.0\n",
      "loss: 0.02948 accuracy: 99.0\n",
      "loss: 0.00890568 accuracy: 100.0\n",
      "loss: 0.0397344 accuracy: 99.0\n",
      "loss: 0.0205203 accuracy: 100.0\n",
      "loss: 0.0277067 accuracy: 99.0\n",
      "loss: 0.0111614 accuracy: 100.0\n",
      "loss: 0.00593564 accuracy: 100.0\n",
      "loss: 0.0205756 accuracy: 99.0\n",
      "loss: 0.088888 accuracy: 97.0\n",
      "loss: 0.0082385 accuracy: 100.0\n",
      "loss: 0.00497948 accuracy: 100.0\n",
      "loss: 0.00903101 accuracy: 100.0\n",
      "loss: 0.00670882 accuracy: 100.0\n",
      "loss: 0.0219514 accuracy: 99.0\n",
      "loss: 0.0684809 accuracy: 98.0\n",
      "loss: 0.0442721 accuracy: 99.0\n",
      "loss: 0.0119631 accuracy: 100.0\n",
      "loss: 0.0118655 accuracy: 100.0\n",
      "loss: 0.0103132 accuracy: 100.0\n",
      "loss: 0.00677617 accuracy: 100.0\n",
      "loss: 0.0115792 accuracy: 100.0\n",
      "loss: 0.00614061 accuracy: 100.0\n",
      "loss: 0.0208596 accuracy: 99.0\n",
      "loss: 0.0405032 accuracy: 98.0\n",
      "loss: 0.00996639 accuracy: 100.0\n",
      "loss: 0.0360925 accuracy: 99.0\n",
      "loss: 0.0107658 accuracy: 100.0\n",
      "loss: 0.0357121 accuracy: 99.0\n",
      "loss: 0.00688551 accuracy: 100.0\n",
      "loss: 0.0127781 accuracy: 100.0\n",
      "loss: 0.014085 accuracy: 100.0\n",
      "loss: 0.0070937 accuracy: 100.0\n",
      "loss: 0.0462966 accuracy: 98.0\n",
      "loss: 0.0368742 accuracy: 99.0\n",
      "loss: 0.034589 accuracy: 99.0\n",
      "loss: 0.0427049 accuracy: 98.0\n",
      "loss: 0.0201425 accuracy: 100.0\n",
      "loss: 0.00647785 accuracy: 100.0\n",
      "loss: 0.0182934 accuracy: 100.0\n",
      "loss: 0.0182416 accuracy: 99.0\n",
      "loss: 0.0181454 accuracy: 100.0\n",
      "loss: 0.0153653 accuracy: 100.0\n",
      "loss: 0.0354619 accuracy: 98.0\n",
      "loss: 0.0121837 accuracy: 100.0\n",
      "loss: 0.0117001 accuracy: 100.0\n",
      "loss: 0.0174572 accuracy: 100.0\n",
      "loss: 0.0134768 accuracy: 100.0\n",
      "loss: 0.00472987 accuracy: 100.0\n",
      "loss: 0.0330697 accuracy: 99.0\n",
      "loss: 0.0843622 accuracy: 97.0\n",
      "loss: 0.0235518 accuracy: 99.0\n",
      "loss: 0.0116123 accuracy: 100.0\n",
      "loss: 0.0581877 accuracy: 97.0\n",
      "loss: 0.0187217 accuracy: 99.0\n",
      "loss: 0.0195702 accuracy: 100.0\n",
      "loss: 0.0782955 accuracy: 98.0\n",
      "loss: 0.0411456 accuracy: 98.0\n",
      "loss: 0.0469147 accuracy: 98.0\n",
      "loss: 0.0191617 accuracy: 99.0\n",
      "loss: 0.0300506 accuracy: 98.0\n",
      "loss: 0.0396353 accuracy: 98.0\n",
      "loss: 0.0372167 accuracy: 98.0\n",
      "loss: 0.049251 accuracy: 98.0\n",
      "loss: 0.00500093 accuracy: 100.0\n",
      "loss: 0.0109561 accuracy: 100.0\n",
      "loss: 0.0143233 accuracy: 100.0\n",
      "loss: 0.023033 accuracy: 100.0\n",
      "loss: 0.0131312 accuracy: 100.0\n",
      "loss: 0.0615557 accuracy: 99.0\n",
      "loss: 0.0128382 accuracy: 100.0\n",
      "loss: 0.0169376 accuracy: 100.0\n",
      "loss: 0.00513456 accuracy: 100.0\n",
      "loss: 0.0158144 accuracy: 99.0\n",
      "loss: 0.00488535 accuracy: 100.0\n",
      "loss: 0.0040968 accuracy: 100.0\n",
      "loss: 0.0140485 accuracy: 100.0\n",
      "loss: 0.00935099 accuracy: 100.0\n",
      "loss: 0.0274189 accuracy: 99.0\n",
      "loss: 0.00541141 accuracy: 100.0\n",
      "loss: 0.0166131 accuracy: 99.0\n",
      "loss: 0.0407233 accuracy: 98.0\n",
      "loss: 0.0249626 accuracy: 100.0\n",
      "loss: 0.0107146 accuracy: 100.0\n",
      "loss: 0.0172477 accuracy: 100.0\n",
      "loss: 0.0237643 accuracy: 99.0\n",
      "loss: 0.0144871 accuracy: 100.0\n",
      "loss: 0.0106285 accuracy: 99.0\n",
      "loss: 0.0229859 accuracy: 99.0\n",
      "loss: 0.0274555 accuracy: 100.0\n",
      "loss: 0.0494601 accuracy: 99.0\n",
      "loss: 0.0196627 accuracy: 100.0\n",
      "loss: 0.00642156 accuracy: 100.0\n",
      "loss: 0.0134481 accuracy: 100.0\n",
      "loss: 0.00819945 accuracy: 100.0\n",
      "loss: 0.0171909 accuracy: 100.0\n",
      "loss: 0.00626261 accuracy: 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0310578 accuracy: 100.0\n",
      "loss: 0.0422085 accuracy: 99.0\n",
      "loss: 0.0897078 accuracy: 97.0\n",
      "loss: 0.0443596 accuracy: 98.0\n",
      "loss: 0.00852693 accuracy: 100.0\n",
      "loss: 0.0464146 accuracy: 98.0\n",
      "loss: 0.00487513 accuracy: 100.0\n",
      "loss: 0.0165343 accuracy: 100.0\n",
      "loss: 0.0119245 accuracy: 100.0\n",
      "loss: 0.0174128 accuracy: 100.0\n",
      "loss: 0.0637446 accuracy: 99.0\n",
      "loss: 0.0426169 accuracy: 97.0\n",
      "loss: 0.0108187 accuracy: 100.0\n",
      "loss: 0.0336664 accuracy: 98.0\n",
      "loss: 0.0260884 accuracy: 100.0\n",
      "loss: 0.0145019 accuracy: 100.0\n",
      "loss: 0.0344303 accuracy: 98.0\n",
      "loss: 0.0209979 accuracy: 99.0\n",
      "loss: 0.0337885 accuracy: 99.0\n",
      "loss: 0.0194348 accuracy: 99.0\n",
      "loss: 0.0189358 accuracy: 100.0\n",
      "loss: 0.0135553 accuracy: 99.0\n",
      "loss: 0.0388023 accuracy: 99.0\n",
      "loss: 0.0435853 accuracy: 99.0\n",
      "loss: 0.0171645 accuracy: 100.0\n",
      "loss: 0.111842 accuracy: 98.0\n",
      "loss: 0.0160852 accuracy: 100.0\n",
      "loss: 0.011479 accuracy: 100.0\n",
      "loss: 0.0123678 accuracy: 100.0\n",
      "loss: 0.0343685 accuracy: 99.0\n",
      "loss: 0.0309543 accuracy: 99.0\n",
      "loss: 0.0173251 accuracy: 100.0\n",
      "loss: 0.0101428 accuracy: 100.0\n",
      "loss: 0.058759 accuracy: 98.0\n",
      "loss: 0.0810904 accuracy: 98.0\n",
      "loss: 0.0797211 accuracy: 98.0\n",
      "loss: 0.0351445 accuracy: 99.0\n",
      "loss: 0.0241145 accuracy: 100.0\n",
      "loss: 0.0569513 accuracy: 99.0\n",
      "loss: 0.0547479 accuracy: 98.0\n",
      "loss: 0.01635 accuracy: 100.0\n",
      "loss: 0.0249483 accuracy: 99.0\n",
      "loss: 0.0332144 accuracy: 98.0\n",
      "loss: 0.0208818 accuracy: 99.0\n",
      "loss: 0.0368583 accuracy: 98.0\n",
      "loss: 0.0549442 accuracy: 99.0\n",
      "loss: 0.0175065 accuracy: 99.0\n",
      "loss: 0.0146054 accuracy: 99.0\n",
      "loss: 0.0103493 accuracy: 100.0\n",
      "loss: 0.0213982 accuracy: 100.0\n",
      "loss: 0.0154024 accuracy: 100.0\n",
      "loss: 0.0112255 accuracy: 100.0\n",
      "loss: 0.0278046 accuracy: 100.0\n",
      "loss: 0.0390193 accuracy: 98.0\n",
      "loss: 0.028107 accuracy: 99.0\n",
      "loss: 0.0440881 accuracy: 99.0\n",
      "loss: 0.0243082 accuracy: 100.0\n",
      "loss: 0.00894679 accuracy: 100.0\n",
      "loss: 0.0486826 accuracy: 99.0\n",
      "loss: 0.0223797 accuracy: 99.0\n",
      "loss: 0.0138463 accuracy: 100.0\n",
      "loss: 0.00456526 accuracy: 100.0\n",
      "loss: 0.00435326 accuracy: 100.0\n",
      "loss: 0.0258796 accuracy: 99.0\n",
      "loss: 0.00469735 accuracy: 100.0\n",
      "loss: 0.0190174 accuracy: 100.0\n",
      "loss: 0.0267868 accuracy: 99.0\n",
      "loss: 0.0341583 accuracy: 99.0\n",
      "loss: 0.00959772 accuracy: 100.0\n",
      "loss: 0.0772202 accuracy: 97.0\n",
      "loss: 0.0359414 accuracy: 99.0\n",
      "loss: 0.0477511 accuracy: 98.0\n",
      "loss: 0.0187849 accuracy: 99.0\n",
      "loss: 0.0266244 accuracy: 100.0\n",
      "loss: 0.0282328 accuracy: 99.0\n",
      "loss: 0.0501936 accuracy: 98.0\n",
      "loss: 0.0658133 accuracy: 97.0\n",
      "loss: 0.0397634 accuracy: 99.0\n",
      "loss: 0.0484197 accuracy: 98.0\n",
      "loss: 0.0101184 accuracy: 100.0\n",
      "loss: 0.0144063 accuracy: 100.0\n",
      "loss: 0.0129553 accuracy: 99.0\n",
      "loss: 0.0119135 accuracy: 100.0\n",
      "loss: 0.00843284 accuracy: 100.0\n",
      "loss: 0.0186777 accuracy: 100.0\n",
      "loss: 0.0172144 accuracy: 100.0\n",
      "loss: 0.0273304 accuracy: 99.0\n",
      "loss: 0.0571779 accuracy: 98.0\n",
      "loss: 0.0318168 accuracy: 98.0\n",
      "loss: 0.00564923 accuracy: 100.0\n",
      "loss: 0.0193937 accuracy: 99.0\n",
      "loss: 0.0625171 accuracy: 97.0\n",
      "loss: 0.0152437 accuracy: 100.0\n",
      "loss: 0.00511598 accuracy: 100.0\n",
      "loss: 0.0217033 accuracy: 100.0\n",
      "loss: 0.0355376 accuracy: 99.0\n",
      "loss: 0.044756 accuracy: 98.0\n",
      "loss: 0.00929875 accuracy: 100.0\n",
      "loss: 0.0151337 accuracy: 100.0\n",
      "loss: 0.0167003 accuracy: 100.0\n",
      "loss: 0.0230419 accuracy: 100.0\n",
      "loss: 0.0188196 accuracy: 100.0\n",
      "loss: 0.0215468 accuracy: 99.0\n",
      "loss: 0.016918 accuracy: 100.0\n",
      "loss: 0.0325651 accuracy: 98.0\n",
      "loss: 0.0540089 accuracy: 98.0\n",
      "loss: 0.0366267 accuracy: 99.0\n",
      "loss: 0.0319086 accuracy: 99.0\n",
      "loss: 0.0114026 accuracy: 100.0\n",
      "loss: 0.00677033 accuracy: 100.0\n",
      "loss: 0.0113371 accuracy: 100.0\n",
      "loss: 0.0232075 accuracy: 99.0\n",
      "loss: 0.0168786 accuracy: 100.0\n",
      "loss: 0.0125154 accuracy: 100.0\n",
      "loss: 0.00951397 accuracy: 100.0\n",
      "loss: 0.0130683 accuracy: 99.0\n",
      "loss: 0.00365057 accuracy: 100.0\n",
      "loss: 0.0786259 accuracy: 99.0\n",
      "loss: 0.00443745 accuracy: 100.0\n",
      "loss: 0.0281343 accuracy: 98.0\n",
      "loss: 0.010999 accuracy: 100.0\n",
      "loss: 0.00905989 accuracy: 100.0\n",
      "loss: 0.0247418 accuracy: 100.0\n",
      "loss: 0.000995458 accuracy: 100.0\n",
      "loss: 0.0371071 accuracy: 98.0\n",
      "loss: 0.015893 accuracy: 100.0\n",
      "loss: 0.00950389 accuracy: 100.0\n",
      "loss: 0.0119527 accuracy: 100.0\n",
      "loss: 0.00559519 accuracy: 100.0\n",
      "loss: 0.00449204 accuracy: 100.0\n",
      "loss: 0.0225989 accuracy: 99.0\n",
      "loss: 0.0128247 accuracy: 100.0\n",
      "loss: 0.0148171 accuracy: 100.0\n",
      "loss: 0.0276587 accuracy: 99.0\n",
      "loss: 0.0143992 accuracy: 99.0\n",
      "loss: 0.00582398 accuracy: 100.0\n",
      "loss: 0.0652864 accuracy: 99.0\n",
      "loss: 0.0267021 accuracy: 99.0\n",
      "loss: 0.00879403 accuracy: 100.0\n",
      "loss: 0.0116839 accuracy: 100.0\n",
      "loss: 0.013549 accuracy: 100.0\n",
      "loss: 0.0096521 accuracy: 100.0\n",
      "loss: 0.0215633 accuracy: 99.0\n",
      "loss: 0.025352 accuracy: 99.0\n",
      "loss: 0.0278697 accuracy: 98.0\n",
      "loss: 0.0123227 accuracy: 100.0\n",
      "loss: 0.0768493 accuracy: 99.0\n",
      "loss: 0.0497814 accuracy: 99.0\n",
      "loss: 0.118634 accuracy: 95.0\n",
      "loss: 0.0197849 accuracy: 100.0\n",
      "loss: 0.0356154 accuracy: 98.0\n",
      "loss: 0.040814 accuracy: 99.0\n",
      "loss: 0.00261572 accuracy: 100.0\n",
      "loss: 0.0210115 accuracy: 100.0\n",
      "loss: 0.0315743 accuracy: 98.0\n",
      "loss: 0.0358038 accuracy: 99.0\n",
      "loss: 0.0109354 accuracy: 100.0\n",
      "loss: 0.0138864 accuracy: 100.0\n",
      "loss: 0.0114539 accuracy: 100.0\n",
      "loss: 0.0105466 accuracy: 100.0\n",
      "loss: 0.0227598 accuracy: 99.0\n",
      "loss: 0.00511996 accuracy: 100.0\n",
      "loss: 0.0190126 accuracy: 99.0\n",
      "loss: 0.0292415 accuracy: 99.0\n",
      "loss: 0.0220846 accuracy: 99.0\n",
      "loss: 0.0473231 accuracy: 99.0\n",
      "loss: 0.0257914 accuracy: 99.0\n",
      "loss: 0.00992582 accuracy: 100.0\n",
      "loss: 0.0117395 accuracy: 100.0\n",
      "loss: 0.0549079 accuracy: 99.0\n",
      "loss: 0.0607777 accuracy: 98.0\n",
      "loss: 0.0130816 accuracy: 100.0\n",
      "loss: 0.042727 accuracy: 99.0\n",
      "loss: 0.0126087 accuracy: 100.0\n",
      "loss: 0.0242795 accuracy: 99.0\n",
      "loss: 0.0199204 accuracy: 99.0\n",
      "loss: 0.0142085 accuracy: 100.0\n",
      "loss: 0.0136065 accuracy: 100.0\n",
      "loss: 0.0518125 accuracy: 99.0\n",
      "loss: 0.0729293 accuracy: 96.0\n",
      "loss: 0.0667821 accuracy: 98.0\n",
      "loss: 0.0274108 accuracy: 99.0\n",
      "loss: 0.0130343 accuracy: 100.0\n",
      "loss: 0.00973921 accuracy: 100.0\n",
      "loss: 0.0111153 accuracy: 100.0\n",
      "loss: 0.00624474 accuracy: 100.0\n",
      "loss: 0.0160077 accuracy: 100.0\n",
      "loss: 0.0119137 accuracy: 100.0\n",
      "loss: 0.0134862 accuracy: 100.0\n",
      "loss: 0.0252562 accuracy: 99.0\n",
      "loss: 0.0252867 accuracy: 99.0\n",
      "loss: 0.0114043 accuracy: 100.0\n",
      "loss: 0.0136753 accuracy: 100.0\n",
      "loss: 0.00641791 accuracy: 100.0\n",
      "loss: 0.0063137 accuracy: 100.0\n",
      "loss: 0.0256897 accuracy: 99.0\n",
      "loss: 0.0487465 accuracy: 99.0\n",
      "loss: 0.0101708 accuracy: 100.0\n",
      "loss: 0.00736794 accuracy: 100.0\n",
      "loss: 0.0504674 accuracy: 99.0\n",
      "loss: 0.00675911 accuracy: 100.0\n",
      "loss: 0.0222117 accuracy: 99.0\n",
      "loss: 0.0239215 accuracy: 99.0\n",
      "loss: 0.0181625 accuracy: 100.0\n",
      "loss: 0.0464271 accuracy: 98.0\n",
      "loss: 0.00923021 accuracy: 100.0\n",
      "loss: 0.0128889 accuracy: 100.0\n",
      "loss: 0.0131449 accuracy: 100.0\n",
      "loss: 0.0125159 accuracy: 100.0\n",
      "loss: 0.0233349 accuracy: 99.0\n",
      "loss: 0.0109382 accuracy: 100.0\n",
      "loss: 0.0692669 accuracy: 99.0\n",
      "loss: 0.00750293 accuracy: 100.0\n",
      "loss: 0.0955428 accuracy: 97.0\n",
      "loss: 0.012459 accuracy: 100.0\n",
      "loss: 0.0386095 accuracy: 99.0\n",
      "loss: 0.0252642 accuracy: 99.0\n",
      "loss: 0.0211784 accuracy: 100.0\n",
      "loss: 0.0773776 accuracy: 97.0\n",
      "loss: 0.00737564 accuracy: 100.0\n",
      "loss: 0.106861 accuracy: 99.0\n",
      "loss: 0.0338934 accuracy: 99.0\n",
      "loss: 0.0297498 accuracy: 99.0\n",
      "loss: 0.0311413 accuracy: 99.0\n",
      "loss: 0.0930053 accuracy: 99.0\n",
      "loss: 0.014917 accuracy: 100.0\n",
      "loss: 0.00511085 accuracy: 100.0\n",
      "loss: 0.0168999 accuracy: 100.0\n",
      "loss: 0.0246555 accuracy: 99.0\n",
      "loss: 0.0383887 accuracy: 98.0\n",
      "loss: 0.019252 accuracy: 99.0\n",
      "loss: 0.0152268 accuracy: 100.0\n",
      "loss: 0.0265617 accuracy: 100.0\n",
      "loss: 0.046653 accuracy: 98.0\n",
      "loss: 0.058785 accuracy: 99.0\n",
      "loss: 0.00632281 accuracy: 100.0\n",
      "loss: 0.0158878 accuracy: 99.0\n",
      "loss: 0.028405 accuracy: 98.0\n",
      "loss: 0.00707812 accuracy: 100.0\n",
      "loss: 0.0303721 accuracy: 99.0\n",
      "loss: 0.0173423 accuracy: 100.0\n",
      "loss: 0.014937 accuracy: 100.0\n",
      "loss: 0.00885241 accuracy: 100.0\n",
      "loss: 0.0221157 accuracy: 99.0\n",
      "loss: 0.00677575 accuracy: 100.0\n",
      "loss: 0.0215038 accuracy: 100.0\n",
      "loss: 0.00706081 accuracy: 100.0\n",
      "loss: 0.0224538 accuracy: 99.0\n",
      "loss: 0.0121388 accuracy: 100.0\n",
      "loss: 0.0348056 accuracy: 99.0\n",
      "loss: 0.00687055 accuracy: 100.0\n",
      "loss: 0.0476236 accuracy: 98.0\n",
      "loss: 0.0202713 accuracy: 100.0\n",
      "loss: 0.0450688 accuracy: 99.0\n",
      "loss: 0.0314878 accuracy: 99.0\n",
      "loss: 0.0124447 accuracy: 99.0\n",
      "loss: 0.0218105 accuracy: 99.0\n",
      "loss: 0.0288466 accuracy: 99.0\n",
      "loss: 0.0208073 accuracy: 99.0\n",
      "loss: 0.0284869 accuracy: 99.0\n",
      "loss: 0.0635653 accuracy: 97.0\n",
      "loss: 0.0392506 accuracy: 98.0\n",
      "loss: 0.0373545 accuracy: 98.0\n",
      "loss: 0.0227067 accuracy: 99.0\n",
      "loss: 0.0394329 accuracy: 98.0\n",
      "loss: 0.0099051 accuracy: 100.0\n",
      "loss: 0.105004 accuracy: 98.0\n",
      "loss: 0.0330554 accuracy: 99.0\n",
      "loss: 0.00782118 accuracy: 100.0\n",
      "loss: 0.00865573 accuracy: 100.0\n",
      "loss: 0.00942117 accuracy: 100.0\n",
      "loss: 0.0130786 accuracy: 100.0\n",
      "loss: 0.010715 accuracy: 100.0\n",
      "loss: 0.0144316 accuracy: 100.0\n",
      "loss: 0.00431288 accuracy: 100.0\n",
      "loss: 0.0107537 accuracy: 100.0\n",
      "loss: 0.00703107 accuracy: 100.0\n",
      "loss: 0.00366237 accuracy: 100.0\n",
      "loss: 0.02477 accuracy: 99.0\n",
      "loss: 0.0102773 accuracy: 100.0\n",
      "loss: 0.00962352 accuracy: 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>> test dataset accuracy: 97.84\n",
      "loss: 0.00518359 accuracy: 100.0\n",
      "loss: 0.0219634 accuracy: 99.0\n",
      "loss: 0.00693582 accuracy: 100.0\n",
      "loss: 0.0385814 accuracy: 98.0\n",
      "loss: 0.0340497 accuracy: 99.0\n",
      "loss: 0.0145134 accuracy: 99.0\n",
      "loss: 0.00967724 accuracy: 100.0\n",
      "loss: 0.0070703 accuracy: 100.0\n",
      "loss: 0.0177842 accuracy: 100.0\n",
      "loss: 0.00476375 accuracy: 100.0\n",
      "loss: 0.0419586 accuracy: 99.0\n",
      "loss: 0.0308073 accuracy: 99.0\n",
      "loss: 0.00780801 accuracy: 100.0\n",
      "loss: 0.0334451 accuracy: 99.0\n",
      "loss: 0.0115853 accuracy: 100.0\n",
      "loss: 0.00739073 accuracy: 100.0\n",
      "loss: 0.0176812 accuracy: 99.0\n",
      "loss: 0.0047533 accuracy: 100.0\n",
      "loss: 0.0183107 accuracy: 99.0\n",
      "loss: 0.0214546 accuracy: 98.0\n",
      "loss: 0.00709516 accuracy: 100.0\n",
      "loss: 0.0347252 accuracy: 99.0\n",
      "loss: 0.0106456 accuracy: 100.0\n",
      "loss: 0.0621358 accuracy: 98.0\n",
      "loss: 0.02407 accuracy: 99.0\n",
      "loss: 0.00623869 accuracy: 100.0\n",
      "loss: 0.0175402 accuracy: 99.0\n",
      "loss: 0.0112462 accuracy: 100.0\n",
      "loss: 0.010517 accuracy: 100.0\n",
      "loss: 0.0212816 accuracy: 100.0\n",
      "loss: 0.013387 accuracy: 100.0\n",
      "loss: 0.0563773 accuracy: 99.0\n",
      "loss: 0.0130533 accuracy: 100.0\n",
      "loss: 0.0373732 accuracy: 98.0\n",
      "loss: 0.00817431 accuracy: 100.0\n",
      "loss: 0.013433 accuracy: 100.0\n",
      "loss: 0.0110046 accuracy: 100.0\n",
      "loss: 0.0159183 accuracy: 100.0\n",
      "loss: 0.00487482 accuracy: 100.0\n",
      "loss: 0.00608504 accuracy: 100.0\n",
      "loss: 0.00477242 accuracy: 100.0\n",
      "loss: 0.0038677 accuracy: 100.0\n",
      "loss: 0.00348633 accuracy: 100.0\n",
      "loss: 0.00346134 accuracy: 100.0\n",
      "loss: 0.00266137 accuracy: 100.0\n",
      "loss: 0.00904609 accuracy: 99.0\n",
      "loss: 0.00600657 accuracy: 100.0\n",
      "loss: 0.0199394 accuracy: 99.0\n",
      "loss: 0.0174075 accuracy: 100.0\n",
      "loss: 0.0101546 accuracy: 100.0\n",
      "loss: 0.00192425 accuracy: 100.0\n",
      "loss: 0.0605147 accuracy: 99.0\n",
      "loss: 0.0157078 accuracy: 99.0\n",
      "loss: 0.0284207 accuracy: 99.0\n",
      "loss: 0.0160566 accuracy: 100.0\n",
      "loss: 0.0136854 accuracy: 100.0\n",
      "loss: 0.0452065 accuracy: 99.0\n",
      "loss: 0.00516939 accuracy: 100.0\n",
      "loss: 0.0063086 accuracy: 100.0\n",
      "loss: 0.0103913 accuracy: 100.0\n",
      "loss: 0.0109083 accuracy: 100.0\n",
      "loss: 0.00962517 accuracy: 100.0\n",
      "loss: 0.0161509 accuracy: 100.0\n",
      "loss: 0.0252213 accuracy: 99.0\n",
      "loss: 0.00984492 accuracy: 100.0\n",
      "loss: 0.0488315 accuracy: 99.0\n",
      "loss: 0.0412438 accuracy: 99.0\n",
      "loss: 0.0265261 accuracy: 99.0\n",
      "loss: 0.0155258 accuracy: 100.0\n",
      "loss: 0.00974472 accuracy: 100.0\n",
      "loss: 0.00923648 accuracy: 100.0\n",
      "loss: 0.00566262 accuracy: 100.0\n",
      "loss: 0.0200027 accuracy: 100.0\n",
      "loss: 0.00754767 accuracy: 100.0\n",
      "loss: 0.0154821 accuracy: 99.0\n",
      "loss: 0.0104474 accuracy: 100.0\n",
      "loss: 0.00249211 accuracy: 100.0\n",
      "loss: 0.00608949 accuracy: 100.0\n",
      "loss: 0.00954758 accuracy: 100.0\n",
      "loss: 0.0270463 accuracy: 99.0\n",
      "loss: 0.00441626 accuracy: 100.0\n",
      "loss: 0.00312513 accuracy: 100.0\n",
      "loss: 0.00541211 accuracy: 100.0\n",
      "loss: 0.00407286 accuracy: 100.0\n",
      "loss: 0.0169583 accuracy: 99.0\n",
      "loss: 0.00764743 accuracy: 100.0\n",
      "loss: 0.0185962 accuracy: 99.0\n",
      "loss: 0.0385777 accuracy: 99.0\n",
      "loss: 0.0103413 accuracy: 100.0\n",
      "loss: 0.0204925 accuracy: 100.0\n",
      "loss: 0.0539488 accuracy: 99.0\n",
      "loss: 0.00161189 accuracy: 100.0\n",
      "loss: 0.0101653 accuracy: 99.0\n",
      "loss: 0.0142806 accuracy: 100.0\n",
      "loss: 0.0266117 accuracy: 99.0\n",
      "loss: 0.0199519 accuracy: 99.0\n",
      "loss: 0.0404393 accuracy: 99.0\n",
      "loss: 0.00605129 accuracy: 100.0\n",
      "loss: 0.00586495 accuracy: 100.0\n",
      "loss: 0.0213325 accuracy: 100.0\n",
      "loss: 0.00480962 accuracy: 100.0\n",
      "loss: 0.00538364 accuracy: 100.0\n",
      "loss: 0.00880606 accuracy: 100.0\n",
      "loss: 0.03371 accuracy: 99.0\n",
      "loss: 0.0241592 accuracy: 99.0\n",
      "loss: 0.0117318 accuracy: 99.0\n",
      "loss: 0.0129504 accuracy: 99.0\n",
      "loss: 0.0100055 accuracy: 100.0\n",
      "loss: 0.00544229 accuracy: 100.0\n",
      "loss: 0.00580624 accuracy: 100.0\n",
      "loss: 0.0057595 accuracy: 100.0\n",
      "loss: 0.0164636 accuracy: 100.0\n",
      "loss: 0.0275042 accuracy: 99.0\n",
      "loss: 0.0366256 accuracy: 98.0\n",
      "loss: 0.00293055 accuracy: 100.0\n",
      "loss: 0.0155246 accuracy: 99.0\n",
      "loss: 0.0048012 accuracy: 100.0\n",
      "loss: 0.0166934 accuracy: 100.0\n",
      "loss: 0.0229187 accuracy: 99.0\n",
      "loss: 0.021869 accuracy: 99.0\n",
      "loss: 0.00597686 accuracy: 100.0\n",
      "loss: 0.00370104 accuracy: 100.0\n",
      "loss: 0.0256007 accuracy: 99.0\n",
      "loss: 0.0273293 accuracy: 99.0\n",
      "loss: 0.00443357 accuracy: 100.0\n",
      "loss: 0.00545015 accuracy: 100.0\n",
      "loss: 0.0178855 accuracy: 100.0\n",
      "loss: 0.0267347 accuracy: 99.0\n",
      "loss: 0.0270218 accuracy: 99.0\n",
      "loss: 0.0155659 accuracy: 99.0\n",
      "loss: 0.0056749 accuracy: 100.0\n",
      "loss: 0.00170935 accuracy: 100.0\n",
      "loss: 0.0149303 accuracy: 99.0\n",
      "loss: 0.00798044 accuracy: 100.0\n",
      "loss: 0.00799726 accuracy: 100.0\n",
      "loss: 0.0155552 accuracy: 100.0\n",
      "loss: 0.0148601 accuracy: 100.0\n",
      "loss: 0.00651903 accuracy: 100.0\n",
      "loss: 0.0259231 accuracy: 99.0\n",
      "loss: 0.0937822 accuracy: 97.0\n",
      "loss: 0.00652809 accuracy: 100.0\n",
      "loss: 0.0135032 accuracy: 100.0\n",
      "loss: 0.00964608 accuracy: 100.0\n",
      "loss: 0.00959162 accuracy: 100.0\n",
      "loss: 0.0094572 accuracy: 100.0\n",
      "loss: 0.0764894 accuracy: 99.0\n",
      "loss: 0.0250974 accuracy: 99.0\n",
      "loss: 0.00457757 accuracy: 100.0\n",
      "loss: 0.0220227 accuracy: 99.0\n",
      "loss: 0.00620326 accuracy: 100.0\n",
      "loss: 0.00666824 accuracy: 100.0\n",
      "loss: 0.00671383 accuracy: 100.0\n",
      "loss: 0.00751937 accuracy: 100.0\n",
      "loss: 0.00377295 accuracy: 100.0\n",
      "loss: 0.011657 accuracy: 99.0\n",
      "loss: 0.0215455 accuracy: 100.0\n",
      "loss: 0.00266977 accuracy: 100.0\n",
      "loss: 0.00400227 accuracy: 100.0\n",
      "loss: 0.00643752 accuracy: 100.0\n",
      "loss: 0.00698559 accuracy: 100.0\n",
      "loss: 0.0123483 accuracy: 100.0\n",
      "loss: 0.00367052 accuracy: 100.0\n",
      "loss: 0.0746864 accuracy: 99.0\n",
      "loss: 0.00479909 accuracy: 100.0\n",
      "loss: 0.00646321 accuracy: 100.0\n",
      "loss: 0.00840127 accuracy: 100.0\n",
      "loss: 0.0146923 accuracy: 100.0\n",
      "loss: 0.00731596 accuracy: 100.0\n",
      "loss: 0.00531558 accuracy: 100.0\n",
      "loss: 0.0239337 accuracy: 99.0\n",
      "loss: 0.00630555 accuracy: 100.0\n",
      "loss: 0.0272762 accuracy: 99.0\n",
      "loss: 0.00488184 accuracy: 100.0\n",
      "loss: 0.00315155 accuracy: 100.0\n",
      "loss: 0.00368592 accuracy: 100.0\n",
      "loss: 0.0123359 accuracy: 100.0\n",
      "loss: 0.00297692 accuracy: 100.0\n",
      "loss: 0.0148238 accuracy: 100.0\n",
      "loss: 0.010132 accuracy: 100.0\n",
      "loss: 0.00662013 accuracy: 100.0\n",
      "loss: 0.00702728 accuracy: 100.0\n",
      "loss: 0.0265124 accuracy: 99.0\n",
      "loss: 0.00881253 accuracy: 100.0\n",
      "loss: 0.00967232 accuracy: 100.0\n",
      "loss: 0.00844045 accuracy: 100.0\n",
      "loss: 0.000818775 accuracy: 100.0\n",
      "loss: 0.00417375 accuracy: 100.0\n",
      "loss: 0.01273 accuracy: 100.0\n",
      "loss: 0.00448834 accuracy: 100.0\n",
      "loss: 0.0141202 accuracy: 99.0\n",
      "loss: 0.0407231 accuracy: 99.0\n",
      "loss: 0.0251439 accuracy: 99.0\n",
      "loss: 0.00334431 accuracy: 100.0\n",
      "loss: 0.0176144 accuracy: 100.0\n",
      "loss: 0.090175 accuracy: 98.0\n",
      "loss: 0.0278127 accuracy: 99.0\n",
      "loss: 0.0531646 accuracy: 99.0\n",
      "loss: 0.0183463 accuracy: 100.0\n",
      "loss: 0.00439123 accuracy: 100.0\n",
      "loss: 0.0150237 accuracy: 100.0\n",
      "loss: 0.0118859 accuracy: 100.0\n",
      "loss: 0.00852149 accuracy: 100.0\n",
      "loss: 0.00432662 accuracy: 100.0\n",
      "loss: 0.0115264 accuracy: 100.0\n",
      "loss: 0.00324481 accuracy: 100.0\n",
      "loss: 0.0602004 accuracy: 98.0\n",
      "loss: 0.0278989 accuracy: 99.0\n",
      "loss: 0.0022356 accuracy: 100.0\n",
      "loss: 0.0104393 accuracy: 100.0\n",
      "loss: 0.00310761 accuracy: 100.0\n",
      "loss: 0.0267861 accuracy: 98.0\n",
      "loss: 0.0186513 accuracy: 100.0\n",
      "loss: 0.00865578 accuracy: 100.0\n",
      "loss: 0.017577 accuracy: 100.0\n",
      "loss: 0.00953812 accuracy: 100.0\n",
      "loss: 0.00757867 accuracy: 100.0\n",
      "loss: 0.00331989 accuracy: 100.0\n",
      "loss: 0.0241515 accuracy: 99.0\n",
      "loss: 0.0114439 accuracy: 100.0\n",
      "loss: 0.0348695 accuracy: 99.0\n",
      "loss: 0.00548833 accuracy: 100.0\n",
      "loss: 0.0165479 accuracy: 99.0\n",
      "loss: 0.146478 accuracy: 98.0\n",
      "loss: 0.0221984 accuracy: 99.0\n",
      "loss: 0.0740739 accuracy: 99.0\n",
      "loss: 0.035644 accuracy: 98.0\n",
      "loss: 0.0732157 accuracy: 97.0\n",
      "loss: 0.00843833 accuracy: 100.0\n",
      "loss: 0.0141691 accuracy: 100.0\n",
      "loss: 0.0159564 accuracy: 100.0\n",
      "loss: 0.0140811 accuracy: 100.0\n",
      "loss: 0.0242508 accuracy: 99.0\n",
      "loss: 0.0318422 accuracy: 99.0\n",
      "loss: 0.00989341 accuracy: 100.0\n",
      "loss: 0.0105578 accuracy: 100.0\n",
      "loss: 0.0170673 accuracy: 99.0\n",
      "loss: 0.00337997 accuracy: 100.0\n",
      "loss: 0.00637146 accuracy: 100.0\n",
      "loss: 0.0413317 accuracy: 99.0\n",
      "loss: 0.00532433 accuracy: 100.0\n",
      "loss: 0.0040825 accuracy: 100.0\n",
      "loss: 0.00657181 accuracy: 100.0\n",
      "loss: 0.00456942 accuracy: 100.0\n",
      "loss: 0.0374026 accuracy: 97.0\n",
      "loss: 0.0101596 accuracy: 100.0\n",
      "loss: 0.0273873 accuracy: 99.0\n",
      "loss: 0.0183555 accuracy: 99.0\n",
      "loss: 0.0122018 accuracy: 100.0\n",
      "loss: 0.0105985 accuracy: 100.0\n",
      "loss: 0.0328058 accuracy: 98.0\n",
      "loss: 0.0560185 accuracy: 99.0\n",
      "loss: 0.00490863 accuracy: 100.0\n",
      "loss: 0.00234553 accuracy: 100.0\n",
      "loss: 0.0179664 accuracy: 99.0\n",
      "loss: 0.0166162 accuracy: 100.0\n",
      "loss: 0.0051532 accuracy: 100.0\n",
      "loss: 0.00924144 accuracy: 100.0\n",
      "loss: 0.084238 accuracy: 99.0\n",
      "loss: 0.00662017 accuracy: 100.0\n",
      "loss: 0.0301887 accuracy: 99.0\n",
      "loss: 0.00610362 accuracy: 100.0\n",
      "loss: 0.013938 accuracy: 100.0\n",
      "loss: 0.00228192 accuracy: 100.0\n",
      "loss: 0.00355071 accuracy: 100.0\n",
      "loss: 0.0154828 accuracy: 99.0\n",
      "loss: 0.0372598 accuracy: 99.0\n",
      "loss: 0.018338 accuracy: 99.0\n",
      "loss: 0.0107786 accuracy: 100.0\n",
      "loss: 0.0122595 accuracy: 100.0\n",
      "loss: 0.0073329 accuracy: 100.0\n",
      "loss: 0.0147025 accuracy: 99.0\n",
      "loss: 0.0414438 accuracy: 99.0\n",
      "loss: 0.00581664 accuracy: 100.0\n",
      "loss: 0.00883727 accuracy: 100.0\n",
      "loss: 0.0144288 accuracy: 99.0\n",
      "loss: 0.0746676 accuracy: 98.0\n",
      "loss: 0.0175276 accuracy: 100.0\n",
      "loss: 0.013426 accuracy: 99.0\n",
      "loss: 0.0098421 accuracy: 100.0\n",
      "loss: 0.00477505 accuracy: 100.0\n",
      "loss: 0.012333 accuracy: 100.0\n",
      "loss: 0.00704 accuracy: 100.0\n",
      "loss: 0.0462633 accuracy: 99.0\n",
      "loss: 0.00912883 accuracy: 100.0\n",
      "loss: 0.00661724 accuracy: 100.0\n",
      "loss: 0.00395795 accuracy: 100.0\n",
      "loss: 0.0224879 accuracy: 99.0\n",
      "loss: 0.0126752 accuracy: 100.0\n",
      "loss: 0.00987736 accuracy: 100.0\n",
      "loss: 0.0197118 accuracy: 99.0\n",
      "loss: 0.0156374 accuracy: 99.0\n",
      "loss: 0.036306 accuracy: 98.0\n",
      "loss: 0.0113525 accuracy: 100.0\n",
      "loss: 0.00865424 accuracy: 100.0\n",
      "loss: 0.00519213 accuracy: 100.0\n",
      "loss: 0.00880127 accuracy: 100.0\n",
      "loss: 0.0030212 accuracy: 100.0\n",
      "loss: 0.00890699 accuracy: 100.0\n",
      "loss: 0.00958154 accuracy: 100.0\n",
      "loss: 0.00881831 accuracy: 100.0\n",
      "loss: 0.019611 accuracy: 100.0\n",
      "loss: 0.0208516 accuracy: 100.0\n",
      "loss: 0.003912 accuracy: 100.0\n",
      "loss: 0.0049648 accuracy: 100.0\n",
      "loss: 0.0223143 accuracy: 99.0\n",
      "loss: 0.00841569 accuracy: 100.0\n",
      "loss: 0.0024546 accuracy: 100.0\n",
      "loss: 0.0205775 accuracy: 100.0\n",
      "loss: 0.018457 accuracy: 100.0\n",
      "loss: 0.0102629 accuracy: 100.0\n",
      "loss: 0.00720746 accuracy: 100.0\n",
      "loss: 0.00401722 accuracy: 100.0\n",
      "loss: 0.00451639 accuracy: 100.0\n",
      "loss: 0.00884403 accuracy: 100.0\n",
      "loss: 0.0173969 accuracy: 100.0\n",
      "loss: 0.00632321 accuracy: 100.0\n",
      "loss: 0.0056165 accuracy: 100.0\n",
      "loss: 0.0357011 accuracy: 99.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00212532 accuracy: 100.0\n",
      "loss: 0.00423739 accuracy: 100.0\n",
      "loss: 0.0320577 accuracy: 99.0\n",
      "loss: 0.0174816 accuracy: 100.0\n",
      "loss: 0.00395777 accuracy: 100.0\n",
      "loss: 0.00434462 accuracy: 100.0\n",
      "loss: 0.00231194 accuracy: 100.0\n",
      "loss: 0.0235093 accuracy: 99.0\n",
      "loss: 0.00563413 accuracy: 100.0\n",
      "loss: 0.0203423 accuracy: 99.0\n",
      "loss: 0.0151646 accuracy: 99.0\n",
      "loss: 0.0316818 accuracy: 99.0\n",
      "loss: 0.0088758 accuracy: 100.0\n",
      "loss: 0.00212707 accuracy: 100.0\n",
      "loss: 0.0314483 accuracy: 99.0\n",
      "loss: 0.0663398 accuracy: 98.0\n",
      "loss: 0.00502437 accuracy: 100.0\n",
      "loss: 0.058223 accuracy: 99.0\n",
      "loss: 0.0250028 accuracy: 100.0\n",
      "loss: 0.00335027 accuracy: 100.0\n",
      "loss: 0.0134118 accuracy: 100.0\n",
      "loss: 0.0138891 accuracy: 99.0\n",
      "loss: 0.0156381 accuracy: 99.0\n",
      "loss: 0.0149804 accuracy: 100.0\n",
      "loss: 0.00960118 accuracy: 100.0\n",
      "loss: 0.00501816 accuracy: 100.0\n",
      "loss: 0.00716223 accuracy: 100.0\n",
      "loss: 0.00722536 accuracy: 100.0\n",
      "loss: 0.0226538 accuracy: 100.0\n",
      "loss: 0.0423353 accuracy: 99.0\n",
      "loss: 0.0153289 accuracy: 100.0\n",
      "loss: 0.00743392 accuracy: 100.0\n",
      "loss: 0.0214777 accuracy: 99.0\n",
      "loss: 0.00367157 accuracy: 100.0\n",
      "loss: 0.015003 accuracy: 100.0\n",
      "loss: 0.00465656 accuracy: 100.0\n",
      "loss: 0.0320917 accuracy: 98.0\n",
      "loss: 0.0230311 accuracy: 99.0\n",
      "loss: 0.0144394 accuracy: 100.0\n",
      "loss: 0.0090491 accuracy: 100.0\n",
      "loss: 0.00614278 accuracy: 100.0\n",
      "loss: 0.00311728 accuracy: 100.0\n",
      "loss: 0.00561522 accuracy: 100.0\n",
      "loss: 0.0151552 accuracy: 99.0\n",
      "loss: 0.0447587 accuracy: 99.0\n",
      "loss: 0.00479496 accuracy: 100.0\n",
      "loss: 0.00469938 accuracy: 100.0\n",
      "loss: 0.000930413 accuracy: 100.0\n",
      "loss: 0.024564 accuracy: 100.0\n",
      "loss: 0.0746791 accuracy: 99.0\n",
      "loss: 0.0179232 accuracy: 99.0\n",
      "loss: 0.00101519 accuracy: 100.0\n",
      "loss: 0.00926953 accuracy: 100.0\n",
      "loss: 0.00294271 accuracy: 100.0\n",
      "loss: 0.0110708 accuracy: 100.0\n",
      "loss: 0.014823 accuracy: 100.0\n",
      "loss: 0.00231991 accuracy: 100.0\n",
      "loss: 0.00423256 accuracy: 100.0\n",
      "loss: 0.0310225 accuracy: 99.0\n",
      "loss: 0.0101979 accuracy: 100.0\n",
      "loss: 0.00866743 accuracy: 100.0\n",
      "loss: 0.0074824 accuracy: 100.0\n",
      "loss: 0.00914419 accuracy: 100.0\n",
      "loss: 0.0123449 accuracy: 100.0\n",
      "loss: 0.00744971 accuracy: 100.0\n",
      "loss: 0.0227349 accuracy: 99.0\n",
      "loss: 0.00938143 accuracy: 100.0\n",
      "loss: 0.0532216 accuracy: 98.0\n",
      "loss: 0.00873407 accuracy: 100.0\n",
      "loss: 0.0016733 accuracy: 100.0\n",
      "loss: 0.0114954 accuracy: 100.0\n",
      "loss: 0.0204096 accuracy: 99.0\n",
      "loss: 0.0168398 accuracy: 99.0\n",
      "loss: 0.00525027 accuracy: 100.0\n",
      "loss: 0.0974748 accuracy: 99.0\n",
      "loss: 0.00774268 accuracy: 100.0\n",
      "loss: 0.00309685 accuracy: 100.0\n",
      "loss: 0.00752561 accuracy: 100.0\n",
      "loss: 0.00600877 accuracy: 100.0\n",
      "loss: 0.0178271 accuracy: 99.0\n",
      "loss: 0.00794595 accuracy: 100.0\n",
      "loss: 0.00970861 accuracy: 100.0\n",
      "loss: 0.0340045 accuracy: 99.0\n",
      "loss: 0.0166301 accuracy: 99.0\n",
      "loss: 0.0364811 accuracy: 98.0\n",
      "loss: 0.0104012 accuracy: 100.0\n",
      "loss: 0.00860966 accuracy: 100.0\n",
      "loss: 0.00886309 accuracy: 100.0\n",
      "loss: 0.0322759 accuracy: 98.0\n",
      "loss: 0.00484018 accuracy: 100.0\n",
      "loss: 0.0227224 accuracy: 99.0\n",
      "loss: 0.00796706 accuracy: 100.0\n",
      "loss: 0.0662739 accuracy: 98.0\n",
      "loss: 0.0105173 accuracy: 100.0\n",
      "loss: 0.017677 accuracy: 99.0\n",
      "loss: 0.0348908 accuracy: 99.0\n",
      "loss: 0.00279352 accuracy: 100.0\n",
      "loss: 0.00768401 accuracy: 100.0\n",
      "loss: 0.0306223 accuracy: 99.0\n",
      "loss: 0.0176943 accuracy: 99.0\n",
      "loss: 0.0200287 accuracy: 99.0\n",
      "loss: 0.00209858 accuracy: 100.0\n",
      "loss: 0.00523206 accuracy: 100.0\n",
      "loss: 0.0607263 accuracy: 97.0\n",
      "loss: 0.00127227 accuracy: 100.0\n",
      "loss: 0.0198434 accuracy: 99.0\n",
      "loss: 0.0332164 accuracy: 98.0\n",
      "loss: 0.00265121 accuracy: 100.0\n",
      "loss: 0.00876577 accuracy: 100.0\n",
      "loss: 0.0306561 accuracy: 99.0\n",
      "loss: 0.01421 accuracy: 99.0\n",
      "loss: 0.0206468 accuracy: 99.0\n",
      "loss: 0.0104359 accuracy: 100.0\n",
      "loss: 0.00535661 accuracy: 100.0\n",
      "loss: 0.0123996 accuracy: 99.0\n",
      "loss: 0.00617155 accuracy: 100.0\n",
      "loss: 0.00578533 accuracy: 100.0\n",
      "loss: 0.0376622 accuracy: 98.0\n",
      "loss: 0.00843942 accuracy: 100.0\n",
      "loss: 0.0194808 accuracy: 100.0\n",
      "loss: 0.10631 accuracy: 99.0\n",
      "loss: 0.00635718 accuracy: 100.0\n",
      "loss: 0.00946994 accuracy: 100.0\n",
      "loss: 0.0282451 accuracy: 99.0\n",
      "loss: 0.00799461 accuracy: 100.0\n",
      "loss: 0.00434218 accuracy: 100.0\n",
      "loss: 0.0230499 accuracy: 99.0\n",
      "loss: 0.0140693 accuracy: 100.0\n",
      "loss: 0.00201018 accuracy: 100.0\n",
      "loss: 0.033829 accuracy: 97.0\n",
      "loss: 0.00458053 accuracy: 100.0\n",
      "loss: 0.00697343 accuracy: 100.0\n",
      "loss: 0.038755 accuracy: 99.0\n",
      "loss: 0.0302042 accuracy: 99.0\n",
      "loss: 0.00396525 accuracy: 100.0\n",
      "loss: 0.0174547 accuracy: 99.0\n",
      "loss: 0.00880485 accuracy: 100.0\n",
      "loss: 0.0332466 accuracy: 98.0\n",
      "loss: 0.0136236 accuracy: 99.0\n",
      "loss: 0.00457363 accuracy: 100.0\n",
      "loss: 0.00507713 accuracy: 100.0\n",
      "loss: 0.00659653 accuracy: 100.0\n",
      "loss: 0.00892123 accuracy: 100.0\n",
      "loss: 0.0241992 accuracy: 98.0\n",
      "loss: 0.0280317 accuracy: 98.0\n",
      "loss: 0.0147138 accuracy: 100.0\n",
      "loss: 0.0141049 accuracy: 100.0\n",
      "loss: 0.0141174 accuracy: 99.0\n",
      "loss: 0.00632695 accuracy: 100.0\n",
      "loss: 0.0366611 accuracy: 99.0\n",
      "loss: 0.0138522 accuracy: 99.0\n",
      "loss: 0.131819 accuracy: 98.0\n",
      "loss: 0.00625929 accuracy: 100.0\n",
      "loss: 0.0175506 accuracy: 100.0\n",
      "loss: 0.00666162 accuracy: 100.0\n",
      "loss: 0.00651706 accuracy: 100.0\n",
      "loss: 0.0029215 accuracy: 100.0\n",
      "loss: 0.010886 accuracy: 100.0\n",
      "loss: 0.071933 accuracy: 98.0\n",
      "loss: 0.0272215 accuracy: 99.0\n",
      "loss: 0.0215913 accuracy: 99.0\n",
      "loss: 0.00254436 accuracy: 100.0\n",
      "loss: 0.00869966 accuracy: 100.0\n",
      "loss: 0.0411887 accuracy: 99.0\n",
      "loss: 0.00492345 accuracy: 100.0\n",
      "loss: 0.0419726 accuracy: 99.0\n",
      "loss: 0.0194745 accuracy: 99.0\n",
      "loss: 0.0073893 accuracy: 100.0\n",
      "loss: 0.00750532 accuracy: 100.0\n",
      "loss: 0.00577403 accuracy: 100.0\n",
      "loss: 0.0178743 accuracy: 100.0\n",
      "loss: 0.0106091 accuracy: 100.0\n",
      "loss: 0.0102686 accuracy: 100.0\n",
      "loss: 0.0385059 accuracy: 99.0\n",
      "loss: 0.0167153 accuracy: 100.0\n",
      "loss: 0.00421784 accuracy: 100.0\n",
      "loss: 0.00195204 accuracy: 100.0\n",
      "loss: 0.00470508 accuracy: 100.0\n",
      "loss: 0.0388457 accuracy: 99.0\n",
      "loss: 0.00611209 accuracy: 100.0\n",
      "loss: 0.0121004 accuracy: 100.0\n",
      "loss: 0.00483793 accuracy: 100.0\n",
      "loss: 0.00766111 accuracy: 100.0\n",
      "loss: 0.0120206 accuracy: 100.0\n",
      "loss: 0.00441743 accuracy: 100.0\n",
      "loss: 0.00388519 accuracy: 100.0\n",
      "loss: 0.0209009 accuracy: 100.0\n",
      "loss: 0.0253041 accuracy: 99.0\n",
      "loss: 0.0292093 accuracy: 99.0\n",
      "loss: 0.0243173 accuracy: 99.0\n",
      "loss: 0.0161938 accuracy: 100.0\n",
      "loss: 0.0360783 accuracy: 99.0\n",
      "loss: 0.0161508 accuracy: 100.0\n",
      "loss: 0.00525146 accuracy: 100.0\n",
      "loss: 0.0178361 accuracy: 100.0\n",
      "loss: 0.00271041 accuracy: 100.0\n",
      "loss: 0.0268669 accuracy: 99.0\n",
      "loss: 0.00587585 accuracy: 100.0\n",
      "loss: 0.011081 accuracy: 100.0\n",
      "loss: 0.002254 accuracy: 100.0\n",
      "loss: 0.00851577 accuracy: 100.0\n",
      "loss: 0.00446036 accuracy: 100.0\n",
      "loss: 0.0178305 accuracy: 100.0\n",
      "loss: 0.0452288 accuracy: 99.0\n",
      "loss: 0.0616725 accuracy: 98.0\n",
      "loss: 0.0335142 accuracy: 98.0\n",
      "loss: 0.00803961 accuracy: 100.0\n",
      "loss: 0.0291936 accuracy: 99.0\n",
      "loss: 0.00527958 accuracy: 100.0\n",
      "loss: 0.0304166 accuracy: 99.0\n",
      "loss: 0.00871542 accuracy: 100.0\n",
      "loss: 0.0293657 accuracy: 100.0\n",
      "loss: 0.049373 accuracy: 99.0\n",
      "loss: 0.0065631 accuracy: 100.0\n",
      "loss: 0.0094086 accuracy: 100.0\n",
      "loss: 0.0363952 accuracy: 99.0\n",
      "loss: 0.0272221 accuracy: 99.0\n",
      "loss: 0.0108502 accuracy: 100.0\n",
      "loss: 0.0104636 accuracy: 100.0\n",
      "loss: 0.00775872 accuracy: 100.0\n",
      "loss: 0.00652397 accuracy: 100.0\n",
      "loss: 0.0101485 accuracy: 100.0\n",
      "loss: 0.0627358 accuracy: 99.0\n",
      "loss: 0.0032355 accuracy: 100.0\n",
      "loss: 0.0357144 accuracy: 99.0\n",
      "loss: 0.0089137 accuracy: 100.0\n",
      "loss: 0.0161862 accuracy: 100.0\n",
      "loss: 0.00373162 accuracy: 100.0\n",
      "loss: 0.0185124 accuracy: 100.0\n",
      "loss: 0.0110586 accuracy: 100.0\n",
      "loss: 0.0282983 accuracy: 99.0\n",
      ">>>>>>>>>> test dataset accuracy: 97.85\n",
      "loss: 0.0145392 accuracy: 100.0\n",
      "loss: 0.00526932 accuracy: 100.0\n",
      "loss: 0.00924209 accuracy: 100.0\n",
      "loss: 0.00883833 accuracy: 100.0\n",
      "loss: 0.00911732 accuracy: 100.0\n",
      "loss: 0.00362333 accuracy: 100.0\n",
      "loss: 0.0139653 accuracy: 100.0\n",
      "loss: 0.0137381 accuracy: 100.0\n",
      "loss: 0.0127023 accuracy: 100.0\n",
      "loss: 0.0068774 accuracy: 100.0\n",
      "loss: 0.00336719 accuracy: 100.0\n",
      "loss: 0.00848849 accuracy: 100.0\n",
      "loss: 0.00522637 accuracy: 100.0\n",
      "loss: 0.00724486 accuracy: 100.0\n",
      "loss: 0.00540391 accuracy: 100.0\n",
      "loss: 0.00758324 accuracy: 100.0\n",
      "loss: 0.00255644 accuracy: 100.0\n",
      "loss: 0.00183912 accuracy: 100.0\n",
      "loss: 0.0142519 accuracy: 99.0\n",
      "loss: 0.00454751 accuracy: 100.0\n",
      "loss: 0.00946479 accuracy: 100.0\n",
      "loss: 0.00553297 accuracy: 100.0\n",
      "loss: 0.0134145 accuracy: 99.0\n",
      "loss: 0.0103821 accuracy: 100.0\n",
      "loss: 0.00426701 accuracy: 100.0\n",
      "loss: 0.00189383 accuracy: 100.0\n",
      "loss: 0.00642383 accuracy: 100.0\n",
      "loss: 0.00615456 accuracy: 100.0\n",
      "loss: 0.0133136 accuracy: 100.0\n",
      "loss: 0.00161296 accuracy: 100.0\n",
      "loss: 0.00362845 accuracy: 100.0\n",
      "loss: 0.00527797 accuracy: 100.0\n",
      "loss: 0.00557922 accuracy: 100.0\n",
      "loss: 0.00455893 accuracy: 100.0\n",
      "loss: 0.00546946 accuracy: 100.0\n",
      "loss: 0.00196936 accuracy: 100.0\n",
      "loss: 0.00427478 accuracy: 100.0\n",
      "loss: 0.00449403 accuracy: 100.0\n",
      "loss: 0.0197988 accuracy: 99.0\n",
      "loss: 0.00221099 accuracy: 100.0\n",
      "loss: 0.0133763 accuracy: 99.0\n",
      "loss: 0.00401228 accuracy: 100.0\n",
      "loss: 0.000767751 accuracy: 100.0\n",
      "loss: 0.00650504 accuracy: 100.0\n",
      "loss: 0.0189023 accuracy: 99.0\n",
      "loss: 0.00501205 accuracy: 100.0\n",
      "loss: 0.0037786 accuracy: 100.0\n",
      "loss: 0.00342077 accuracy: 100.0\n",
      "loss: 0.00379632 accuracy: 100.0\n",
      "loss: 0.00980268 accuracy: 100.0\n",
      "loss: 0.0101597 accuracy: 100.0\n",
      "loss: 0.0151668 accuracy: 100.0\n",
      "loss: 0.00386486 accuracy: 100.0\n",
      "loss: 0.00495852 accuracy: 100.0\n",
      "loss: 0.00236598 accuracy: 100.0\n",
      "loss: 0.00383931 accuracy: 100.0\n",
      "loss: 0.00466367 accuracy: 100.0\n",
      "loss: 0.00296051 accuracy: 100.0\n",
      "loss: 0.0103972 accuracy: 100.0\n",
      "loss: 0.00338777 accuracy: 100.0\n",
      "loss: 0.00260841 accuracy: 100.0\n",
      "loss: 0.00816238 accuracy: 100.0\n",
      "loss: 0.00381778 accuracy: 100.0\n",
      "loss: 0.00489579 accuracy: 100.0\n",
      "loss: 0.00528214 accuracy: 100.0\n",
      "loss: 0.00992114 accuracy: 100.0\n",
      "loss: 0.0226111 accuracy: 99.0\n",
      "loss: 0.0039024 accuracy: 100.0\n",
      "loss: 0.00678092 accuracy: 100.0\n",
      "loss: 0.00531008 accuracy: 100.0\n",
      "loss: 0.00212138 accuracy: 100.0\n",
      "loss: 0.00100728 accuracy: 100.0\n",
      "loss: 0.00564425 accuracy: 100.0\n",
      "loss: 0.00786197 accuracy: 100.0\n",
      "loss: 0.00320767 accuracy: 100.0\n",
      "loss: 0.00175067 accuracy: 100.0\n",
      "loss: 0.0049553 accuracy: 100.0\n",
      "loss: 0.00827876 accuracy: 100.0\n",
      "loss: 0.00897074 accuracy: 100.0\n",
      "loss: 0.00323257 accuracy: 100.0\n",
      "loss: 0.00208728 accuracy: 100.0\n",
      "loss: 0.0042191 accuracy: 100.0\n",
      "loss: 0.00486016 accuracy: 100.0\n",
      "loss: 0.025041 accuracy: 98.0\n",
      "loss: 0.0166639 accuracy: 99.0\n",
      "loss: 0.00902021 accuracy: 100.0\n",
      "loss: 0.0190768 accuracy: 99.0\n",
      "loss: 0.00678697 accuracy: 100.0\n",
      "loss: 0.00517745 accuracy: 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00376242 accuracy: 100.0\n",
      "loss: 0.00593254 accuracy: 100.0\n",
      "loss: 0.000656642 accuracy: 100.0\n",
      "loss: 0.0553248 accuracy: 99.0\n",
      "loss: 0.0416491 accuracy: 99.0\n",
      "loss: 0.0233455 accuracy: 99.0\n",
      "loss: 0.00422576 accuracy: 100.0\n",
      "loss: 0.0049267 accuracy: 100.0\n",
      "loss: 0.0171392 accuracy: 100.0\n",
      "loss: 0.0134995 accuracy: 99.0\n",
      "loss: 0.0151467 accuracy: 99.0\n",
      "loss: 0.0151431 accuracy: 99.0\n",
      "loss: 0.0120371 accuracy: 100.0\n",
      "loss: 0.00431018 accuracy: 100.0\n",
      "loss: 0.00401552 accuracy: 100.0\n",
      "loss: 0.00242152 accuracy: 100.0\n",
      "loss: 0.0803322 accuracy: 98.0\n",
      "loss: 0.0111469 accuracy: 100.0\n",
      "loss: 0.00355915 accuracy: 100.0\n",
      "loss: 0.0145754 accuracy: 100.0\n",
      "loss: 0.0120904 accuracy: 100.0\n",
      "loss: 0.0212294 accuracy: 99.0\n",
      "loss: 0.00504698 accuracy: 100.0\n",
      "loss: 0.00563604 accuracy: 100.0\n",
      "loss: 0.00429726 accuracy: 100.0\n",
      "loss: 0.0109489 accuracy: 99.0\n",
      "loss: 0.00199216 accuracy: 100.0\n",
      "loss: 0.00331777 accuracy: 100.0\n",
      "loss: 0.00382375 accuracy: 100.0\n",
      "loss: 0.00784654 accuracy: 100.0\n",
      "loss: 0.00260529 accuracy: 100.0\n",
      "loss: 0.00525877 accuracy: 100.0\n",
      "loss: 0.00348078 accuracy: 100.0\n",
      "loss: 0.00340384 accuracy: 100.0\n",
      "loss: 0.0307962 accuracy: 99.0\n",
      "loss: 0.00302482 accuracy: 100.0\n",
      "loss: 0.0156216 accuracy: 99.0\n",
      "loss: 0.00478466 accuracy: 100.0\n",
      "loss: 0.00206649 accuracy: 100.0\n",
      "loss: 0.00608213 accuracy: 100.0\n",
      "loss: 0.0885651 accuracy: 99.0\n",
      "loss: 0.0123443 accuracy: 100.0\n",
      "loss: 0.00431242 accuracy: 100.0\n",
      "loss: 0.00363779 accuracy: 100.0\n",
      "loss: 0.0165463 accuracy: 100.0\n",
      "loss: 0.00434152 accuracy: 100.0\n",
      "loss: 0.00440972 accuracy: 100.0\n",
      "loss: 0.0115784 accuracy: 100.0\n",
      "loss: 0.00825135 accuracy: 100.0\n",
      "loss: 0.00328954 accuracy: 100.0\n",
      "loss: 0.00485647 accuracy: 100.0\n",
      "loss: 0.014343 accuracy: 100.0\n",
      "loss: 0.00855325 accuracy: 100.0\n",
      "loss: 0.00484565 accuracy: 100.0\n",
      "loss: 0.0123553 accuracy: 100.0\n",
      "loss: 0.00864854 accuracy: 100.0\n",
      "loss: 0.0138139 accuracy: 99.0\n",
      "loss: 0.00434539 accuracy: 100.0\n",
      "loss: 0.0186875 accuracy: 99.0\n",
      "loss: 0.00506322 accuracy: 100.0\n",
      "loss: 0.0067048 accuracy: 100.0\n",
      "loss: 0.00107914 accuracy: 100.0\n",
      "loss: 0.00157356 accuracy: 100.0\n",
      "loss: 0.0183773 accuracy: 99.0\n",
      "loss: 0.0215441 accuracy: 99.0\n",
      "loss: 0.0103014 accuracy: 100.0\n",
      "loss: 0.00907113 accuracy: 100.0\n",
      "loss: 0.0166819 accuracy: 99.0\n",
      "loss: 0.0200052 accuracy: 99.0\n",
      "loss: 0.0160214 accuracy: 100.0\n",
      "loss: 0.00615939 accuracy: 100.0\n",
      "loss: 0.00905934 accuracy: 100.0\n",
      "loss: 0.00235508 accuracy: 100.0\n",
      "loss: 0.00460772 accuracy: 100.0\n",
      "loss: 0.0132574 accuracy: 99.0\n",
      "loss: 0.00564217 accuracy: 100.0\n",
      "loss: 0.00318724 accuracy: 100.0\n",
      "loss: 0.00576103 accuracy: 100.0\n",
      "loss: 0.00359057 accuracy: 100.0\n",
      "loss: 0.00251669 accuracy: 100.0\n",
      "loss: 0.00233494 accuracy: 100.0\n",
      "loss: 0.00228697 accuracy: 100.0\n",
      "loss: 0.00167444 accuracy: 100.0\n",
      "loss: 0.00896114 accuracy: 100.0\n",
      "loss: 0.00187833 accuracy: 100.0\n",
      "loss: 0.00263285 accuracy: 100.0\n",
      "loss: 0.00470248 accuracy: 100.0\n",
      "loss: 0.00393728 accuracy: 100.0\n",
      "loss: 0.00225132 accuracy: 100.0\n",
      "loss: 0.00711592 accuracy: 100.0\n",
      "loss: 0.00345038 accuracy: 100.0\n",
      "loss: 0.00586549 accuracy: 100.0\n",
      "loss: 0.0407513 accuracy: 99.0\n",
      "loss: 0.0045216 accuracy: 100.0\n",
      "loss: 0.00694538 accuracy: 100.0\n",
      "loss: 0.0091031 accuracy: 100.0\n",
      "loss: 0.00418254 accuracy: 100.0\n",
      "loss: 0.00537233 accuracy: 100.0\n",
      "loss: 0.00796874 accuracy: 100.0\n",
      "loss: 0.00211719 accuracy: 100.0\n",
      "loss: 0.00914486 accuracy: 100.0\n",
      "loss: 0.00821456 accuracy: 100.0\n",
      "loss: 0.00477259 accuracy: 100.0\n",
      "loss: 0.00481318 accuracy: 100.0\n",
      "loss: 0.00955071 accuracy: 100.0\n",
      "loss: 0.00806788 accuracy: 100.0\n",
      "loss: 0.0431849 accuracy: 99.0\n",
      "loss: 0.00783518 accuracy: 100.0\n",
      "loss: 0.00674318 accuracy: 100.0\n",
      "loss: 0.00423706 accuracy: 100.0\n",
      "loss: 0.00274453 accuracy: 100.0\n",
      "loss: 0.0018979 accuracy: 100.0\n",
      "loss: 0.00788342 accuracy: 100.0\n",
      "loss: 0.0029546 accuracy: 100.0\n",
      "loss: 0.00349419 accuracy: 100.0\n",
      "loss: 0.00404363 accuracy: 100.0\n",
      "loss: 0.0106571 accuracy: 100.0\n",
      "loss: 0.00995585 accuracy: 99.0\n",
      "loss: 0.0165903 accuracy: 99.0\n",
      "loss: 0.0121401 accuracy: 99.0\n",
      "loss: 0.00254087 accuracy: 100.0\n",
      "loss: 0.00700414 accuracy: 100.0\n",
      "loss: 0.00870196 accuracy: 100.0\n",
      "loss: 0.00534001 accuracy: 100.0\n",
      "loss: 0.00412453 accuracy: 100.0\n",
      "loss: 0.00942086 accuracy: 100.0\n",
      "loss: 0.0104436 accuracy: 100.0\n",
      "loss: 0.00285116 accuracy: 100.0\n",
      "loss: 0.00504266 accuracy: 100.0\n",
      "loss: 0.012265 accuracy: 100.0\n",
      "loss: 0.00255851 accuracy: 100.0\n",
      "loss: 0.00516577 accuracy: 100.0\n",
      "loss: 0.0191137 accuracy: 99.0\n",
      "loss: 0.00429169 accuracy: 100.0\n",
      "loss: 0.00448954 accuracy: 100.0\n",
      "loss: 0.000899011 accuracy: 100.0\n",
      "loss: 0.00775387 accuracy: 100.0\n",
      "loss: 0.00863371 accuracy: 100.0\n",
      "loss: 0.00453662 accuracy: 100.0\n",
      "loss: 0.00638512 accuracy: 100.0\n",
      "loss: 0.0129681 accuracy: 100.0\n",
      "loss: 0.00350257 accuracy: 100.0\n",
      "loss: 0.0135215 accuracy: 100.0\n",
      "loss: 0.00182213 accuracy: 100.0\n",
      "loss: 0.00321657 accuracy: 100.0\n",
      "loss: 0.0038835 accuracy: 100.0\n",
      "loss: 0.00736795 accuracy: 100.0\n",
      "loss: 0.00644405 accuracy: 100.0\n",
      "loss: 0.00133898 accuracy: 100.0\n",
      "loss: 0.00708013 accuracy: 100.0\n",
      "loss: 0.00364546 accuracy: 100.0\n",
      "loss: 0.002403 accuracy: 100.0\n",
      "loss: 0.00649558 accuracy: 100.0\n",
      "loss: 0.00210842 accuracy: 100.0\n",
      "loss: 0.00425606 accuracy: 100.0\n",
      "loss: 0.00465325 accuracy: 100.0\n",
      "loss: 0.0034679 accuracy: 100.0\n",
      "loss: 0.00336723 accuracy: 100.0\n",
      "loss: 0.0060335 accuracy: 100.0\n",
      "loss: 0.00294119 accuracy: 100.0\n",
      "loss: 0.00670967 accuracy: 100.0\n",
      "loss: 0.0105788 accuracy: 100.0\n",
      "loss: 0.00244491 accuracy: 100.0\n",
      "loss: 0.00448064 accuracy: 100.0\n",
      "loss: 0.00482763 accuracy: 100.0\n",
      "loss: 0.0125518 accuracy: 99.0\n",
      "loss: 0.0043879 accuracy: 100.0\n",
      "loss: 0.00291242 accuracy: 100.0\n",
      "loss: 0.00830666 accuracy: 100.0\n",
      "loss: 0.00760868 accuracy: 100.0\n",
      "loss: 0.00163728 accuracy: 100.0\n",
      "loss: 0.00502036 accuracy: 100.0\n",
      "loss: 0.00186627 accuracy: 100.0\n",
      "loss: 0.00453322 accuracy: 100.0\n",
      "loss: 0.00782687 accuracy: 100.0\n",
      "loss: 0.000841285 accuracy: 100.0\n",
      "loss: 0.00332679 accuracy: 100.0\n",
      "loss: 0.00356211 accuracy: 100.0\n",
      "loss: 0.027044 accuracy: 99.0\n",
      "loss: 0.00553894 accuracy: 100.0\n",
      "loss: 0.0108584 accuracy: 100.0\n",
      "loss: 0.00609767 accuracy: 100.0\n",
      "loss: 0.0255245 accuracy: 99.0\n",
      "loss: 0.00304655 accuracy: 100.0\n",
      "loss: 0.0027018 accuracy: 100.0\n",
      "loss: 0.00159791 accuracy: 100.0\n",
      "loss: 0.0783937 accuracy: 99.0\n",
      "loss: 0.00841624 accuracy: 100.0\n",
      "loss: 0.0103292 accuracy: 100.0\n",
      "loss: 0.0114947 accuracy: 100.0\n",
      "loss: 0.0156437 accuracy: 99.0\n",
      "loss: 0.0180662 accuracy: 100.0\n",
      "loss: 0.00497664 accuracy: 100.0\n",
      "loss: 0.0512149 accuracy: 99.0\n",
      "loss: 0.00336038 accuracy: 100.0\n",
      "loss: 0.00149958 accuracy: 100.0\n",
      "loss: 0.00316141 accuracy: 100.0\n",
      "loss: 0.00922976 accuracy: 100.0\n",
      "loss: 0.0141187 accuracy: 100.0\n",
      "loss: 0.00680993 accuracy: 100.0\n",
      "loss: 0.00510345 accuracy: 100.0\n",
      "loss: 0.00510972 accuracy: 100.0\n",
      "loss: 0.00380366 accuracy: 100.0\n",
      "loss: 0.00399325 accuracy: 100.0\n",
      "loss: 0.015882 accuracy: 100.0\n",
      "loss: 0.00815356 accuracy: 100.0\n",
      "loss: 0.0224808 accuracy: 99.0\n",
      "loss: 0.0220827 accuracy: 99.0\n",
      "loss: 0.0345557 accuracy: 98.0\n",
      "loss: 0.0505224 accuracy: 99.0\n",
      "loss: 0.00879383 accuracy: 100.0\n",
      "loss: 0.00664112 accuracy: 100.0\n",
      "loss: 0.00976709 accuracy: 100.0\n",
      "loss: 0.0135171 accuracy: 99.0\n",
      "loss: 0.0262013 accuracy: 99.0\n",
      "loss: 0.0221509 accuracy: 100.0\n",
      "loss: 0.00741397 accuracy: 100.0\n",
      "loss: 0.00331543 accuracy: 100.0\n",
      "loss: 0.00662206 accuracy: 100.0\n",
      "loss: 0.00386499 accuracy: 100.0\n",
      "loss: 0.00695354 accuracy: 100.0\n",
      "loss: 0.00237934 accuracy: 100.0\n",
      "loss: 0.0175719 accuracy: 99.0\n",
      "loss: 0.00390174 accuracy: 100.0\n",
      "loss: 0.0148463 accuracy: 100.0\n",
      "loss: 0.00446935 accuracy: 100.0\n",
      "loss: 0.0106807 accuracy: 100.0\n",
      "loss: 0.0421174 accuracy: 98.0\n",
      "loss: 0.00329383 accuracy: 100.0\n",
      "loss: 0.0176319 accuracy: 99.0\n",
      "loss: 0.00616043 accuracy: 100.0\n",
      "loss: 0.0123689 accuracy: 100.0\n",
      "loss: 0.00285157 accuracy: 100.0\n",
      "loss: 0.0133512 accuracy: 100.0\n",
      "loss: 0.00636914 accuracy: 100.0\n",
      "loss: 0.00262421 accuracy: 100.0\n",
      "loss: 0.00245367 accuracy: 100.0\n",
      "loss: 0.00498475 accuracy: 100.0\n",
      "loss: 0.00316545 accuracy: 100.0\n",
      "loss: 0.0211645 accuracy: 99.0\n",
      "loss: 0.00168069 accuracy: 100.0\n",
      "loss: 0.00144968 accuracy: 100.0\n",
      "loss: 0.00201137 accuracy: 100.0\n",
      "loss: 0.00336922 accuracy: 100.0\n",
      "loss: 0.00649694 accuracy: 100.0\n",
      "loss: 0.047152 accuracy: 99.0\n",
      "loss: 0.00776095 accuracy: 100.0\n",
      "loss: 0.00650592 accuracy: 100.0\n",
      "loss: 0.00629437 accuracy: 100.0\n",
      "loss: 0.007924 accuracy: 100.0\n",
      "loss: 0.00882195 accuracy: 100.0\n",
      "loss: 0.00900629 accuracy: 100.0\n",
      "loss: 0.00692547 accuracy: 100.0\n",
      "loss: 0.00650406 accuracy: 100.0\n",
      "loss: 0.00318729 accuracy: 100.0\n",
      "loss: 0.00359769 accuracy: 100.0\n",
      "loss: 0.0114281 accuracy: 100.0\n",
      "loss: 0.00821888 accuracy: 100.0\n",
      "loss: 0.00234075 accuracy: 100.0\n",
      "loss: 0.00710882 accuracy: 100.0\n",
      "loss: 0.00254353 accuracy: 100.0\n",
      "loss: 0.0033322 accuracy: 100.0\n",
      "loss: 0.00372634 accuracy: 100.0\n",
      "loss: 0.0201424 accuracy: 99.0\n",
      "loss: 0.00148068 accuracy: 100.0\n",
      "loss: 0.00145758 accuracy: 100.0\n",
      "loss: 0.0040327 accuracy: 100.0\n",
      "loss: 0.00144493 accuracy: 100.0\n",
      "loss: 0.00452497 accuracy: 100.0\n",
      "loss: 0.00142452 accuracy: 100.0\n",
      "loss: 0.003723 accuracy: 100.0\n",
      "loss: 0.00230833 accuracy: 100.0\n",
      "loss: 0.0316917 accuracy: 99.0\n",
      "loss: 0.014731 accuracy: 100.0\n",
      "loss: 0.00271585 accuracy: 100.0\n",
      "loss: 0.0153462 accuracy: 99.0\n",
      "loss: 0.00457176 accuracy: 100.0\n",
      "loss: 0.00547432 accuracy: 100.0\n",
      "loss: 0.00537508 accuracy: 100.0\n",
      "loss: 0.0264255 accuracy: 99.0\n",
      "loss: 0.0392361 accuracy: 99.0\n",
      "loss: 0.0014136 accuracy: 100.0\n",
      "loss: 0.0118587 accuracy: 100.0\n",
      "loss: 0.00476333 accuracy: 100.0\n",
      "loss: 0.0113728 accuracy: 100.0\n",
      "loss: 0.012451 accuracy: 100.0\n",
      "loss: 0.00730229 accuracy: 100.0\n",
      "loss: 0.00471814 accuracy: 100.0\n",
      "loss: 0.0152901 accuracy: 99.0\n",
      "loss: 0.015653 accuracy: 100.0\n",
      "loss: 0.00702812 accuracy: 100.0\n",
      "loss: 0.00413897 accuracy: 100.0\n",
      "loss: 0.0755675 accuracy: 99.0\n",
      "loss: 0.00816846 accuracy: 100.0\n",
      "loss: 0.00640549 accuracy: 100.0\n",
      "loss: 0.00106021 accuracy: 100.0\n",
      "loss: 0.0102607 accuracy: 100.0\n",
      "loss: 0.0130223 accuracy: 100.0\n",
      "loss: 0.0259751 accuracy: 99.0\n",
      "loss: 0.00315065 accuracy: 100.0\n",
      "loss: 0.0133976 accuracy: 99.0\n",
      "loss: 0.0229151 accuracy: 98.0\n",
      "loss: 0.00310055 accuracy: 100.0\n",
      "loss: 0.00802032 accuracy: 100.0\n",
      "loss: 0.00213267 accuracy: 100.0\n",
      "loss: 0.00401223 accuracy: 100.0\n",
      "loss: 0.002693 accuracy: 100.0\n",
      "loss: 0.00301746 accuracy: 100.0\n",
      "loss: 0.00481503 accuracy: 100.0\n",
      "loss: 0.00492643 accuracy: 100.0\n",
      "loss: 0.014941 accuracy: 99.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00465692 accuracy: 100.0\n",
      "loss: 0.00477888 accuracy: 100.0\n",
      "loss: 0.00427068 accuracy: 100.0\n",
      "loss: 0.00300239 accuracy: 100.0\n",
      "loss: 0.0102341 accuracy: 100.0\n",
      "loss: 0.00247674 accuracy: 100.0\n",
      "loss: 0.00867814 accuracy: 100.0\n",
      "loss: 0.0029155 accuracy: 100.0\n",
      "loss: 0.00802704 accuracy: 100.0\n",
      "loss: 0.00232523 accuracy: 100.0\n",
      "loss: 0.00203886 accuracy: 100.0\n",
      "loss: 0.00846684 accuracy: 100.0\n",
      "loss: 0.00280378 accuracy: 100.0\n",
      "loss: 0.00149402 accuracy: 100.0\n",
      "loss: 0.00672821 accuracy: 100.0\n",
      "loss: 0.0187308 accuracy: 99.0\n",
      "loss: 0.00332172 accuracy: 100.0\n",
      "loss: 0.0093138 accuracy: 100.0\n",
      "loss: 0.002042 accuracy: 100.0\n",
      "loss: 0.00261263 accuracy: 100.0\n",
      "loss: 0.00293913 accuracy: 100.0\n",
      "loss: 0.00092237 accuracy: 100.0\n",
      "loss: 0.00228592 accuracy: 100.0\n",
      "loss: 0.00919254 accuracy: 100.0\n",
      "loss: 0.00226502 accuracy: 100.0\n",
      "loss: 0.0210076 accuracy: 99.0\n",
      "loss: 0.0111715 accuracy: 99.0\n",
      "loss: 0.00167728 accuracy: 100.0\n",
      "loss: 0.00909672 accuracy: 100.0\n",
      "loss: 0.0120443 accuracy: 99.0\n",
      "loss: 0.00241882 accuracy: 100.0\n",
      "loss: 0.0575179 accuracy: 98.0\n",
      "loss: 0.00949084 accuracy: 100.0\n",
      "loss: 0.00354731 accuracy: 100.0\n",
      "loss: 0.0103896 accuracy: 100.0\n",
      "loss: 0.0107449 accuracy: 100.0\n",
      "loss: 0.0193745 accuracy: 98.0\n",
      "loss: 0.0102153 accuracy: 100.0\n",
      "loss: 0.00499206 accuracy: 100.0\n",
      "loss: 0.0140428 accuracy: 100.0\n",
      "loss: 0.0180384 accuracy: 99.0\n",
      "loss: 0.00839135 accuracy: 100.0\n",
      "loss: 0.012148 accuracy: 100.0\n",
      "loss: 0.00186761 accuracy: 100.0\n",
      "loss: 0.0487565 accuracy: 98.0\n",
      "loss: 0.0156257 accuracy: 99.0\n",
      "loss: 0.0055867 accuracy: 100.0\n",
      "loss: 0.0115896 accuracy: 99.0\n",
      "loss: 0.0109518 accuracy: 100.0\n",
      "loss: 0.00409563 accuracy: 100.0\n",
      "loss: 0.00383555 accuracy: 100.0\n",
      "loss: 0.0100734 accuracy: 100.0\n",
      "loss: 0.0122014 accuracy: 100.0\n",
      "loss: 0.0151702 accuracy: 99.0\n",
      "loss: 0.00850751 accuracy: 100.0\n",
      "loss: 0.0391193 accuracy: 99.0\n",
      "loss: 0.092586 accuracy: 99.0\n",
      "loss: 0.0378858 accuracy: 99.0\n",
      "loss: 0.00938047 accuracy: 100.0\n",
      "loss: 0.0271994 accuracy: 99.0\n",
      "loss: 0.0132829 accuracy: 100.0\n",
      "loss: 0.0207395 accuracy: 99.0\n",
      "loss: 0.00150446 accuracy: 100.0\n",
      "loss: 0.00295199 accuracy: 100.0\n",
      "loss: 0.0159985 accuracy: 99.0\n",
      "loss: 0.0047519 accuracy: 100.0\n",
      "loss: 0.00241159 accuracy: 100.0\n",
      "loss: 0.00411131 accuracy: 100.0\n",
      "loss: 0.00748164 accuracy: 100.0\n",
      "loss: 0.00175303 accuracy: 100.0\n",
      "loss: 0.00226981 accuracy: 100.0\n",
      "loss: 0.0266441 accuracy: 99.0\n",
      "loss: 0.0135224 accuracy: 100.0\n",
      "loss: 0.00704093 accuracy: 100.0\n",
      "loss: 0.0194221 accuracy: 99.0\n",
      "loss: 0.00358877 accuracy: 100.0\n",
      "loss: 0.0239118 accuracy: 99.0\n",
      "loss: 0.0114145 accuracy: 100.0\n",
      "loss: 0.0160602 accuracy: 99.0\n",
      "loss: 0.00648655 accuracy: 100.0\n",
      "loss: 0.00850627 accuracy: 100.0\n",
      "loss: 0.00302923 accuracy: 100.0\n",
      "loss: 0.0049171 accuracy: 100.0\n",
      "loss: 0.0071165 accuracy: 100.0\n",
      "loss: 0.00332956 accuracy: 100.0\n",
      "loss: 0.0127863 accuracy: 99.0\n",
      "loss: 0.0257364 accuracy: 99.0\n",
      "loss: 0.047781 accuracy: 99.0\n",
      "loss: 0.00405948 accuracy: 100.0\n",
      "loss: 0.00245188 accuracy: 100.0\n",
      "loss: 0.0164613 accuracy: 99.0\n",
      "loss: 0.0103124 accuracy: 100.0\n",
      "loss: 0.0576302 accuracy: 99.0\n",
      "loss: 0.0151993 accuracy: 100.0\n",
      "loss: 0.0033312 accuracy: 100.0\n",
      "loss: 0.00482963 accuracy: 100.0\n",
      "loss: 0.0036333 accuracy: 100.0\n",
      "loss: 0.000930149 accuracy: 100.0\n",
      "loss: 0.0150868 accuracy: 99.0\n",
      "loss: 0.00620462 accuracy: 100.0\n",
      "loss: 0.00819077 accuracy: 100.0\n",
      "loss: 0.0108091 accuracy: 100.0\n",
      "loss: 0.00994769 accuracy: 100.0\n",
      "loss: 0.00312282 accuracy: 100.0\n",
      "loss: 0.0182498 accuracy: 99.0\n",
      "loss: 0.00427621 accuracy: 100.0\n",
      "loss: 0.00617787 accuracy: 100.0\n",
      "loss: 0.00562287 accuracy: 100.0\n",
      "loss: 0.00776705 accuracy: 100.0\n",
      "loss: 0.0308463 accuracy: 98.0\n",
      "loss: 0.0178759 accuracy: 99.0\n",
      "loss: 0.0751072 accuracy: 99.0\n",
      "loss: 0.00145466 accuracy: 100.0\n",
      "loss: 0.00972173 accuracy: 100.0\n",
      "loss: 0.0244043 accuracy: 99.0\n",
      "loss: 0.0193646 accuracy: 99.0\n",
      "loss: 0.0129866 accuracy: 99.0\n",
      "loss: 0.00805774 accuracy: 100.0\n",
      "loss: 0.00952356 accuracy: 100.0\n",
      "loss: 0.00221401 accuracy: 100.0\n",
      "loss: 0.027591 accuracy: 99.0\n",
      "loss: 0.000804853 accuracy: 100.0\n",
      "loss: 0.00306125 accuracy: 100.0\n",
      "loss: 0.00480019 accuracy: 100.0\n",
      "loss: 0.0100248 accuracy: 100.0\n",
      "loss: 0.0016355 accuracy: 100.0\n",
      "loss: 0.00166143 accuracy: 100.0\n",
      "loss: 0.0109936 accuracy: 100.0\n",
      "loss: 0.00515921 accuracy: 100.0\n",
      "loss: 0.00739968 accuracy: 100.0\n",
      "loss: 0.00476026 accuracy: 100.0\n",
      "loss: 0.0059553 accuracy: 100.0\n",
      "loss: 0.00604918 accuracy: 100.0\n",
      "loss: 0.00235382 accuracy: 100.0\n",
      "loss: 0.0222293 accuracy: 99.0\n",
      "loss: 0.00496875 accuracy: 100.0\n",
      "loss: 0.0034745 accuracy: 100.0\n",
      "loss: 0.00531054 accuracy: 100.0\n",
      "loss: 0.00119455 accuracy: 100.0\n",
      "loss: 0.00331768 accuracy: 100.0\n",
      "loss: 0.000806513 accuracy: 100.0\n",
      "loss: 0.0173778 accuracy: 99.0\n",
      "loss: 0.0116123 accuracy: 100.0\n",
      "loss: 0.00747369 accuracy: 100.0\n",
      "loss: 0.00429763 accuracy: 100.0\n",
      "loss: 0.00254387 accuracy: 100.0\n",
      "loss: 0.00286193 accuracy: 100.0\n",
      "loss: 0.0219416 accuracy: 99.0\n",
      "loss: 0.00368242 accuracy: 100.0\n",
      ">>>>>>>>>> test dataset accuracy: 97.81\n",
      "loss: 0.00787234 accuracy: 100.0\n",
      "loss: 0.0129172 accuracy: 100.0\n",
      "loss: 0.00275667 accuracy: 100.0\n",
      "loss: 0.00318429 accuracy: 100.0\n",
      "loss: 0.00221346 accuracy: 100.0\n",
      "loss: 0.00103419 accuracy: 100.0\n",
      "loss: 0.00261085 accuracy: 100.0\n",
      "loss: 0.00288391 accuracy: 100.0\n",
      "loss: 0.00851872 accuracy: 100.0\n",
      "loss: 0.00220421 accuracy: 100.0\n",
      "loss: 0.00756806 accuracy: 100.0\n",
      "loss: 0.00494829 accuracy: 100.0\n",
      "loss: 0.0109101 accuracy: 100.0\n",
      "loss: 0.00370883 accuracy: 100.0\n",
      "loss: 0.002119 accuracy: 100.0\n",
      "loss: 0.00127556 accuracy: 100.0\n",
      "loss: 0.0023548 accuracy: 100.0\n",
      "loss: 0.0207683 accuracy: 99.0\n",
      "loss: 0.00466922 accuracy: 100.0\n",
      "loss: 0.00259748 accuracy: 100.0\n",
      "loss: 0.0126239 accuracy: 99.0\n",
      "loss: 0.00127622 accuracy: 100.0\n",
      "loss: 0.0179301 accuracy: 99.0\n",
      "loss: 0.00224708 accuracy: 100.0\n",
      "loss: 0.00229793 accuracy: 100.0\n",
      "loss: 0.00201308 accuracy: 100.0\n",
      "loss: 0.00731113 accuracy: 100.0\n",
      "loss: 0.00312567 accuracy: 100.0\n",
      "loss: 0.00781209 accuracy: 100.0\n",
      "loss: 0.00567442 accuracy: 100.0\n",
      "loss: 0.00208006 accuracy: 100.0\n",
      "loss: 0.00336415 accuracy: 100.0\n",
      "loss: 0.00773187 accuracy: 100.0\n",
      "loss: 0.000652767 accuracy: 100.0\n",
      "loss: 0.00275232 accuracy: 100.0\n",
      "loss: 0.00481224 accuracy: 100.0\n",
      "loss: 0.00748531 accuracy: 100.0\n",
      "loss: 0.00727758 accuracy: 100.0\n",
      "loss: 0.0055805 accuracy: 100.0\n",
      "loss: 0.00180448 accuracy: 100.0\n",
      "loss: 0.0029867 accuracy: 100.0\n",
      "loss: 0.00386887 accuracy: 100.0\n",
      "loss: 0.00267517 accuracy: 100.0\n",
      "loss: 0.0122654 accuracy: 100.0\n",
      "loss: 0.0114005 accuracy: 100.0\n",
      "loss: 0.00411874 accuracy: 100.0\n",
      "loss: 0.0070878 accuracy: 100.0\n",
      "loss: 0.00132608 accuracy: 100.0\n",
      "loss: 0.0045193 accuracy: 100.0\n",
      "loss: 0.00731019 accuracy: 100.0\n",
      "loss: 0.0143697 accuracy: 100.0\n",
      "loss: 0.00357854 accuracy: 100.0\n",
      "loss: 0.00608081 accuracy: 100.0\n",
      "loss: 0.00285274 accuracy: 100.0\n",
      "loss: 0.00229393 accuracy: 100.0\n",
      "loss: 0.0182771 accuracy: 100.0\n",
      "loss: 0.00364541 accuracy: 100.0\n",
      "loss: 0.00274325 accuracy: 100.0\n",
      "loss: 0.00178224 accuracy: 100.0\n",
      "loss: 0.0025461 accuracy: 100.0\n",
      "loss: 0.0021538 accuracy: 100.0\n",
      "loss: 0.00122847 accuracy: 100.0\n",
      "loss: 0.00319673 accuracy: 100.0\n",
      "loss: 0.00464146 accuracy: 100.0\n",
      "loss: 0.00472865 accuracy: 100.0\n",
      "loss: 0.0132259 accuracy: 99.0\n",
      "loss: 0.00420759 accuracy: 100.0\n",
      "loss: 0.000818096 accuracy: 100.0\n",
      "loss: 0.00325542 accuracy: 100.0\n",
      "loss: 0.00430097 accuracy: 100.0\n",
      "loss: 0.00192934 accuracy: 100.0\n",
      "loss: 0.00189591 accuracy: 100.0\n",
      "loss: 0.00611728 accuracy: 100.0\n",
      "loss: 0.0304159 accuracy: 99.0\n",
      "loss: 0.00427765 accuracy: 100.0\n",
      "loss: 0.0734095 accuracy: 99.0\n",
      "loss: 0.00183018 accuracy: 100.0\n",
      "loss: 0.000751171 accuracy: 100.0\n",
      "loss: 0.0108511 accuracy: 100.0\n",
      "loss: 0.0109806 accuracy: 100.0\n",
      "loss: 0.00160481 accuracy: 100.0\n",
      "loss: 0.00400061 accuracy: 100.0\n",
      "loss: 0.00445181 accuracy: 100.0\n",
      "loss: 0.00220405 accuracy: 100.0\n",
      "loss: 0.00224242 accuracy: 100.0\n",
      "loss: 0.00200071 accuracy: 100.0\n",
      "loss: 0.00174246 accuracy: 100.0\n",
      "loss: 0.00387341 accuracy: 100.0\n",
      "loss: 0.00308208 accuracy: 100.0\n",
      "loss: 0.00394818 accuracy: 100.0\n",
      "loss: 0.00134786 accuracy: 100.0\n",
      "loss: 0.00199316 accuracy: 100.0\n",
      "loss: 0.00515615 accuracy: 100.0\n",
      "loss: 0.0039867 accuracy: 100.0\n",
      "loss: 0.0165349 accuracy: 99.0\n",
      "loss: 0.000747187 accuracy: 100.0\n",
      "loss: 0.00439194 accuracy: 100.0\n",
      "loss: 0.00244506 accuracy: 100.0\n",
      "loss: 0.00354303 accuracy: 100.0\n",
      "loss: 0.00454458 accuracy: 100.0\n",
      "loss: 0.00110567 accuracy: 100.0\n",
      "loss: 0.00566922 accuracy: 100.0\n",
      "loss: 0.008276 accuracy: 100.0\n",
      "loss: 0.0165256 accuracy: 99.0\n",
      "loss: 0.00253355 accuracy: 100.0\n",
      "loss: 0.00823551 accuracy: 100.0\n",
      "loss: 0.00438588 accuracy: 100.0\n",
      "loss: 0.00353386 accuracy: 100.0\n",
      "loss: 0.000936444 accuracy: 100.0\n",
      "loss: 0.00436377 accuracy: 100.0\n",
      "loss: 0.0103425 accuracy: 100.0\n",
      "loss: 0.00157617 accuracy: 100.0\n",
      "loss: 0.00117339 accuracy: 100.0\n",
      "loss: 0.00431135 accuracy: 100.0\n",
      "loss: 0.00710503 accuracy: 100.0\n",
      "loss: 0.00232907 accuracy: 100.0\n",
      "loss: 0.00428698 accuracy: 100.0\n",
      "loss: 0.0108177 accuracy: 100.0\n",
      "loss: 0.00611168 accuracy: 100.0\n",
      "loss: 0.00133468 accuracy: 100.0\n",
      "loss: 0.00453805 accuracy: 100.0\n",
      "loss: 0.0047575 accuracy: 100.0\n",
      "loss: 0.0163933 accuracy: 99.0\n",
      "loss: 0.00267038 accuracy: 100.0\n",
      "loss: 0.00990963 accuracy: 100.0\n",
      "loss: 0.00493972 accuracy: 100.0\n",
      "loss: 0.00383929 accuracy: 100.0\n",
      "loss: 0.00603117 accuracy: 100.0\n",
      "loss: 0.00469466 accuracy: 100.0\n",
      "loss: 0.00153717 accuracy: 100.0\n",
      "loss: 0.03023 accuracy: 99.0\n",
      "loss: 0.00427602 accuracy: 100.0\n",
      "loss: 0.00667196 accuracy: 100.0\n",
      "loss: 0.00476429 accuracy: 100.0\n",
      "loss: 0.00148848 accuracy: 100.0\n",
      "loss: 0.00207271 accuracy: 100.0\n",
      "loss: 0.00124374 accuracy: 100.0\n",
      "loss: 0.00852863 accuracy: 100.0\n",
      "loss: 0.00907794 accuracy: 100.0\n",
      "loss: 0.00279275 accuracy: 100.0\n",
      "loss: 0.00986658 accuracy: 100.0\n",
      "loss: 0.00454391 accuracy: 100.0\n",
      "loss: 0.0105646 accuracy: 100.0\n",
      "loss: 0.00430489 accuracy: 100.0\n",
      "loss: 0.00205453 accuracy: 100.0\n",
      "loss: 0.00160856 accuracy: 100.0\n",
      "loss: 0.0017139 accuracy: 100.0\n",
      "loss: 0.00180592 accuracy: 100.0\n",
      "loss: 0.0027664 accuracy: 100.0\n",
      "loss: 0.00531833 accuracy: 100.0\n",
      "loss: 0.0017251 accuracy: 100.0\n",
      "loss: 0.0072793 accuracy: 100.0\n",
      "loss: 0.001786 accuracy: 100.0\n",
      "loss: 0.00165286 accuracy: 100.0\n",
      "loss: 0.000623618 accuracy: 100.0\n",
      "loss: 0.0110603 accuracy: 100.0\n",
      "loss: 0.00261768 accuracy: 100.0\n",
      "loss: 0.00597691 accuracy: 100.0\n",
      "loss: 0.00904474 accuracy: 100.0\n",
      "loss: 0.0014795 accuracy: 100.0\n",
      "loss: 0.00216761 accuracy: 100.0\n",
      "loss: 0.00484419 accuracy: 100.0\n",
      "loss: 0.00378349 accuracy: 100.0\n",
      "loss: 0.00455217 accuracy: 100.0\n",
      "loss: 0.00829753 accuracy: 100.0\n",
      "loss: 0.00231271 accuracy: 100.0\n",
      "loss: 0.00179743 accuracy: 100.0\n",
      "loss: 0.00218276 accuracy: 100.0\n",
      "loss: 0.00559048 accuracy: 100.0\n",
      "loss: 0.00175809 accuracy: 100.0\n",
      "loss: 0.00137073 accuracy: 100.0\n",
      "loss: 0.00590267 accuracy: 100.0\n",
      "loss: 0.00280131 accuracy: 100.0\n",
      "loss: 0.00922835 accuracy: 100.0\n",
      "loss: 0.00210769 accuracy: 100.0\n",
      "loss: 0.00370034 accuracy: 100.0\n",
      "loss: 0.0173785 accuracy: 99.0\n",
      "loss: 0.0284253 accuracy: 98.0\n",
      "loss: 0.00551808 accuracy: 100.0\n",
      "loss: 0.00197674 accuracy: 100.0\n",
      "loss: 0.00991392 accuracy: 100.0\n",
      "loss: 0.00502557 accuracy: 100.0\n",
      "loss: 0.00116203 accuracy: 100.0\n",
      "loss: 0.00418463 accuracy: 100.0\n",
      "loss: 0.00102299 accuracy: 100.0\n",
      "loss: 0.00379915 accuracy: 100.0\n",
      "loss: 0.00283718 accuracy: 100.0\n",
      "loss: 0.00399907 accuracy: 100.0\n",
      "loss: 0.00218525 accuracy: 100.0\n",
      "loss: 0.0027624 accuracy: 100.0\n",
      "loss: 0.0100213 accuracy: 100.0\n",
      "loss: 0.00483726 accuracy: 100.0\n",
      "loss: 0.0503459 accuracy: 98.0\n",
      "loss: 0.0109879 accuracy: 100.0\n",
      "loss: 0.00522828 accuracy: 100.0\n",
      "loss: 0.00123226 accuracy: 100.0\n",
      "loss: 0.00780562 accuracy: 100.0\n",
      "loss: 0.00321116 accuracy: 100.0\n",
      "loss: 0.00116608 accuracy: 100.0\n",
      "loss: 0.00446206 accuracy: 100.0\n",
      "loss: 0.00394735 accuracy: 100.0\n",
      "loss: 0.00399844 accuracy: 100.0\n",
      "loss: 0.0176256 accuracy: 99.0\n",
      "loss: 0.00191254 accuracy: 100.0\n",
      "loss: 0.00547967 accuracy: 100.0\n",
      "loss: 0.00328093 accuracy: 100.0\n",
      "loss: 0.00275282 accuracy: 100.0\n",
      "loss: 0.00291299 accuracy: 100.0\n",
      "loss: 0.00327802 accuracy: 100.0\n",
      "loss: 0.00178585 accuracy: 100.0\n",
      "loss: 0.00112909 accuracy: 100.0\n",
      "loss: 0.006485 accuracy: 100.0\n",
      "loss: 0.00365957 accuracy: 100.0\n",
      "loss: 0.0093445 accuracy: 100.0\n",
      "loss: 0.00290207 accuracy: 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000718759 accuracy: 100.0\n",
      "loss: 0.00322428 accuracy: 100.0\n",
      "loss: 0.00181229 accuracy: 100.0\n",
      "loss: 0.00269326 accuracy: 100.0\n",
      "loss: 0.0165147 accuracy: 99.0\n",
      "loss: 0.00206951 accuracy: 100.0\n",
      "loss: 0.00299031 accuracy: 100.0\n",
      "loss: 0.0131077 accuracy: 99.0\n",
      "loss: 0.00677846 accuracy: 100.0\n",
      "loss: 0.00217927 accuracy: 100.0\n",
      "loss: 0.00865421 accuracy: 100.0\n",
      "loss: 0.00382133 accuracy: 100.0\n",
      "loss: 0.00231352 accuracy: 100.0\n",
      "loss: 0.00729025 accuracy: 100.0\n",
      "loss: 0.00658436 accuracy: 100.0\n",
      "loss: 0.00264717 accuracy: 100.0\n",
      "loss: 0.011623 accuracy: 99.0\n",
      "loss: 0.00386966 accuracy: 100.0\n",
      "loss: 0.00508892 accuracy: 100.0\n",
      "loss: 0.00675401 accuracy: 100.0\n",
      "loss: 0.002195 accuracy: 100.0\n",
      "loss: 0.00440722 accuracy: 100.0\n",
      "loss: 0.00324471 accuracy: 100.0\n",
      "loss: 0.00190213 accuracy: 100.0\n",
      "loss: 0.00409757 accuracy: 100.0\n",
      "loss: 0.0112602 accuracy: 100.0\n",
      "loss: 0.00207192 accuracy: 100.0\n",
      "loss: 0.00197174 accuracy: 100.0\n",
      "loss: 0.00404318 accuracy: 100.0\n",
      "loss: 0.00838116 accuracy: 100.0\n",
      "loss: 0.00204311 accuracy: 100.0\n",
      "loss: 0.00294177 accuracy: 100.0\n",
      "loss: 0.00176702 accuracy: 100.0\n",
      "loss: 0.00162926 accuracy: 100.0\n",
      "loss: 0.00588102 accuracy: 100.0\n",
      "loss: 0.0031628 accuracy: 100.0\n",
      "loss: 0.00204673 accuracy: 100.0\n",
      "loss: 0.00243245 accuracy: 100.0\n",
      "loss: 0.00150177 accuracy: 100.0\n",
      "loss: 0.000773064 accuracy: 100.0\n",
      "loss: 0.00358976 accuracy: 100.0\n",
      "loss: 0.00204271 accuracy: 100.0\n",
      "loss: 0.00323684 accuracy: 100.0\n",
      "loss: 0.00405252 accuracy: 100.0\n",
      "loss: 0.00359215 accuracy: 100.0\n",
      "loss: 0.0125808 accuracy: 100.0\n",
      "loss: 0.00771308 accuracy: 100.0\n",
      "loss: 0.00427564 accuracy: 100.0\n",
      "loss: 0.00079155 accuracy: 100.0\n",
      "loss: 0.00594132 accuracy: 100.0\n",
      "loss: 0.00455163 accuracy: 100.0\n",
      "loss: 0.00177987 accuracy: 100.0\n",
      "loss: 0.00134125 accuracy: 100.0\n",
      "loss: 0.0017271 accuracy: 100.0\n",
      "loss: 0.00188134 accuracy: 100.0\n",
      "loss: 0.00999079 accuracy: 99.0\n",
      "loss: 0.00618027 accuracy: 100.0\n",
      "loss: 0.00864655 accuracy: 100.0\n",
      "loss: 0.00180743 accuracy: 100.0\n",
      "loss: 0.00282551 accuracy: 100.0\n",
      "loss: 0.0181709 accuracy: 99.0\n",
      "loss: 0.00887731 accuracy: 100.0\n",
      "loss: 0.00422186 accuracy: 100.0\n",
      "loss: 0.00389729 accuracy: 100.0\n",
      "loss: 0.00173188 accuracy: 100.0\n",
      "loss: 0.00707431 accuracy: 100.0\n",
      "loss: 0.00437914 accuracy: 100.0\n",
      "loss: 0.00142618 accuracy: 100.0\n",
      "loss: 0.00325427 accuracy: 100.0\n",
      "loss: 0.0025804 accuracy: 100.0\n",
      "loss: 0.000437614 accuracy: 100.0\n",
      "loss: 0.00172736 accuracy: 100.0\n",
      "loss: 0.00478533 accuracy: 100.0\n",
      "loss: 0.00559291 accuracy: 100.0\n",
      "loss: 0.0113798 accuracy: 99.0\n",
      "loss: 0.00402204 accuracy: 100.0\n",
      "loss: 0.00316289 accuracy: 100.0\n",
      "loss: 0.00634664 accuracy: 100.0\n",
      "loss: 0.0460796 accuracy: 99.0\n",
      "loss: 0.00342893 accuracy: 100.0\n",
      "loss: 0.00239594 accuracy: 100.0\n",
      "loss: 0.00106802 accuracy: 100.0\n",
      "loss: 0.00269336 accuracy: 100.0\n",
      "loss: 0.00420594 accuracy: 100.0\n",
      "loss: 0.000694438 accuracy: 100.0\n",
      "loss: 0.00203284 accuracy: 100.0\n",
      "loss: 0.000725232 accuracy: 100.0\n",
      "loss: 0.00304494 accuracy: 100.0\n",
      "loss: 0.0023075 accuracy: 100.0\n",
      "loss: 0.00223948 accuracy: 100.0\n",
      "loss: 0.00301845 accuracy: 100.0\n",
      "loss: 0.00182905 accuracy: 100.0\n",
      "loss: 0.00508459 accuracy: 100.0\n",
      "loss: 0.00188845 accuracy: 100.0\n",
      "loss: 0.00366522 accuracy: 100.0\n",
      "loss: 0.00150452 accuracy: 100.0\n",
      "loss: 0.00169477 accuracy: 100.0\n",
      "loss: 0.00264326 accuracy: 100.0\n",
      "loss: 0.00805132 accuracy: 100.0\n",
      "loss: 0.00138053 accuracy: 100.0\n",
      "loss: 0.00300026 accuracy: 100.0\n",
      "loss: 0.00067173 accuracy: 100.0\n",
      "loss: 0.0010519 accuracy: 100.0\n",
      "loss: 0.00286802 accuracy: 100.0\n",
      "loss: 0.00788968 accuracy: 100.0\n",
      "loss: 0.00836058 accuracy: 100.0\n",
      "loss: 0.00273562 accuracy: 100.0\n",
      "loss: 0.00188084 accuracy: 100.0\n",
      "loss: 0.0171906 accuracy: 99.0\n",
      "loss: 0.00890181 accuracy: 100.0\n",
      "loss: 0.00601856 accuracy: 100.0\n",
      "loss: 0.00191079 accuracy: 100.0\n",
      "loss: 0.011253 accuracy: 100.0\n",
      "loss: 0.00145919 accuracy: 100.0\n",
      "loss: 0.0051562 accuracy: 100.0\n",
      "loss: 0.0047511 accuracy: 100.0\n",
      "loss: 0.0013463 accuracy: 100.0\n",
      "loss: 0.00103019 accuracy: 100.0\n",
      "loss: 0.00267526 accuracy: 100.0\n",
      "loss: 0.0279849 accuracy: 99.0\n",
      "loss: 0.00179682 accuracy: 100.0\n",
      "loss: 0.00218178 accuracy: 100.0\n",
      "loss: 0.00577654 accuracy: 100.0\n",
      "loss: 0.00398879 accuracy: 100.0\n",
      "loss: 0.00356347 accuracy: 100.0\n",
      "loss: 0.00765583 accuracy: 100.0\n",
      "loss: 0.00629442 accuracy: 100.0\n",
      "loss: 0.00189649 accuracy: 100.0\n",
      "loss: 0.00439288 accuracy: 100.0\n",
      "loss: 0.0270868 accuracy: 99.0\n",
      "loss: 0.00597909 accuracy: 100.0\n",
      "loss: 0.000968146 accuracy: 100.0\n",
      "loss: 0.0115863 accuracy: 99.0\n",
      "loss: 0.0076805 accuracy: 100.0\n",
      "loss: 0.00748942 accuracy: 100.0\n",
      "loss: 0.00500562 accuracy: 100.0\n",
      "loss: 0.00324634 accuracy: 100.0\n",
      "loss: 0.00238692 accuracy: 100.0\n",
      "loss: 0.00376246 accuracy: 100.0\n",
      "loss: 0.00206226 accuracy: 100.0\n",
      "loss: 0.00210172 accuracy: 100.0\n",
      "loss: 0.0101121 accuracy: 100.0\n",
      "loss: 0.00775316 accuracy: 100.0\n",
      "loss: 0.00278166 accuracy: 100.0\n",
      "loss: 0.00284778 accuracy: 100.0\n",
      "loss: 0.00281659 accuracy: 100.0\n",
      "loss: 0.00789511 accuracy: 100.0\n",
      "loss: 0.00238905 accuracy: 100.0\n",
      "loss: 0.000414277 accuracy: 100.0\n",
      "loss: 0.00191719 accuracy: 100.0\n",
      "loss: 0.00161959 accuracy: 100.0\n",
      "loss: 0.00310455 accuracy: 100.0\n",
      "loss: 0.00341729 accuracy: 100.0\n",
      "loss: 0.00426639 accuracy: 100.0\n",
      "loss: 0.00320641 accuracy: 100.0\n",
      "loss: 0.0020738 accuracy: 100.0\n",
      "loss: 0.00230224 accuracy: 100.0\n",
      "loss: 0.00257821 accuracy: 100.0\n",
      "loss: 0.00775272 accuracy: 100.0\n",
      "loss: 0.00056834 accuracy: 100.0\n",
      "loss: 0.00374516 accuracy: 100.0\n",
      "loss: 0.0114613 accuracy: 99.0\n",
      "loss: 0.010009 accuracy: 100.0\n",
      "loss: 0.00908003 accuracy: 100.0\n",
      "loss: 0.0141324 accuracy: 99.0\n",
      "loss: 0.00259852 accuracy: 100.0\n",
      "loss: 0.00821994 accuracy: 100.0\n",
      "loss: 0.00358059 accuracy: 100.0\n",
      "loss: 0.00827211 accuracy: 100.0\n",
      "loss: 0.00317249 accuracy: 100.0\n",
      "loss: 0.0125728 accuracy: 99.0\n",
      "loss: 0.00686376 accuracy: 100.0\n",
      "loss: 0.00238919 accuracy: 100.0\n",
      "loss: 0.00556725 accuracy: 100.0\n",
      "loss: 0.00335727 accuracy: 100.0\n",
      "loss: 0.0902089 accuracy: 99.0\n",
      "loss: 0.00129606 accuracy: 100.0\n",
      "loss: 0.00125313 accuracy: 100.0\n",
      "loss: 0.000754701 accuracy: 100.0\n",
      "loss: 0.00755424 accuracy: 100.0\n",
      "loss: 0.0117685 accuracy: 100.0\n",
      "loss: 0.00130679 accuracy: 100.0\n",
      "loss: 0.00114306 accuracy: 100.0\n",
      "loss: 0.0118182 accuracy: 99.0\n",
      "loss: 0.0104245 accuracy: 100.0\n",
      "loss: 0.00145461 accuracy: 100.0\n",
      "loss: 0.00351467 accuracy: 100.0\n",
      "loss: 0.00385188 accuracy: 100.0\n",
      "loss: 0.00225239 accuracy: 100.0\n",
      "loss: 0.00212243 accuracy: 100.0\n",
      "loss: 0.00724343 accuracy: 100.0\n",
      "loss: 0.00295602 accuracy: 100.0\n",
      "loss: 0.00157418 accuracy: 100.0\n",
      "loss: 0.00426638 accuracy: 100.0\n",
      "loss: 0.00530268 accuracy: 100.0\n",
      "loss: 0.00899813 accuracy: 100.0\n",
      "loss: 0.00357434 accuracy: 100.0\n",
      "loss: 0.0025364 accuracy: 100.0\n",
      "loss: 0.0014464 accuracy: 100.0\n",
      "loss: 0.00304386 accuracy: 100.0\n",
      "loss: 0.00497059 accuracy: 100.0\n",
      "loss: 0.00604047 accuracy: 100.0\n",
      "loss: 0.0043517 accuracy: 100.0\n",
      "loss: 0.00213655 accuracy: 100.0\n",
      "loss: 0.00444295 accuracy: 100.0\n",
      "loss: 0.0048971 accuracy: 100.0\n",
      "loss: 0.0059238 accuracy: 100.0\n",
      "loss: 0.0308268 accuracy: 99.0\n",
      "loss: 0.0030773 accuracy: 100.0\n",
      "loss: 0.00157206 accuracy: 100.0\n",
      "loss: 0.0062845 accuracy: 100.0\n",
      "loss: 0.0103322 accuracy: 100.0\n",
      "loss: 0.00773915 accuracy: 100.0\n",
      "loss: 0.00565143 accuracy: 100.0\n",
      "loss: 0.00260265 accuracy: 100.0\n",
      "loss: 0.00834145 accuracy: 100.0\n",
      "loss: 0.0708182 accuracy: 99.0\n",
      "loss: 0.000998722 accuracy: 100.0\n",
      "loss: 0.0027595 accuracy: 100.0\n",
      "loss: 0.00532892 accuracy: 100.0\n",
      "loss: 0.00373447 accuracy: 100.0\n",
      "loss: 0.0075641 accuracy: 100.0\n",
      "loss: 0.00226701 accuracy: 100.0\n",
      "loss: 0.0045194 accuracy: 100.0\n",
      "loss: 0.00111482 accuracy: 100.0\n",
      "loss: 0.00164467 accuracy: 100.0\n",
      "loss: 0.00285797 accuracy: 100.0\n",
      "loss: 0.0064762 accuracy: 100.0\n",
      "loss: 0.0047111 accuracy: 100.0\n",
      "loss: 0.00146595 accuracy: 100.0\n",
      "loss: 0.00388545 accuracy: 100.0\n",
      "loss: 0.00638524 accuracy: 100.0\n",
      "loss: 0.00195225 accuracy: 100.0\n",
      "loss: 0.00547112 accuracy: 100.0\n",
      "loss: 0.000601743 accuracy: 100.0\n",
      "loss: 0.00307284 accuracy: 100.0\n",
      "loss: 0.0103846 accuracy: 100.0\n",
      "loss: 0.000927583 accuracy: 100.0\n",
      "loss: 0.00227734 accuracy: 100.0\n",
      "loss: 0.00297414 accuracy: 100.0\n",
      "loss: 0.00653317 accuracy: 100.0\n",
      "loss: 0.0032119 accuracy: 100.0\n",
      "loss: 0.0089627 accuracy: 100.0\n",
      "loss: 0.00763731 accuracy: 100.0\n",
      "loss: 0.000486758 accuracy: 100.0\n",
      "loss: 0.00153348 accuracy: 100.0\n",
      "loss: 0.0025486 accuracy: 100.0\n",
      "loss: 0.000621807 accuracy: 100.0\n",
      "loss: 0.00455493 accuracy: 100.0\n",
      "loss: 0.00490857 accuracy: 100.0\n",
      "loss: 0.00403934 accuracy: 100.0\n",
      "loss: 0.048534 accuracy: 99.0\n",
      "loss: 0.0100364 accuracy: 100.0\n",
      "loss: 0.00176346 accuracy: 100.0\n",
      "loss: 0.00295554 accuracy: 100.0\n",
      "loss: 0.00770575 accuracy: 100.0\n",
      "loss: 0.00312566 accuracy: 100.0\n",
      "loss: 0.0291996 accuracy: 99.0\n",
      "loss: 0.0053109 accuracy: 100.0\n",
      "loss: 0.00253347 accuracy: 100.0\n",
      "loss: 0.0230417 accuracy: 99.0\n",
      "loss: 0.0217678 accuracy: 99.0\n",
      "loss: 0.00451731 accuracy: 100.0\n",
      "loss: 0.0497024 accuracy: 99.0\n",
      "loss: 0.00736016 accuracy: 100.0\n",
      "loss: 0.00158799 accuracy: 100.0\n",
      "loss: 0.00547195 accuracy: 100.0\n",
      "loss: 0.00215705 accuracy: 100.0\n",
      "loss: 0.00415819 accuracy: 100.0\n",
      "loss: 0.00385521 accuracy: 100.0\n",
      "loss: 0.00318799 accuracy: 100.0\n",
      "loss: 0.000980121 accuracy: 100.0\n",
      "loss: 0.00217275 accuracy: 100.0\n",
      "loss: 0.00697648 accuracy: 100.0\n",
      "loss: 0.000749419 accuracy: 100.0\n",
      "loss: 0.00318088 accuracy: 100.0\n",
      "loss: 0.010422 accuracy: 100.0\n",
      "loss: 0.00133989 accuracy: 100.0\n",
      "loss: 0.0132213 accuracy: 100.0\n",
      "loss: 0.00131461 accuracy: 100.0\n",
      "loss: 0.00887487 accuracy: 100.0\n",
      "loss: 0.00281048 accuracy: 100.0\n",
      "loss: 0.00683454 accuracy: 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00373367 accuracy: 100.0\n",
      "loss: 0.00141464 accuracy: 100.0\n",
      "loss: 0.00032573 accuracy: 100.0\n",
      "loss: 0.00157615 accuracy: 100.0\n",
      "loss: 0.00152779 accuracy: 100.0\n",
      "loss: 0.00645663 accuracy: 100.0\n",
      "loss: 0.00111038 accuracy: 100.0\n",
      "loss: 0.00718164 accuracy: 100.0\n",
      "loss: 0.00294254 accuracy: 100.0\n",
      "loss: 0.00569331 accuracy: 100.0\n",
      "loss: 0.00120978 accuracy: 100.0\n",
      "loss: 0.00481159 accuracy: 100.0\n",
      "loss: 0.00980274 accuracy: 100.0\n",
      "loss: 0.000817407 accuracy: 100.0\n",
      "loss: 0.00924475 accuracy: 100.0\n",
      "loss: 0.00347821 accuracy: 100.0\n",
      "loss: 0.0106965 accuracy: 99.0\n",
      "loss: 0.0158682 accuracy: 99.0\n",
      "loss: 0.00396815 accuracy: 100.0\n",
      "loss: 0.000976906 accuracy: 100.0\n",
      "loss: 0.00127462 accuracy: 100.0\n",
      "loss: 0.00537688 accuracy: 100.0\n",
      "loss: 0.00275509 accuracy: 100.0\n",
      "loss: 0.00819595 accuracy: 100.0\n",
      "loss: 0.00593324 accuracy: 100.0\n",
      "loss: 0.030322 accuracy: 99.0\n",
      "loss: 0.00828513 accuracy: 100.0\n",
      "loss: 0.00286803 accuracy: 100.0\n",
      "loss: 0.00796134 accuracy: 100.0\n",
      "loss: 0.00934699 accuracy: 100.0\n",
      "loss: 0.0329569 accuracy: 99.0\n",
      "loss: 0.00253038 accuracy: 100.0\n",
      "loss: 0.00527913 accuracy: 100.0\n",
      "loss: 0.00204968 accuracy: 100.0\n",
      "loss: 0.0015933 accuracy: 100.0\n",
      "loss: 0.0183371 accuracy: 99.0\n",
      "loss: 0.00645948 accuracy: 100.0\n",
      "loss: 0.00388489 accuracy: 100.0\n",
      "loss: 0.00393754 accuracy: 100.0\n",
      "loss: 0.00594579 accuracy: 100.0\n",
      "loss: 0.0216769 accuracy: 98.0\n",
      "loss: 0.000604139 accuracy: 100.0\n",
      "loss: 0.0222297 accuracy: 99.0\n",
      "loss: 0.011084 accuracy: 100.0\n",
      "loss: 0.00965806 accuracy: 100.0\n",
      "loss: 0.00413512 accuracy: 100.0\n",
      "loss: 0.00532579 accuracy: 100.0\n",
      "loss: 0.00196258 accuracy: 100.0\n",
      "loss: 0.00131635 accuracy: 100.0\n",
      "loss: 0.00966222 accuracy: 100.0\n",
      "loss: 0.000351592 accuracy: 100.0\n",
      ">>>>>>>>>> test dataset accuracy: 98.02\n",
      "loss: 0.0625478 accuracy: 99.0\n",
      "loss: 0.0013266 accuracy: 100.0\n",
      "loss: 0.00226889 accuracy: 100.0\n",
      "loss: 0.00235059 accuracy: 100.0\n",
      "loss: 0.00302895 accuracy: 100.0\n",
      "loss: 0.002074 accuracy: 100.0\n",
      "loss: 0.00134426 accuracy: 100.0\n",
      "loss: 0.00354852 accuracy: 100.0\n",
      "loss: 0.00178987 accuracy: 100.0\n",
      "loss: 0.0030909 accuracy: 100.0\n",
      "loss: 0.000940508 accuracy: 100.0\n",
      "loss: 0.000752026 accuracy: 100.0\n",
      "loss: 0.00139789 accuracy: 100.0\n",
      "loss: 0.00313228 accuracy: 100.0\n",
      "loss: 0.00466724 accuracy: 100.0\n",
      "loss: 0.0140411 accuracy: 99.0\n",
      "loss: 0.00153623 accuracy: 100.0\n",
      "loss: 0.0031338 accuracy: 100.0\n",
      "loss: 0.00218074 accuracy: 100.0\n",
      "loss: 0.00121987 accuracy: 100.0\n",
      "loss: 0.0177658 accuracy: 99.0\n",
      "loss: 0.00215041 accuracy: 100.0\n",
      "loss: 0.014389 accuracy: 99.0\n",
      "loss: 0.00186174 accuracy: 100.0\n",
      "loss: 0.00242969 accuracy: 100.0\n",
      "loss: 0.00163691 accuracy: 100.0\n",
      "loss: 0.00378738 accuracy: 100.0\n",
      "loss: 0.00106896 accuracy: 100.0\n",
      "loss: 0.0128801 accuracy: 99.0\n",
      "loss: 0.00156518 accuracy: 100.0\n",
      "loss: 0.00320812 accuracy: 100.0\n",
      "loss: 0.00200745 accuracy: 100.0\n",
      "loss: 0.000968905 accuracy: 100.0\n",
      "loss: 0.00256859 accuracy: 100.0\n",
      "loss: 0.00940473 accuracy: 99.0\n",
      "loss: 0.00382334 accuracy: 100.0\n",
      "loss: 0.00173772 accuracy: 100.0\n",
      "loss: 0.00498158 accuracy: 100.0\n",
      "loss: 0.00128361 accuracy: 100.0\n",
      "loss: 0.00827704 accuracy: 100.0\n",
      "loss: 0.00184066 accuracy: 100.0\n",
      "loss: 0.00050733 accuracy: 100.0\n",
      "loss: 0.00335572 accuracy: 100.0\n",
      "loss: 0.00240023 accuracy: 100.0\n",
      "loss: 0.00286375 accuracy: 100.0\n",
      "loss: 0.000678314 accuracy: 100.0\n",
      "loss: 0.00542392 accuracy: 100.0\n",
      "loss: 0.00717697 accuracy: 100.0\n",
      "loss: 0.00597262 accuracy: 100.0\n",
      "loss: 0.002343 accuracy: 100.0\n",
      "loss: 0.00273971 accuracy: 100.0\n",
      "loss: 0.00125985 accuracy: 100.0\n",
      "loss: 0.00098745 accuracy: 100.0\n",
      "loss: 0.00202783 accuracy: 100.0\n",
      "loss: 0.0033174 accuracy: 100.0\n",
      "loss: 0.00238958 accuracy: 100.0\n",
      "loss: 0.00149128 accuracy: 100.0\n",
      "loss: 0.00414707 accuracy: 100.0\n",
      "loss: 0.000629927 accuracy: 100.0\n",
      "loss: 0.00545768 accuracy: 100.0\n",
      "loss: 0.0016593 accuracy: 100.0\n",
      "loss: 0.00181008 accuracy: 100.0\n",
      "loss: 0.000742544 accuracy: 100.0\n",
      "loss: 0.00105684 accuracy: 100.0\n",
      "loss: 0.00135707 accuracy: 100.0\n",
      "loss: 0.00180086 accuracy: 100.0\n",
      "loss: 0.00365879 accuracy: 100.0\n",
      "loss: 0.00358874 accuracy: 100.0\n",
      "loss: 0.0011183 accuracy: 100.0\n",
      "loss: 0.00100124 accuracy: 100.0\n",
      "loss: 0.00240181 accuracy: 100.0\n",
      "loss: 0.00255889 accuracy: 100.0\n",
      "loss: 0.000473771 accuracy: 100.0\n",
      "loss: 0.000925431 accuracy: 100.0\n",
      "loss: 0.00133234 accuracy: 100.0\n",
      "loss: 0.00302078 accuracy: 100.0\n",
      "loss: 0.00149119 accuracy: 100.0\n",
      "loss: 0.00248169 accuracy: 100.0\n",
      "loss: 0.00746449 accuracy: 100.0\n",
      "loss: 0.00235589 accuracy: 100.0\n",
      "loss: 0.001453 accuracy: 100.0\n",
      "loss: 0.00409997 accuracy: 100.0\n",
      "loss: 0.00341879 accuracy: 100.0\n",
      "loss: 0.00152411 accuracy: 100.0\n",
      "loss: 0.00140786 accuracy: 100.0\n",
      "loss: 0.0014753 accuracy: 100.0\n",
      "loss: 0.00244003 accuracy: 100.0\n",
      "loss: 0.00111561 accuracy: 100.0\n",
      "loss: 0.00093814 accuracy: 100.0\n",
      "loss: 0.00246866 accuracy: 100.0\n",
      "loss: 0.000947805 accuracy: 100.0\n",
      "loss: 0.00303576 accuracy: 100.0\n",
      "loss: 0.00491176 accuracy: 100.0\n",
      "loss: 0.00181907 accuracy: 100.0\n",
      "loss: 0.000775002 accuracy: 100.0\n",
      "loss: 0.00162609 accuracy: 100.0\n",
      "loss: 0.00120866 accuracy: 100.0\n",
      "loss: 0.00306124 accuracy: 100.0\n",
      "loss: 0.00149387 accuracy: 100.0\n",
      "loss: 0.00132543 accuracy: 100.0\n",
      "loss: 0.000584457 accuracy: 100.0\n",
      "loss: 0.00269701 accuracy: 100.0\n",
      "loss: 0.00168798 accuracy: 100.0\n",
      "loss: 0.000891083 accuracy: 100.0\n",
      "loss: 0.00123775 accuracy: 100.0\n",
      "loss: 0.00183502 accuracy: 100.0\n",
      "loss: 0.00357736 accuracy: 100.0\n",
      "loss: 0.00101026 accuracy: 100.0\n",
      "loss: 0.00239577 accuracy: 100.0\n",
      "loss: 0.00717586 accuracy: 100.0\n",
      "loss: 0.000838034 accuracy: 100.0\n",
      "loss: 0.0012926 accuracy: 100.0\n",
      "loss: 0.00102991 accuracy: 100.0\n",
      "loss: 0.00195603 accuracy: 100.0\n",
      "loss: 0.00190207 accuracy: 100.0\n",
      "loss: 0.00102717 accuracy: 100.0\n",
      "loss: 0.00148419 accuracy: 100.0\n",
      "loss: 0.000848328 accuracy: 100.0\n",
      "loss: 0.00462067 accuracy: 100.0\n",
      "loss: 0.00188112 accuracy: 100.0\n",
      "loss: 0.00489088 accuracy: 100.0\n",
      "loss: 0.00292183 accuracy: 100.0\n",
      "loss: 0.00340249 accuracy: 100.0\n",
      "loss: 0.00211495 accuracy: 100.0\n",
      "loss: 0.00231814 accuracy: 100.0\n",
      "loss: 0.00166834 accuracy: 100.0\n",
      "loss: 0.0033325 accuracy: 100.0\n",
      "loss: 0.000821645 accuracy: 100.0\n",
      "loss: 0.00524638 accuracy: 100.0\n",
      "loss: 0.00119921 accuracy: 100.0\n",
      "loss: 0.00172398 accuracy: 100.0\n",
      "loss: 0.00169077 accuracy: 100.0\n",
      "loss: 0.00558861 accuracy: 100.0\n",
      "loss: 0.000786724 accuracy: 100.0\n",
      "loss: 0.00644869 accuracy: 100.0\n",
      "loss: 0.00316517 accuracy: 100.0\n",
      "loss: 0.0054227 accuracy: 100.0\n",
      "loss: 0.0014084 accuracy: 100.0\n",
      "loss: 0.00226553 accuracy: 100.0\n",
      "loss: 0.000976967 accuracy: 100.0\n",
      "loss: 0.00162073 accuracy: 100.0\n",
      "loss: 0.0014831 accuracy: 100.0\n",
      "loss: 0.000958873 accuracy: 100.0\n",
      "loss: 0.00166162 accuracy: 100.0\n",
      "loss: 0.00146941 accuracy: 100.0\n",
      "loss: 0.00261545 accuracy: 100.0\n",
      "loss: 0.000989891 accuracy: 100.0\n",
      "loss: 0.0030411 accuracy: 100.0\n",
      "loss: 0.00300285 accuracy: 100.0\n",
      "loss: 0.00053364 accuracy: 100.0\n",
      "loss: 0.000634908 accuracy: 100.0\n",
      "loss: 0.000793228 accuracy: 100.0\n",
      "loss: 0.00110534 accuracy: 100.0\n",
      "loss: 0.00152125 accuracy: 100.0\n",
      "loss: 0.000877596 accuracy: 100.0\n",
      "loss: 0.00244153 accuracy: 100.0\n",
      "loss: 0.000220894 accuracy: 100.0\n",
      "loss: 0.00131733 accuracy: 100.0\n",
      "loss: 0.0017547 accuracy: 100.0\n",
      "loss: 0.000365298 accuracy: 100.0\n",
      "loss: 0.00131142 accuracy: 100.0\n",
      "loss: 0.00184803 accuracy: 100.0\n",
      "loss: 0.001746 accuracy: 100.0\n",
      "loss: 0.0016482 accuracy: 100.0\n",
      "loss: 0.00306617 accuracy: 100.0\n",
      "loss: 0.00127215 accuracy: 100.0\n",
      "loss: 0.00220644 accuracy: 100.0\n",
      "loss: 0.000760682 accuracy: 100.0\n",
      "loss: 0.0012271 accuracy: 100.0\n",
      "loss: 0.00291609 accuracy: 100.0\n",
      "loss: 0.00122595 accuracy: 100.0\n",
      "loss: 0.00136484 accuracy: 100.0\n",
      "loss: 0.00326868 accuracy: 100.0\n",
      "loss: 0.00379101 accuracy: 100.0\n",
      "loss: 0.00156843 accuracy: 100.0\n",
      "loss: 0.00237999 accuracy: 100.0\n",
      "loss: 0.00238111 accuracy: 100.0\n",
      "loss: 0.0014814 accuracy: 100.0\n",
      "loss: 0.00284138 accuracy: 100.0\n",
      "loss: 0.000375088 accuracy: 100.0\n",
      "loss: 0.00207207 accuracy: 100.0\n",
      "loss: 0.00126697 accuracy: 100.0\n",
      "loss: 0.00285879 accuracy: 100.0\n",
      "loss: 0.00656318 accuracy: 100.0\n",
      "loss: 0.00204211 accuracy: 100.0\n",
      "loss: 0.00240185 accuracy: 100.0\n",
      "loss: 0.00110078 accuracy: 100.0\n",
      "loss: 0.00290016 accuracy: 100.0\n",
      "loss: 0.000926393 accuracy: 100.0\n",
      "loss: 0.00275059 accuracy: 100.0\n",
      "loss: 0.00116462 accuracy: 100.0\n",
      "loss: 0.00800473 accuracy: 100.0\n",
      "loss: 0.00265289 accuracy: 100.0\n",
      "loss: 0.00752116 accuracy: 100.0\n",
      "loss: 0.00181501 accuracy: 100.0\n",
      "loss: 0.000518313 accuracy: 100.0\n",
      "loss: 0.000560138 accuracy: 100.0\n",
      "loss: 0.00314095 accuracy: 100.0\n",
      "loss: 0.010433 accuracy: 99.0\n",
      "loss: 0.00159638 accuracy: 100.0\n",
      "loss: 0.000862664 accuracy: 100.0\n",
      "loss: 0.00249466 accuracy: 100.0\n",
      "loss: 0.00236068 accuracy: 100.0\n",
      "loss: 0.00446338 accuracy: 100.0\n",
      "loss: 0.00124891 accuracy: 100.0\n",
      "loss: 0.000433223 accuracy: 100.0\n",
      "loss: 0.00490994 accuracy: 100.0\n",
      "loss: 0.00138148 accuracy: 100.0\n",
      "loss: 0.00440026 accuracy: 100.0\n",
      "loss: 0.00228062 accuracy: 100.0\n",
      "loss: 0.00839353 accuracy: 99.0\n",
      "loss: 0.00466417 accuracy: 100.0\n",
      "loss: 0.00184739 accuracy: 100.0\n",
      "loss: 0.00111455 accuracy: 100.0\n",
      "loss: 0.00419339 accuracy: 100.0\n",
      "loss: 0.00485552 accuracy: 100.0\n",
      "loss: 0.00464663 accuracy: 100.0\n",
      "loss: 0.00460894 accuracy: 100.0\n",
      "loss: 0.00496207 accuracy: 100.0\n",
      "loss: 0.00159264 accuracy: 100.0\n",
      "loss: 0.00138712 accuracy: 100.0\n",
      "loss: 0.00290514 accuracy: 100.0\n",
      "loss: 0.000776856 accuracy: 100.0\n",
      "loss: 0.00236517 accuracy: 100.0\n",
      "loss: 0.00370124 accuracy: 100.0\n",
      "loss: 0.00108883 accuracy: 100.0\n",
      "loss: 0.000467081 accuracy: 100.0\n",
      "loss: 0.00382628 accuracy: 100.0\n",
      "loss: 0.00142117 accuracy: 100.0\n",
      "loss: 0.00264497 accuracy: 100.0\n",
      "loss: 0.00251055 accuracy: 100.0\n",
      "loss: 0.00606338 accuracy: 100.0\n",
      "loss: 0.0014997 accuracy: 100.0\n",
      "loss: 0.00111209 accuracy: 100.0\n",
      "loss: 0.00290825 accuracy: 100.0\n",
      "loss: 0.00265782 accuracy: 100.0\n",
      "loss: 0.0117194 accuracy: 100.0\n",
      "loss: 0.00225564 accuracy: 100.0\n",
      "loss: 0.00297902 accuracy: 100.0\n",
      "loss: 0.00273905 accuracy: 100.0\n",
      "loss: 0.00292464 accuracy: 100.0\n",
      "loss: 0.000165625 accuracy: 100.0\n",
      "loss: 0.00209615 accuracy: 100.0\n",
      "loss: 0.00186879 accuracy: 100.0\n",
      "loss: 0.00217021 accuracy: 100.0\n",
      "loss: 0.000777181 accuracy: 100.0\n",
      "loss: 0.00182532 accuracy: 100.0\n",
      "loss: 0.00490402 accuracy: 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00167651 accuracy: 100.0\n",
      "loss: 0.00147694 accuracy: 100.0\n",
      "loss: 0.00524344 accuracy: 100.0\n",
      "loss: 0.000835472 accuracy: 100.0\n",
      "loss: 0.00797888 accuracy: 100.0\n",
      "loss: 0.000612926 accuracy: 100.0\n",
      "loss: 0.000572985 accuracy: 100.0\n",
      "loss: 0.00528231 accuracy: 100.0\n",
      "loss: 0.00168807 accuracy: 100.0\n",
      "loss: 0.000466614 accuracy: 100.0\n",
      "loss: 0.000973205 accuracy: 100.0\n",
      "loss: 0.00317956 accuracy: 100.0\n",
      "loss: 0.00478865 accuracy: 100.0\n",
      "loss: 0.0037673 accuracy: 100.0\n",
      "loss: 0.000375706 accuracy: 100.0\n",
      "loss: 0.0031323 accuracy: 100.0\n",
      "loss: 0.00892661 accuracy: 100.0\n",
      "loss: 0.00369967 accuracy: 100.0\n",
      "loss: 0.00188119 accuracy: 100.0\n",
      "loss: 0.000634753 accuracy: 100.0\n",
      "loss: 0.00141561 accuracy: 100.0\n",
      "loss: 0.00334723 accuracy: 100.0\n",
      "loss: 0.00338813 accuracy: 100.0\n",
      "loss: 0.000797698 accuracy: 100.0\n",
      "loss: 0.0016971 accuracy: 100.0\n",
      "loss: 0.00177958 accuracy: 100.0\n",
      "loss: 0.00176983 accuracy: 100.0\n",
      "loss: 0.00356394 accuracy: 100.0\n",
      "loss: 0.00181174 accuracy: 100.0\n",
      "loss: 0.00249829 accuracy: 100.0\n",
      "loss: 0.000732843 accuracy: 100.0\n",
      "loss: 0.000716548 accuracy: 100.0\n",
      "loss: 0.00185833 accuracy: 100.0\n",
      "loss: 0.00207219 accuracy: 100.0\n",
      "loss: 0.00126708 accuracy: 100.0\n",
      "loss: 0.00193854 accuracy: 100.0\n",
      "loss: 0.00153873 accuracy: 100.0\n",
      "loss: 0.00327135 accuracy: 100.0\n",
      "loss: 0.00132955 accuracy: 100.0\n",
      "loss: 0.00104383 accuracy: 100.0\n",
      "loss: 0.000919416 accuracy: 100.0\n",
      "loss: 0.000908555 accuracy: 100.0\n",
      "loss: 0.00176561 accuracy: 100.0\n",
      "loss: 0.00397886 accuracy: 100.0\n",
      "loss: 0.00184383 accuracy: 100.0\n",
      "loss: 0.000758739 accuracy: 100.0\n",
      "loss: 0.00150484 accuracy: 100.0\n",
      "loss: 0.00174664 accuracy: 100.0\n",
      "loss: 0.00310485 accuracy: 100.0\n",
      "loss: 0.00196449 accuracy: 100.0\n",
      "loss: 0.00256942 accuracy: 100.0\n",
      "loss: 0.00378772 accuracy: 100.0\n",
      "loss: 0.00242648 accuracy: 100.0\n",
      "loss: 0.00342312 accuracy: 100.0\n",
      "loss: 0.000957385 accuracy: 100.0\n",
      "loss: 0.000680283 accuracy: 100.0\n",
      "loss: 0.00115428 accuracy: 100.0\n",
      "loss: 0.00218522 accuracy: 100.0\n",
      "loss: 0.00201611 accuracy: 100.0\n",
      "loss: 0.000756621 accuracy: 100.0\n",
      "loss: 0.00187255 accuracy: 100.0\n",
      "loss: 0.001877 accuracy: 100.0\n",
      "loss: 0.0789409 accuracy: 99.0\n",
      "loss: 0.00103072 accuracy: 100.0\n",
      "loss: 0.00176146 accuracy: 100.0\n",
      "loss: 0.00120395 accuracy: 100.0\n",
      "loss: 0.00140905 accuracy: 100.0\n",
      "loss: 0.00449254 accuracy: 100.0\n",
      "loss: 0.00156293 accuracy: 100.0\n",
      "loss: 0.00204788 accuracy: 100.0\n",
      "loss: 0.00553364 accuracy: 100.0\n",
      "loss: 0.00259357 accuracy: 100.0\n",
      "loss: 0.00189139 accuracy: 100.0\n",
      "loss: 0.00327762 accuracy: 100.0\n",
      "loss: 0.000820447 accuracy: 100.0\n",
      "loss: 0.00296711 accuracy: 100.0\n",
      "loss: 0.00410806 accuracy: 100.0\n",
      "loss: 0.000534528 accuracy: 100.0\n",
      "loss: 0.00180116 accuracy: 100.0\n",
      "loss: 0.00244912 accuracy: 100.0\n",
      "loss: 0.00173637 accuracy: 100.0\n",
      "loss: 0.000789506 accuracy: 100.0\n",
      "loss: 0.00167791 accuracy: 100.0\n",
      "loss: 0.00114547 accuracy: 100.0\n",
      "loss: 0.00453207 accuracy: 100.0\n",
      "loss: 0.00355079 accuracy: 100.0\n",
      "loss: 0.00200256 accuracy: 100.0\n",
      "loss: 0.0010679 accuracy: 100.0\n",
      "loss: 0.00274594 accuracy: 100.0\n",
      "loss: 0.00355227 accuracy: 100.0\n",
      "loss: 0.00325141 accuracy: 100.0\n",
      "loss: 0.00145502 accuracy: 100.0\n",
      "loss: 0.00259475 accuracy: 100.0\n",
      "loss: 0.0019304 accuracy: 100.0\n",
      "loss: 0.003722 accuracy: 100.0\n",
      "loss: 0.000493912 accuracy: 100.0\n",
      "loss: 0.00272478 accuracy: 100.0\n",
      "loss: 0.0010491 accuracy: 100.0\n",
      "loss: 0.00339641 accuracy: 100.0\n",
      "loss: 0.036358 accuracy: 99.0\n",
      "loss: 0.0528034 accuracy: 99.0\n",
      "loss: 0.00157637 accuracy: 100.0\n",
      "loss: 0.00293046 accuracy: 100.0\n",
      "loss: 0.00214418 accuracy: 100.0\n",
      "loss: 0.00611259 accuracy: 100.0\n",
      "loss: 0.0503837 accuracy: 99.0\n",
      "loss: 0.00258505 accuracy: 100.0\n",
      "loss: 0.00119204 accuracy: 100.0\n",
      "loss: 0.00461863 accuracy: 100.0\n",
      "loss: 0.000683494 accuracy: 100.0\n",
      "loss: 0.00461356 accuracy: 100.0\n",
      "loss: 0.000820974 accuracy: 100.0\n",
      "loss: 0.000388461 accuracy: 100.0\n",
      "loss: 0.0085911 accuracy: 100.0\n",
      "loss: 0.00559064 accuracy: 100.0\n",
      "loss: 0.00659362 accuracy: 100.0\n",
      "loss: 0.00571321 accuracy: 100.0\n",
      "loss: 0.00126087 accuracy: 100.0\n",
      "loss: 0.0038101 accuracy: 100.0\n",
      "loss: 0.00128478 accuracy: 100.0\n",
      "loss: 0.00167915 accuracy: 100.0\n",
      "loss: 0.00184838 accuracy: 100.0\n",
      "loss: 0.00138671 accuracy: 100.0\n",
      "loss: 0.00199336 accuracy: 100.0\n",
      "loss: 0.00978699 accuracy: 100.0\n",
      "loss: 0.00605158 accuracy: 100.0\n",
      "loss: 0.000631874 accuracy: 100.0\n",
      "loss: 0.00246444 accuracy: 100.0\n",
      "loss: 0.0012046 accuracy: 100.0\n",
      "loss: 0.0023652 accuracy: 100.0\n",
      "loss: 0.00300669 accuracy: 100.0\n",
      "loss: 0.000775435 accuracy: 100.0\n",
      "loss: 0.00322447 accuracy: 100.0\n",
      "loss: 0.00165888 accuracy: 100.0\n",
      "loss: 0.00277665 accuracy: 100.0\n",
      "loss: 0.00180161 accuracy: 100.0\n",
      "loss: 0.00438556 accuracy: 100.0\n",
      "loss: 0.00089797 accuracy: 100.0\n",
      "loss: 0.00263544 accuracy: 100.0\n",
      "loss: 0.000515783 accuracy: 100.0\n",
      "loss: 0.000600757 accuracy: 100.0\n",
      "loss: 0.00270823 accuracy: 100.0\n",
      "loss: 0.00140847 accuracy: 100.0\n",
      "loss: 0.00126753 accuracy: 100.0\n",
      "loss: 0.00113163 accuracy: 100.0\n",
      "loss: 0.00107299 accuracy: 100.0\n",
      "loss: 0.0101817 accuracy: 100.0\n",
      "loss: 0.00505605 accuracy: 100.0\n",
      "loss: 0.00613406 accuracy: 100.0\n",
      "loss: 0.0008635 accuracy: 100.0\n",
      "loss: 0.000990486 accuracy: 100.0\n",
      "loss: 0.00187444 accuracy: 100.0\n",
      "loss: 0.00209692 accuracy: 100.0\n",
      "loss: 0.002449 accuracy: 100.0\n",
      "loss: 0.00291714 accuracy: 100.0\n",
      "loss: 0.000733316 accuracy: 100.0\n",
      "loss: 0.00672562 accuracy: 100.0\n",
      "loss: 0.00167444 accuracy: 100.0\n",
      "loss: 0.00286956 accuracy: 100.0\n",
      "loss: 0.00260726 accuracy: 100.0\n",
      "loss: 0.0007978 accuracy: 100.0\n",
      "loss: 0.00104631 accuracy: 100.0\n",
      "loss: 0.00279605 accuracy: 100.0\n",
      "loss: 0.000888547 accuracy: 100.0\n",
      "loss: 0.000331238 accuracy: 100.0\n",
      "loss: 0.000818999 accuracy: 100.0\n",
      "loss: 0.00236252 accuracy: 100.0\n",
      "loss: 0.00279812 accuracy: 100.0\n",
      "loss: 0.00148473 accuracy: 100.0\n",
      "loss: 0.000956994 accuracy: 100.0\n",
      "loss: 0.0027071 accuracy: 100.0\n",
      "loss: 0.00163756 accuracy: 100.0\n",
      "loss: 0.00221755 accuracy: 100.0\n",
      "loss: 0.00182878 accuracy: 100.0\n",
      "loss: 0.0044536 accuracy: 100.0\n",
      "loss: 0.00271651 accuracy: 100.0\n",
      "loss: 0.00453974 accuracy: 100.0\n",
      "loss: 0.00221138 accuracy: 100.0\n",
      "loss: 0.000983358 accuracy: 100.0\n",
      "loss: 0.00147496 accuracy: 100.0\n",
      "loss: 0.00492287 accuracy: 100.0\n",
      "loss: 0.00096901 accuracy: 100.0\n",
      "loss: 0.00177375 accuracy: 100.0\n",
      "loss: 0.00194083 accuracy: 100.0\n",
      "loss: 0.00223406 accuracy: 100.0\n",
      "loss: 0.00207662 accuracy: 100.0\n",
      "loss: 0.00226793 accuracy: 100.0\n",
      "loss: 0.0016632 accuracy: 100.0\n",
      "loss: 0.00295649 accuracy: 100.0\n",
      "loss: 0.0024065 accuracy: 100.0\n",
      "loss: 0.0411703 accuracy: 99.0\n",
      "loss: 0.00146702 accuracy: 100.0\n",
      "loss: 0.00200721 accuracy: 100.0\n",
      "loss: 0.00114339 accuracy: 100.0\n",
      "loss: 0.00153389 accuracy: 100.0\n",
      "loss: 0.00254541 accuracy: 100.0\n",
      "loss: 0.0150413 accuracy: 99.0\n",
      "loss: 0.00360004 accuracy: 100.0\n",
      "loss: 0.00120851 accuracy: 100.0\n",
      "loss: 0.00444483 accuracy: 100.0\n",
      "loss: 0.00234957 accuracy: 100.0\n",
      "loss: 0.00324243 accuracy: 100.0\n",
      "loss: 0.00125219 accuracy: 100.0\n",
      "loss: 0.00171284 accuracy: 100.0\n",
      "loss: 0.0015994 accuracy: 100.0\n",
      "loss: 0.00402818 accuracy: 100.0\n",
      "loss: 0.000989339 accuracy: 100.0\n",
      "loss: 0.00471162 accuracy: 100.0\n",
      "loss: 0.000844456 accuracy: 100.0\n",
      "loss: 0.00298659 accuracy: 100.0\n",
      "loss: 0.00422586 accuracy: 100.0\n",
      "loss: 0.00544674 accuracy: 100.0\n",
      "loss: 0.00309834 accuracy: 100.0\n",
      "loss: 0.00439985 accuracy: 100.0\n",
      "loss: 0.00484126 accuracy: 100.0\n",
      "loss: 0.00044821 accuracy: 100.0\n",
      "loss: 0.00173879 accuracy: 100.0\n",
      "loss: 0.00104306 accuracy: 100.0\n",
      "loss: 0.00143433 accuracy: 100.0\n",
      "loss: 0.00315002 accuracy: 100.0\n",
      "loss: 0.000872868 accuracy: 100.0\n",
      "loss: 0.00526345 accuracy: 100.0\n",
      "loss: 0.00130162 accuracy: 100.0\n",
      "loss: 0.00228461 accuracy: 100.0\n",
      "loss: 0.0157628 accuracy: 99.0\n",
      "loss: 0.00158532 accuracy: 100.0\n",
      "loss: 0.00122113 accuracy: 100.0\n",
      "loss: 0.0245464 accuracy: 99.0\n",
      "loss: 0.00393388 accuracy: 100.0\n",
      "loss: 0.00244079 accuracy: 100.0\n",
      "loss: 0.00257894 accuracy: 100.0\n",
      "loss: 0.00688513 accuracy: 100.0\n",
      "loss: 0.00245745 accuracy: 100.0\n",
      "loss: 0.000352006 accuracy: 100.0\n",
      "loss: 0.00127499 accuracy: 100.0\n",
      "loss: 0.00132718 accuracy: 100.0\n",
      "loss: 0.00566902 accuracy: 100.0\n",
      "loss: 0.00179923 accuracy: 100.0\n",
      "loss: 0.00119882 accuracy: 100.0\n",
      "loss: 0.00350922 accuracy: 100.0\n",
      "loss: 0.00536144 accuracy: 100.0\n",
      "loss: 0.00159545 accuracy: 100.0\n",
      "loss: 0.00477791 accuracy: 100.0\n",
      "loss: 0.00667291 accuracy: 100.0\n",
      "loss: 0.00524414 accuracy: 100.0\n",
      "loss: 0.0022938 accuracy: 100.0\n",
      "loss: 0.000999698 accuracy: 100.0\n",
      "loss: 0.00135449 accuracy: 100.0\n",
      "loss: 0.00363268 accuracy: 100.0\n",
      "loss: 0.00523805 accuracy: 100.0\n",
      "loss: 0.000982699 accuracy: 100.0\n",
      "loss: 0.000539942 accuracy: 100.0\n",
      "loss: 0.00230163 accuracy: 100.0\n",
      "loss: 0.00270286 accuracy: 100.0\n",
      "loss: 0.000970147 accuracy: 100.0\n",
      "loss: 0.003498 accuracy: 100.0\n",
      "loss: 0.00172307 accuracy: 100.0\n",
      "loss: 0.00109685 accuracy: 100.0\n",
      "loss: 0.000933682 accuracy: 100.0\n",
      "loss: 0.00112602 accuracy: 100.0\n",
      "loss: 0.000883084 accuracy: 100.0\n",
      "loss: 0.00897297 accuracy: 100.0\n",
      "loss: 0.00170631 accuracy: 100.0\n",
      "loss: 0.00299497 accuracy: 100.0\n",
      "loss: 0.00349281 accuracy: 100.0\n",
      "loss: 0.00282527 accuracy: 100.0\n",
      "loss: 0.00248778 accuracy: 100.0\n",
      "loss: 0.00372788 accuracy: 100.0\n",
      "loss: 0.002564 accuracy: 100.0\n",
      "loss: 0.00320971 accuracy: 100.0\n",
      "loss: 0.00226028 accuracy: 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00610393 accuracy: 100.0\n",
      "loss: 0.000868407 accuracy: 100.0\n",
      "loss: 0.00142289 accuracy: 100.0\n",
      "loss: 0.00246698 accuracy: 100.0\n",
      "loss: 0.00147385 accuracy: 100.0\n",
      "loss: 0.0634295 accuracy: 99.0\n",
      "loss: 0.001368 accuracy: 100.0\n",
      "loss: 0.00305643 accuracy: 100.0\n",
      "loss: 0.00106648 accuracy: 100.0\n",
      "loss: 0.00127378 accuracy: 100.0\n",
      "loss: 0.0202784 accuracy: 99.0\n",
      "loss: 0.0185308 accuracy: 99.0\n",
      "loss: 0.00147175 accuracy: 100.0\n",
      "loss: 0.0013124 accuracy: 100.0\n",
      "loss: 0.00327725 accuracy: 100.0\n",
      "loss: 0.00213254 accuracy: 100.0\n",
      "loss: 0.00257596 accuracy: 100.0\n",
      "loss: 0.00337693 accuracy: 100.0\n",
      "loss: 0.00130776 accuracy: 100.0\n",
      "loss: 0.00164087 accuracy: 100.0\n",
      "loss: 0.00163533 accuracy: 100.0\n",
      "loss: 0.0005988 accuracy: 100.0\n",
      "loss: 0.0020417 accuracy: 100.0\n",
      "loss: 0.00154414 accuracy: 100.0\n",
      "loss: 0.000621525 accuracy: 100.0\n",
      "loss: 0.00129158 accuracy: 100.0\n",
      "loss: 0.000872761 accuracy: 100.0\n",
      "loss: 0.00271469 accuracy: 100.0\n",
      "loss: 0.0203123 accuracy: 99.0\n",
      "loss: 0.00765281 accuracy: 100.0\n",
      ">>>>>>>>>> test dataset accuracy: 97.95\n",
      "loss: 0.00163345 accuracy: 100.0\n",
      "loss: 0.00206695 accuracy: 100.0\n",
      "loss: 0.00251168 accuracy: 100.0\n",
      "loss: 0.00217815 accuracy: 100.0\n",
      "loss: 0.000580336 accuracy: 100.0\n",
      "loss: 0.00265323 accuracy: 100.0\n",
      "loss: 0.0010404 accuracy: 100.0\n",
      "loss: 0.00682744 accuracy: 100.0\n",
      "loss: 0.00694985 accuracy: 100.0\n",
      "loss: 0.000583402 accuracy: 100.0\n",
      "loss: 0.00198719 accuracy: 100.0\n",
      "loss: 0.00101742 accuracy: 100.0\n",
      "loss: 0.000928106 accuracy: 100.0\n",
      "loss: 0.000594422 accuracy: 100.0\n",
      "loss: 0.000603345 accuracy: 100.0\n",
      "loss: 0.00112543 accuracy: 100.0\n",
      "loss: 0.0010949 accuracy: 100.0\n",
      "loss: 0.00077745 accuracy: 100.0\n",
      "loss: 0.00223654 accuracy: 100.0\n",
      "loss: 0.00156436 accuracy: 100.0\n",
      "loss: 0.000385113 accuracy: 100.0\n",
      "loss: 0.000970443 accuracy: 100.0\n",
      "loss: 0.00233982 accuracy: 100.0\n",
      "loss: 0.000498515 accuracy: 100.0\n",
      "loss: 0.00053618 accuracy: 100.0\n",
      "loss: 0.000561685 accuracy: 100.0\n",
      "loss: 0.00307659 accuracy: 100.0\n",
      "loss: 0.000787811 accuracy: 100.0\n",
      "loss: 0.000792268 accuracy: 100.0\n",
      "loss: 0.0010184 accuracy: 100.0\n",
      "loss: 0.00171807 accuracy: 100.0\n",
      "loss: 0.000560185 accuracy: 100.0\n",
      "loss: 0.00105144 accuracy: 100.0\n",
      "loss: 0.00207491 accuracy: 100.0\n",
      "loss: 0.00301328 accuracy: 100.0\n",
      "loss: 0.00192471 accuracy: 100.0\n",
      "loss: 0.00146628 accuracy: 100.0\n",
      "loss: 0.00118117 accuracy: 100.0\n",
      "loss: 0.00117341 accuracy: 100.0\n",
      "loss: 0.00586845 accuracy: 100.0\n",
      "loss: 0.000805443 accuracy: 100.0\n",
      "loss: 0.00150269 accuracy: 100.0\n",
      "loss: 0.0018729 accuracy: 100.0\n",
      "loss: 0.00153662 accuracy: 100.0\n",
      "loss: 0.00131882 accuracy: 100.0\n",
      "loss: 0.00108069 accuracy: 100.0\n",
      "loss: 0.000690484 accuracy: 100.0\n",
      "loss: 0.00220746 accuracy: 100.0\n",
      "loss: 0.000810588 accuracy: 100.0\n",
      "loss: 0.0019683 accuracy: 100.0\n",
      "loss: 0.00451706 accuracy: 100.0\n",
      "loss: 0.000418459 accuracy: 100.0\n",
      "loss: 0.00252525 accuracy: 100.0\n",
      "loss: 0.00155549 accuracy: 100.0\n",
      "loss: 0.0027592 accuracy: 100.0\n",
      "loss: 0.00252548 accuracy: 100.0\n",
      "loss: 0.00103134 accuracy: 100.0\n",
      "loss: 0.00484646 accuracy: 100.0\n",
      "loss: 0.00142677 accuracy: 100.0\n",
      "loss: 0.00136231 accuracy: 100.0\n",
      "loss: 0.00210698 accuracy: 100.0\n",
      "loss: 0.00118449 accuracy: 100.0\n",
      "loss: 0.000868264 accuracy: 100.0\n",
      "loss: 0.00284639 accuracy: 100.0\n",
      "loss: 0.0012658 accuracy: 100.0\n",
      "loss: 0.00108543 accuracy: 100.0\n",
      "loss: 0.00226572 accuracy: 100.0\n",
      "loss: 0.00214733 accuracy: 100.0\n",
      "loss: 0.00245185 accuracy: 100.0\n",
      "loss: 0.000396281 accuracy: 100.0\n",
      "loss: 0.0016971 accuracy: 100.0\n",
      "loss: 0.00181904 accuracy: 100.0\n",
      "loss: 0.000885912 accuracy: 100.0\n",
      "loss: 0.00173281 accuracy: 100.0\n",
      "loss: 0.00265038 accuracy: 100.0\n",
      "loss: 0.000886737 accuracy: 100.0\n",
      "loss: 0.00107029 accuracy: 100.0\n",
      "loss: 0.00143859 accuracy: 100.0\n",
      "loss: 0.00199714 accuracy: 100.0\n",
      "loss: 0.00114157 accuracy: 100.0\n",
      "loss: 0.00182931 accuracy: 100.0\n",
      "loss: 0.00227911 accuracy: 100.0\n",
      "loss: 0.00542708 accuracy: 100.0\n",
      "loss: 0.0018628 accuracy: 100.0\n",
      "loss: 0.000671938 accuracy: 100.0\n",
      "loss: 0.00582675 accuracy: 100.0\n",
      "loss: 0.00179814 accuracy: 100.0\n",
      "loss: 0.00307311 accuracy: 100.0\n",
      "loss: 0.00166214 accuracy: 100.0\n",
      "loss: 0.00118802 accuracy: 100.0\n",
      "loss: 0.000347535 accuracy: 100.0\n",
      "loss: 0.00263474 accuracy: 100.0\n",
      "loss: 0.00236103 accuracy: 100.0\n",
      "loss: 0.000611698 accuracy: 100.0\n",
      "loss: 0.00122422 accuracy: 100.0\n",
      "loss: 0.00107594 accuracy: 100.0\n",
      "loss: 0.000958455 accuracy: 100.0\n",
      "loss: 0.00202084 accuracy: 100.0\n",
      "loss: 0.000803776 accuracy: 100.0\n",
      "loss: 0.00144656 accuracy: 100.0\n",
      "loss: 0.00138687 accuracy: 100.0\n",
      "loss: 0.00428059 accuracy: 100.0\n",
      "loss: 0.00184473 accuracy: 100.0\n",
      "loss: 0.000810678 accuracy: 100.0\n",
      "loss: 0.00128153 accuracy: 100.0\n",
      "loss: 0.00152686 accuracy: 100.0\n",
      "loss: 0.000823821 accuracy: 100.0\n",
      "loss: 0.00120918 accuracy: 100.0\n",
      "loss: 0.00185172 accuracy: 100.0\n",
      "loss: 0.00137754 accuracy: 100.0\n",
      "loss: 0.000301234 accuracy: 100.0\n",
      "loss: 0.00293635 accuracy: 100.0\n",
      "loss: 0.00115791 accuracy: 100.0\n",
      "loss: 0.000929668 accuracy: 100.0\n",
      "loss: 0.000854221 accuracy: 100.0\n",
      "loss: 0.000786692 accuracy: 100.0\n",
      "loss: 0.00120118 accuracy: 100.0\n",
      "loss: 0.000626382 accuracy: 100.0\n",
      "loss: 0.000706261 accuracy: 100.0\n",
      "loss: 0.000688222 accuracy: 100.0\n",
      "loss: 0.00207551 accuracy: 100.0\n",
      "loss: 0.00133675 accuracy: 100.0\n",
      "loss: 0.000961444 accuracy: 100.0\n",
      "loss: 0.00107399 accuracy: 100.0\n",
      "loss: 0.00154354 accuracy: 100.0\n",
      "loss: 0.00101945 accuracy: 100.0\n",
      "loss: 0.00022753 accuracy: 100.0\n",
      "loss: 0.000671309 accuracy: 100.0\n",
      "loss: 0.0015462 accuracy: 100.0\n",
      "loss: 0.000421706 accuracy: 100.0\n",
      "loss: 0.00318406 accuracy: 100.0\n",
      "loss: 0.0018665 accuracy: 100.0\n",
      "loss: 0.00130267 accuracy: 100.0\n",
      "loss: 0.00234038 accuracy: 100.0\n",
      "loss: 0.00203328 accuracy: 100.0\n",
      "loss: 0.000921427 accuracy: 100.0\n",
      "loss: 0.00233326 accuracy: 100.0\n",
      "loss: 0.000448742 accuracy: 100.0\n",
      "loss: 0.00359849 accuracy: 100.0\n",
      "loss: 0.00102162 accuracy: 100.0\n",
      "loss: 0.0530015 accuracy: 99.0\n",
      "loss: 0.00117687 accuracy: 100.0\n",
      "loss: 0.000595604 accuracy: 100.0\n",
      "loss: 0.00106905 accuracy: 100.0\n",
      "loss: 0.00125485 accuracy: 100.0\n",
      "loss: 0.00161338 accuracy: 100.0\n",
      "loss: 0.00230193 accuracy: 100.0\n",
      "loss: 0.00412344 accuracy: 100.0\n",
      "loss: 0.00133705 accuracy: 100.0\n",
      "loss: 0.00145401 accuracy: 100.0\n",
      "loss: 0.000709132 accuracy: 100.0\n",
      "loss: 0.00055764 accuracy: 100.0\n",
      "loss: 0.00103013 accuracy: 100.0\n",
      "loss: 0.00136038 accuracy: 100.0\n",
      "loss: 0.00085624 accuracy: 100.0\n",
      "loss: 0.000574663 accuracy: 100.0\n",
      "loss: 0.00143482 accuracy: 100.0\n",
      "loss: 0.00170829 accuracy: 100.0\n",
      "loss: 0.000810476 accuracy: 100.0\n",
      "loss: 0.00123805 accuracy: 100.0\n",
      "loss: 0.00194446 accuracy: 100.0\n",
      "loss: 0.00135453 accuracy: 100.0\n",
      "loss: 0.00276106 accuracy: 100.0\n",
      "loss: 0.00197277 accuracy: 100.0\n",
      "loss: 0.00138688 accuracy: 100.0\n",
      "loss: 0.00250289 accuracy: 100.0\n",
      "loss: 0.00105741 accuracy: 100.0\n",
      "loss: 0.00354458 accuracy: 100.0\n",
      "loss: 0.0019036 accuracy: 100.0\n",
      "loss: 0.000936839 accuracy: 100.0\n",
      "loss: 0.000719081 accuracy: 100.0\n",
      "loss: 0.00216977 accuracy: 100.0\n",
      "loss: 0.000731374 accuracy: 100.0\n",
      "loss: 0.000336489 accuracy: 100.0\n",
      "loss: 0.000824208 accuracy: 100.0\n",
      "loss: 0.0017636 accuracy: 100.0\n",
      "loss: 0.00234796 accuracy: 100.0\n",
      "loss: 0.000285657 accuracy: 100.0\n",
      "loss: 0.000844153 accuracy: 100.0\n",
      "loss: 0.00158086 accuracy: 100.0\n",
      "loss: 0.00155154 accuracy: 100.0\n",
      "loss: 0.000421309 accuracy: 100.0\n",
      "loss: 0.000860073 accuracy: 100.0\n",
      "loss: 0.0014607 accuracy: 100.0\n",
      "loss: 0.00184032 accuracy: 100.0\n",
      "loss: 0.00134422 accuracy: 100.0\n",
      "loss: 0.00109694 accuracy: 100.0\n",
      "loss: 0.00180541 accuracy: 100.0\n",
      "loss: 0.00227589 accuracy: 100.0\n",
      "loss: 0.00286827 accuracy: 100.0\n",
      "loss: 0.00118868 accuracy: 100.0\n",
      "loss: 0.00166694 accuracy: 100.0\n",
      "loss: 0.000803017 accuracy: 100.0\n",
      "loss: 0.00109751 accuracy: 100.0\n",
      "loss: 0.00255765 accuracy: 100.0\n",
      "loss: 0.00239501 accuracy: 100.0\n",
      "loss: 0.00175494 accuracy: 100.0\n",
      "loss: 0.00309023 accuracy: 100.0\n",
      "loss: 0.000903463 accuracy: 100.0\n",
      "loss: 0.0012039 accuracy: 100.0\n",
      "loss: 0.00211938 accuracy: 100.0\n",
      "loss: 0.00124377 accuracy: 100.0\n",
      "loss: 0.000848043 accuracy: 100.0\n",
      "loss: 0.000885822 accuracy: 100.0\n",
      "loss: 0.00165324 accuracy: 100.0\n",
      "loss: 0.000576734 accuracy: 100.0\n",
      "loss: 0.00540743 accuracy: 100.0\n",
      "loss: 0.00201415 accuracy: 100.0\n",
      "loss: 0.000418512 accuracy: 100.0\n",
      "loss: 0.00116502 accuracy: 100.0\n",
      "loss: 0.00132985 accuracy: 100.0\n",
      "loss: 0.000944627 accuracy: 100.0\n",
      "loss: 0.000856699 accuracy: 100.0\n",
      "loss: 0.00249847 accuracy: 100.0\n",
      "loss: 0.00126625 accuracy: 100.0\n",
      "loss: 0.00171567 accuracy: 100.0\n",
      "loss: 0.00182492 accuracy: 100.0\n",
      "loss: 0.00132759 accuracy: 100.0\n",
      "loss: 0.0014159 accuracy: 100.0\n",
      "loss: 0.000321075 accuracy: 100.0\n",
      "loss: 0.00125185 accuracy: 100.0\n",
      "loss: 0.00246461 accuracy: 100.0\n",
      "loss: 0.000948905 accuracy: 100.0\n",
      "loss: 0.00177927 accuracy: 100.0\n",
      "loss: 0.000215752 accuracy: 100.0\n",
      "loss: 0.00145635 accuracy: 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00253369 accuracy: 100.0\n",
      "loss: 0.000985578 accuracy: 100.0\n",
      "loss: 0.00129218 accuracy: 100.0\n",
      "loss: 0.00114973 accuracy: 100.0\n",
      "loss: 0.00456386 accuracy: 100.0\n",
      "loss: 0.00142724 accuracy: 100.0\n",
      "loss: 0.00172734 accuracy: 100.0\n",
      "loss: 0.000823159 accuracy: 100.0\n",
      "loss: 0.000690131 accuracy: 100.0\n",
      "loss: 0.00121108 accuracy: 100.0\n",
      "loss: 0.000902565 accuracy: 100.0\n",
      "loss: 0.00095003 accuracy: 100.0\n",
      "loss: 0.00177972 accuracy: 100.0\n",
      "loss: 0.00331376 accuracy: 100.0\n",
      "loss: 0.00333411 accuracy: 100.0\n",
      "loss: 0.0349408 accuracy: 99.0\n",
      "loss: 0.000891149 accuracy: 100.0\n",
      "loss: 0.000524154 accuracy: 100.0\n",
      "loss: 0.00201996 accuracy: 100.0\n",
      "loss: 0.000794382 accuracy: 100.0\n",
      "loss: 0.00161451 accuracy: 100.0\n",
      "loss: 0.0026703 accuracy: 100.0\n",
      "loss: 0.00112946 accuracy: 100.0\n",
      "loss: 0.00154416 accuracy: 100.0\n",
      "loss: 0.000989909 accuracy: 100.0\n",
      "loss: 0.00107699 accuracy: 100.0\n",
      "loss: 0.000715784 accuracy: 100.0\n",
      "loss: 0.000568577 accuracy: 100.0\n",
      "loss: 0.00042351 accuracy: 100.0\n",
      "loss: 0.00093253 accuracy: 100.0\n",
      "loss: 0.00151514 accuracy: 100.0\n",
      "loss: 0.00153094 accuracy: 100.0\n",
      "loss: 0.00119968 accuracy: 100.0\n",
      "loss: 0.00178904 accuracy: 100.0\n",
      "loss: 0.00118287 accuracy: 100.0\n",
      "loss: 0.00033237 accuracy: 100.0\n",
      "loss: 0.000842399 accuracy: 100.0\n",
      "loss: 0.00109952 accuracy: 100.0\n",
      "loss: 0.000707931 accuracy: 100.0\n",
      "loss: 0.00153018 accuracy: 100.0\n",
      "loss: 0.00140726 accuracy: 100.0\n",
      "loss: 0.00166112 accuracy: 100.0\n",
      "loss: 0.000484714 accuracy: 100.0\n",
      "loss: 0.00131112 accuracy: 100.0\n",
      "loss: 0.000750165 accuracy: 100.0\n",
      "loss: 0.0014862 accuracy: 100.0\n",
      "loss: 0.000790129 accuracy: 100.0\n",
      "loss: 0.00113676 accuracy: 100.0\n",
      "loss: 0.000728706 accuracy: 100.0\n",
      "loss: 0.000853747 accuracy: 100.0\n",
      "loss: 0.00139678 accuracy: 100.0\n",
      "loss: 0.0013245 accuracy: 100.0\n",
      "loss: 0.00201671 accuracy: 100.0\n",
      "loss: 0.00158204 accuracy: 100.0\n",
      "loss: 0.000949924 accuracy: 100.0\n",
      "loss: 0.00140917 accuracy: 100.0\n",
      "loss: 0.0024925 accuracy: 100.0\n",
      "loss: 0.00148379 accuracy: 100.0\n",
      "loss: 0.00279947 accuracy: 100.0\n",
      "loss: 0.00161648 accuracy: 100.0\n",
      "loss: 0.000987164 accuracy: 100.0\n",
      "loss: 0.00116322 accuracy: 100.0\n",
      "loss: 0.000709522 accuracy: 100.0\n",
      "loss: 0.00157576 accuracy: 100.0\n",
      "loss: 0.00123937 accuracy: 100.0\n",
      "loss: 0.00128855 accuracy: 100.0\n",
      "loss: 0.00219591 accuracy: 100.0\n",
      "loss: 0.0014757 accuracy: 100.0\n",
      "loss: 0.000838387 accuracy: 100.0\n",
      "loss: 0.00142336 accuracy: 100.0\n",
      "loss: 0.000762045 accuracy: 100.0\n",
      "loss: 0.00159468 accuracy: 100.0\n",
      "loss: 0.000299077 accuracy: 100.0\n",
      "loss: 0.000769766 accuracy: 100.0\n",
      "loss: 0.0011753 accuracy: 100.0\n",
      "loss: 0.00205944 accuracy: 100.0\n",
      "loss: 0.00315615 accuracy: 100.0\n",
      "loss: 0.00492144 accuracy: 100.0\n",
      "loss: 0.000660123 accuracy: 100.0\n",
      "loss: 0.00179912 accuracy: 100.0\n",
      "loss: 0.00178198 accuracy: 100.0\n",
      "loss: 0.00317905 accuracy: 100.0\n",
      "loss: 0.000406475 accuracy: 100.0\n",
      "loss: 0.00125874 accuracy: 100.0\n",
      "loss: 0.000108503 accuracy: 100.0\n",
      "loss: 0.00143589 accuracy: 100.0\n",
      "loss: 0.000659519 accuracy: 100.0\n",
      "loss: 0.00177278 accuracy: 100.0\n",
      "loss: 0.00200892 accuracy: 100.0\n",
      "loss: 0.000635766 accuracy: 100.0\n",
      "loss: 0.00137236 accuracy: 100.0\n",
      "loss: 0.00106803 accuracy: 100.0\n",
      "loss: 0.000735765 accuracy: 100.0\n",
      "loss: 0.00289957 accuracy: 100.0\n",
      "loss: 0.00280157 accuracy: 100.0\n",
      "loss: 0.000989337 accuracy: 100.0\n",
      "loss: 0.00243374 accuracy: 100.0\n",
      "loss: 0.00154478 accuracy: 100.0\n",
      "loss: 0.00137842 accuracy: 100.0\n",
      "loss: 0.00262633 accuracy: 100.0\n",
      "loss: 0.00151447 accuracy: 100.0\n",
      "loss: 0.000752721 accuracy: 100.0\n",
      "loss: 0.00491936 accuracy: 100.0\n",
      "loss: 0.0034643 accuracy: 100.0\n",
      "loss: 0.00205782 accuracy: 100.0\n",
      "loss: 0.00203776 accuracy: 100.0\n",
      "loss: 0.000401491 accuracy: 100.0\n",
      "loss: 0.000559126 accuracy: 100.0\n",
      "loss: 0.00173171 accuracy: 100.0\n",
      "loss: 0.000583343 accuracy: 100.0\n",
      "loss: 0.000822313 accuracy: 100.0\n",
      "loss: 0.00148248 accuracy: 100.0\n",
      "loss: 0.00210402 accuracy: 100.0\n",
      "loss: 0.00111225 accuracy: 100.0\n",
      "loss: 0.000700822 accuracy: 100.0\n",
      "loss: 0.000715721 accuracy: 100.0\n",
      "loss: 0.000837657 accuracy: 100.0\n",
      "loss: 0.000578188 accuracy: 100.0\n",
      "loss: 0.00193928 accuracy: 100.0\n",
      "loss: 0.00109314 accuracy: 100.0\n",
      "loss: 0.000491205 accuracy: 100.0\n",
      "loss: 0.00178089 accuracy: 100.0\n",
      "loss: 0.00220203 accuracy: 100.0\n",
      "loss: 0.000782122 accuracy: 100.0\n",
      "loss: 0.00182696 accuracy: 100.0\n",
      "loss: 0.00205053 accuracy: 100.0\n",
      "loss: 0.000840267 accuracy: 100.0\n",
      "loss: 0.000412038 accuracy: 100.0\n",
      "loss: 0.00105591 accuracy: 100.0\n",
      "loss: 0.00309301 accuracy: 100.0\n",
      "loss: 0.000757157 accuracy: 100.0\n",
      "loss: 0.00113684 accuracy: 100.0\n",
      "loss: 0.00101411 accuracy: 100.0\n",
      "loss: 0.00227058 accuracy: 100.0\n",
      "loss: 0.000810543 accuracy: 100.0\n",
      "loss: 0.000536313 accuracy: 100.0\n",
      "loss: 0.00109269 accuracy: 100.0\n",
      "loss: 0.000684285 accuracy: 100.0\n",
      "loss: 0.00156354 accuracy: 100.0\n",
      "loss: 0.00342508 accuracy: 100.0\n",
      "loss: 0.00130359 accuracy: 100.0\n",
      "loss: 0.00283832 accuracy: 100.0\n",
      "loss: 0.00123651 accuracy: 100.0\n",
      "loss: 0.000852236 accuracy: 100.0\n",
      "loss: 0.00379008 accuracy: 100.0\n",
      "loss: 0.000850604 accuracy: 100.0\n",
      "loss: 0.00212257 accuracy: 100.0\n",
      "loss: 0.0028148 accuracy: 100.0\n",
      "loss: 0.00155628 accuracy: 100.0\n",
      "loss: 0.00195591 accuracy: 100.0\n",
      "loss: 0.00126703 accuracy: 100.0\n",
      "loss: 0.00256246 accuracy: 100.0\n",
      "loss: 0.00146231 accuracy: 100.0\n",
      "loss: 0.00192143 accuracy: 100.0\n",
      "loss: 0.000823868 accuracy: 100.0\n",
      "loss: 0.000999116 accuracy: 100.0\n",
      "loss: 0.00283485 accuracy: 100.0\n",
      "loss: 0.00180789 accuracy: 100.0\n",
      "loss: 0.000494419 accuracy: 100.0\n",
      "loss: 0.00274532 accuracy: 100.0\n",
      "loss: 0.00129738 accuracy: 100.0\n",
      "loss: 0.00211324 accuracy: 100.0\n",
      "loss: 0.00132739 accuracy: 100.0\n",
      "loss: 0.00464943 accuracy: 100.0\n",
      "loss: 0.0022789 accuracy: 100.0\n",
      "loss: 0.000466099 accuracy: 100.0\n",
      "loss: 0.00106103 accuracy: 100.0\n",
      "loss: 0.0019247 accuracy: 100.0\n",
      "loss: 0.000970013 accuracy: 100.0\n",
      "loss: 0.00179393 accuracy: 100.0\n",
      "loss: 0.00180693 accuracy: 100.0\n",
      "loss: 0.00146715 accuracy: 100.0\n",
      "loss: 0.00171455 accuracy: 100.0\n",
      "loss: 0.00209272 accuracy: 100.0\n",
      "loss: 0.00328241 accuracy: 100.0\n",
      "loss: 0.00169888 accuracy: 100.0\n",
      "loss: 0.0016774 accuracy: 100.0\n",
      "loss: 0.000454177 accuracy: 100.0\n",
      "loss: 0.00107404 accuracy: 100.0\n",
      "loss: 0.000706477 accuracy: 100.0\n",
      "loss: 0.00112223 accuracy: 100.0\n",
      "loss: 0.000677962 accuracy: 100.0\n",
      "loss: 0.000332258 accuracy: 100.0\n",
      "loss: 0.000257936 accuracy: 100.0\n",
      "loss: 0.000632774 accuracy: 100.0\n",
      "loss: 0.00073203 accuracy: 100.0\n",
      "loss: 0.00268613 accuracy: 100.0\n",
      "loss: 0.00115041 accuracy: 100.0\n",
      "loss: 0.000836497 accuracy: 100.0\n",
      "loss: 0.0013261 accuracy: 100.0\n",
      "loss: 0.0030361 accuracy: 100.0\n",
      "loss: 0.00502737 accuracy: 100.0\n",
      "loss: 0.00520966 accuracy: 100.0\n",
      "loss: 0.000494512 accuracy: 100.0\n",
      "loss: 0.00139112 accuracy: 100.0\n",
      "loss: 0.00114373 accuracy: 100.0\n",
      "loss: 0.000469229 accuracy: 100.0\n",
      "loss: 0.000866317 accuracy: 100.0\n",
      "loss: 0.000592727 accuracy: 100.0\n",
      "loss: 0.00158835 accuracy: 100.0\n",
      "loss: 0.00050392 accuracy: 100.0\n",
      "loss: 0.00251865 accuracy: 100.0\n",
      "loss: 0.00275783 accuracy: 100.0\n",
      "loss: 0.00143556 accuracy: 100.0\n",
      "loss: 0.00186684 accuracy: 100.0\n",
      "loss: 0.000924947 accuracy: 100.0\n",
      "loss: 0.000949563 accuracy: 100.0\n",
      "loss: 0.00211147 accuracy: 100.0\n",
      "loss: 0.00162798 accuracy: 100.0\n",
      "loss: 0.00108101 accuracy: 100.0\n",
      "loss: 0.00559917 accuracy: 100.0\n",
      "loss: 0.000817167 accuracy: 100.0\n",
      "loss: 0.00153667 accuracy: 100.0\n",
      "loss: 0.0010607 accuracy: 100.0\n",
      "loss: 0.00221571 accuracy: 100.0\n",
      "loss: 0.00242254 accuracy: 100.0\n",
      "loss: 0.00144828 accuracy: 100.0\n",
      "loss: 0.0010979 accuracy: 100.0\n",
      "loss: 0.00178602 accuracy: 100.0\n",
      "loss: 0.00106374 accuracy: 100.0\n",
      "loss: 0.0051327 accuracy: 100.0\n",
      "loss: 0.00100379 accuracy: 100.0\n",
      "loss: 0.00376952 accuracy: 100.0\n",
      "loss: 0.000767301 accuracy: 100.0\n",
      "loss: 0.00124788 accuracy: 100.0\n",
      "loss: 0.000495403 accuracy: 100.0\n",
      "loss: 0.00167792 accuracy: 100.0\n",
      "loss: 0.000989885 accuracy: 100.0\n",
      "loss: 0.0012926 accuracy: 100.0\n",
      "loss: 0.00189451 accuracy: 100.0\n",
      "loss: 0.000662888 accuracy: 100.0\n",
      "loss: 0.00282794 accuracy: 100.0\n",
      "loss: 0.00132169 accuracy: 100.0\n",
      "loss: 0.00130772 accuracy: 100.0\n",
      "loss: 0.00404965 accuracy: 100.0\n",
      "loss: 0.00141456 accuracy: 100.0\n",
      "loss: 0.00107032 accuracy: 100.0\n",
      "loss: 0.000386504 accuracy: 100.0\n",
      "loss: 0.00211935 accuracy: 100.0\n",
      "loss: 0.000923316 accuracy: 100.0\n",
      "loss: 0.00116508 accuracy: 100.0\n",
      "loss: 0.000224388 accuracy: 100.0\n",
      "loss: 0.115633 accuracy: 98.0\n",
      "loss: 0.000655667 accuracy: 100.0\n",
      "loss: 0.00129279 accuracy: 100.0\n",
      "loss: 0.000655226 accuracy: 100.0\n",
      "loss: 0.00147071 accuracy: 100.0\n",
      "loss: 0.000357621 accuracy: 100.0\n",
      "loss: 0.00107711 accuracy: 100.0\n",
      "loss: 0.00114472 accuracy: 100.0\n",
      "loss: 0.00425034 accuracy: 100.0\n",
      "loss: 0.00571466 accuracy: 100.0\n",
      "loss: 0.000412122 accuracy: 100.0\n",
      "loss: 0.00081566 accuracy: 100.0\n",
      "loss: 0.0030099 accuracy: 100.0\n",
      "loss: 0.00098526 accuracy: 100.0\n",
      "loss: 0.0011767 accuracy: 100.0\n",
      "loss: 0.000519379 accuracy: 100.0\n",
      "loss: 0.00205714 accuracy: 100.0\n",
      "loss: 0.00120024 accuracy: 100.0\n",
      "loss: 0.00125371 accuracy: 100.0\n",
      "loss: 0.00664429 accuracy: 100.0\n",
      "loss: 0.00151439 accuracy: 100.0\n",
      "loss: 0.00178633 accuracy: 100.0\n",
      "loss: 0.00699559 accuracy: 100.0\n",
      "loss: 0.000761342 accuracy: 100.0\n",
      "loss: 0.00160834 accuracy: 100.0\n",
      "loss: 0.00134221 accuracy: 100.0\n",
      "loss: 0.000949534 accuracy: 100.0\n",
      "loss: 0.00242685 accuracy: 100.0\n",
      "loss: 0.00179009 accuracy: 100.0\n",
      "loss: 0.00108142 accuracy: 100.0\n",
      "loss: 0.00207668 accuracy: 100.0\n",
      "loss: 0.000449776 accuracy: 100.0\n",
      "loss: 0.00167893 accuracy: 100.0\n",
      "loss: 0.000304963 accuracy: 100.0\n",
      "loss: 0.000698928 accuracy: 100.0\n",
      "loss: 0.00112352 accuracy: 100.0\n",
      "loss: 0.000992557 accuracy: 100.0\n",
      "loss: 0.000466331 accuracy: 100.0\n",
      "loss: 0.000796644 accuracy: 100.0\n",
      "loss: 0.00123555 accuracy: 100.0\n",
      "loss: 0.0550118 accuracy: 99.0\n",
      "loss: 0.00247987 accuracy: 100.0\n",
      "loss: 0.00371293 accuracy: 100.0\n",
      "loss: 0.000342581 accuracy: 100.0\n",
      "loss: 0.000983373 accuracy: 100.0\n",
      "loss: 0.00123559 accuracy: 100.0\n",
      "loss: 0.00539338 accuracy: 100.0\n",
      "loss: 0.00180089 accuracy: 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.00190524 accuracy: 100.0\n",
      "loss: 0.000725302 accuracy: 100.0\n",
      "loss: 0.00058021 accuracy: 100.0\n",
      "loss: 0.00270537 accuracy: 100.0\n",
      "loss: 0.00296149 accuracy: 100.0\n",
      "loss: 0.00244899 accuracy: 100.0\n",
      "loss: 0.00139543 accuracy: 100.0\n",
      "loss: 0.00131453 accuracy: 100.0\n",
      "loss: 0.00230661 accuracy: 100.0\n",
      "loss: 0.000497015 accuracy: 100.0\n",
      "loss: 0.000357347 accuracy: 100.0\n",
      "loss: 0.00224727 accuracy: 100.0\n",
      "loss: 0.000676417 accuracy: 100.0\n",
      "loss: 0.000573971 accuracy: 100.0\n",
      "loss: 0.00208787 accuracy: 100.0\n",
      "loss: 0.000762648 accuracy: 100.0\n",
      "loss: 0.00421148 accuracy: 100.0\n",
      "loss: 0.000827569 accuracy: 100.0\n",
      "loss: 0.00112153 accuracy: 100.0\n",
      "loss: 0.00044979 accuracy: 100.0\n",
      "loss: 0.0014759 accuracy: 100.0\n",
      "loss: 0.00128987 accuracy: 100.0\n",
      "loss: 0.000898674 accuracy: 100.0\n",
      "loss: 0.000812084 accuracy: 100.0\n",
      "loss: 0.00160039 accuracy: 100.0\n",
      "loss: 0.00189901 accuracy: 100.0\n",
      "loss: 0.00285435 accuracy: 100.0\n",
      "loss: 0.00162699 accuracy: 100.0\n",
      "loss: 0.00114079 accuracy: 100.0\n",
      "loss: 0.00127264 accuracy: 100.0\n",
      "loss: 0.00111439 accuracy: 100.0\n",
      "loss: 0.0013506 accuracy: 100.0\n",
      "loss: 0.00206856 accuracy: 100.0\n",
      ">>>>>>>>>> test dataset accuracy: 98.09\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(mnist.train.num_examples // batch_size))\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    sess.run(init)\n",
    "    #saver.restore(sess, interim_checkpoint_path)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = summary_op.eval(feed_dict={x: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            t, l, a = sess.run([training_op, loss, accuracy], feed_dict={x: X_batch, y: y_batch})\n",
    "            \n",
    "            if batch_index % 10000: print(\"loss:\", l, \"accuracy:\", a)\n",
    "        if epoch % 1 == 0:\n",
    "            save_path = saver.save(sess, interim_checkpoint_path)\n",
    "            test_acc = accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "            \n",
    "            print(\">>>>>>>>>> test dataset accuracy:\", test_acc)\n",
    "\n",
    "    save_path = saver.save(sess, \"./checkpoints/mnist_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
